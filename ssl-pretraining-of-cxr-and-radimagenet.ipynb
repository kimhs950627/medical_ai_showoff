{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d37b13d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-19T04:33:20.390925Z",
     "iopub.status.busy": "2024-06-19T04:33:20.390564Z",
     "iopub.status.idle": "2024-06-19T04:33:44.577574Z",
     "shell.execute_reply": "2024-06-19T04:33:44.576630Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 24.198037,
     "end_time": "2024-06-19T04:33:44.579876",
     "exception": false,
     "start_time": "2024-06-19T04:33:20.381839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 04:33:24.181312: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-19 04:33:24.181435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-19 04:33:24.307312: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.15.0\n",
      "Keras version : 3.3.3\n",
      "Running on 1 replicas\n",
      "batch size 8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import random\n",
    "import pydicom\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "seed = 2024\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ML tools \n",
    "sys.path.append(\"/kaggle/input/kimm-keras-image-model-repository\"\n",
    "               )\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras# ; keras.config.set_dtype_policy(\"mixed_float16\")\n",
    "import kimm\n",
    "import keras_cv\n",
    "import keras_nlp\n",
    "\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "keras.utils.set_random_seed(seed)\n",
    "import tensorflow_io as tfio\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "print(f\"Tensorflow version : {tf.__version__}\")\n",
    "try:\n",
    "    print(f\"Keras version : {keras.__version__}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from keras import Input, Model, ops\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import Conv2D, DepthwiseConv2D, Dense, Activation, BatchNormalization, LayerNormalization, MultiHeadAttention, Embedding, Subtract, Add, Multiply, GlobalAveragePooling2D, GlobalAveragePooling1D, LayerNormalization\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.applications import *\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "#from wandb.keras import WandbCallback, WandbModelCheckpoint, WandbMetricsLogger\n",
    "def wandb_config():\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    try:\n",
    "        secret_value_0 = user_secrets.get_secret(\"__gcloud_sdk_auth__\")\n",
    "        secret_value_1 = user_secrets.get_secret(\"huggingface_key\")\n",
    "        secret_value_2 = user_secrets.get_secret(\"wandb_key\")\n",
    "        !wandb login $secret_value_2\n",
    "    except:\n",
    "        secret_value_0 = user_secrets.get_secret(\"huggingface_key\")\n",
    "        secret_value_1 = user_secrets.get_secret(\"wandb_key\")\n",
    "        !wandb login $secret_value_1\n",
    "    \n",
    "\n",
    "res = int(1.5*256)\n",
    "small_res = 64\n",
    "batch_size = 8\n",
    "embed_dims = 1024\n",
    "n_multicrop = 4\n",
    "\n",
    "def auto_select_accelerator():\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        print(\"Running on TPU:\", tpu.master())\n",
    "    except ValueError:\n",
    "        tpu = False\n",
    "        strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "    \n",
    "    return tpu, strategy\n",
    "\n",
    "tpu, strategy = auto_select_accelerator()\n",
    "batch_size = strategy.num_replicas_in_sync * batch_size\n",
    "print('batch size', batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0bf5dc",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-06-19T04:33:44.595246Z",
     "iopub.status.busy": "2024-06-19T04:33:44.594912Z",
     "iopub.status.idle": "2024-06-19T04:33:44.724235Z",
     "shell.execute_reply": "2024-06-19T04:33:44.723330Z"
    },
    "papermill": {
     "duration": 0.139077,
     "end_time": "2024-06-19T04:33:44.726236",
     "exception": false,
     "start_time": "2024-06-19T04:33:44.587159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirements loaded, keras : v3.3.3, Tensorflow : v2.15.0\n",
      "RandAug Component in this SSL module :  ['random_contrast', 'random_brightness', 'random_shear', 'random_shear_1', 'random_translation', 'random_translation_1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'models_from_kimm': ['ConvMixer1024D20',\n",
       "  'ConvMixer1536D20',\n",
       "  'ConvMixer736D32',\n",
       "  'ConvNeXtAtto',\n",
       "  'ConvNeXtBase',\n",
       "  'ConvNeXtFemto',\n",
       "  'ConvNeXtLarge',\n",
       "  'ConvNeXtNano',\n",
       "  'ConvNeXtPico',\n",
       "  'ConvNeXtSmall',\n",
       "  'ConvNeXtTiny',\n",
       "  'ConvNeXtXLarge',\n",
       "  'DenseNet121',\n",
       "  'DenseNet161',\n",
       "  'DenseNet169',\n",
       "  'DenseNet201',\n",
       "  'EfficientNetB0',\n",
       "  'EfficientNetB1',\n",
       "  'EfficientNetB2',\n",
       "  'EfficientNetB3',\n",
       "  'EfficientNetB4',\n",
       "  'EfficientNetB5',\n",
       "  'EfficientNetB6',\n",
       "  'EfficientNetB7',\n",
       "  'EfficientNetLiteB0',\n",
       "  'EfficientNetLiteB1',\n",
       "  'EfficientNetLiteB2',\n",
       "  'EfficientNetLiteB3',\n",
       "  'EfficientNetLiteB4',\n",
       "  'EfficientNetV2B0',\n",
       "  'EfficientNetV2B1',\n",
       "  'EfficientNetV2B2',\n",
       "  'EfficientNetV2B3',\n",
       "  'EfficientNetV2L',\n",
       "  'EfficientNetV2M',\n",
       "  'EfficientNetV2S',\n",
       "  'EfficientNetV2XL',\n",
       "  'GhostNet050',\n",
       "  'GhostNet100',\n",
       "  'GhostNet100V2',\n",
       "  'GhostNet130',\n",
       "  'GhostNet130V2',\n",
       "  'GhostNet160V2',\n",
       "  'HGNetBase',\n",
       "  'HGNetSmall',\n",
       "  'HGNetTiny',\n",
       "  'HGNetV2B0',\n",
       "  'HGNetV2B1',\n",
       "  'HGNetV2B2',\n",
       "  'HGNetV2B3',\n",
       "  'HGNetV2B4',\n",
       "  'HGNetV2B5',\n",
       "  'HGNetV2B6',\n",
       "  'InceptionNeXtBase',\n",
       "  'InceptionNeXtSmall',\n",
       "  'InceptionNeXtTiny',\n",
       "  'InceptionV3',\n",
       "  'LCNet035',\n",
       "  'LCNet050',\n",
       "  'LCNet075',\n",
       "  'LCNet100',\n",
       "  'LCNet150',\n",
       "  'MobileNetV2W050',\n",
       "  'MobileNetV2W100',\n",
       "  'MobileNetV2W110',\n",
       "  'MobileNetV2W120',\n",
       "  'MobileNetV2W140',\n",
       "  'MobileNetV3W050Small',\n",
       "  'MobileNetV3W075Small',\n",
       "  'MobileNetV3W100Large',\n",
       "  'MobileNetV3W100LargeMinimal',\n",
       "  'MobileNetV3W100Small',\n",
       "  'MobileNetV3W100SmallMinimal',\n",
       "  'MobileOneS0',\n",
       "  'MobileOneS1',\n",
       "  'MobileOneS2',\n",
       "  'MobileOneS3',\n",
       "  'MobileViTS',\n",
       "  'MobileViTV2W050',\n",
       "  'MobileViTV2W075',\n",
       "  'MobileViTV2W100',\n",
       "  'MobileViTV2W125',\n",
       "  'MobileViTV2W150',\n",
       "  'MobileViTV2W175',\n",
       "  'MobileViTV2W200',\n",
       "  'MobileViTXS',\n",
       "  'MobileViTXXS',\n",
       "  'RegNetX002',\n",
       "  'RegNetX004',\n",
       "  'RegNetX006',\n",
       "  'RegNetX008',\n",
       "  'RegNetX016',\n",
       "  'RegNetX032',\n",
       "  'RegNetX040',\n",
       "  'RegNetX064',\n",
       "  'RegNetX080',\n",
       "  'RegNetX120',\n",
       "  'RegNetX160',\n",
       "  'RegNetX320',\n",
       "  'RegNetY002',\n",
       "  'RegNetY004',\n",
       "  'RegNetY006',\n",
       "  'RegNetY008',\n",
       "  'RegNetY016',\n",
       "  'RegNetY032',\n",
       "  'RegNetY040',\n",
       "  'RegNetY064',\n",
       "  'RegNetY080',\n",
       "  'RegNetY120',\n",
       "  'RegNetY160',\n",
       "  'RegNetY320',\n",
       "  'RepVGGA0',\n",
       "  'RepVGGA1',\n",
       "  'RepVGGA2',\n",
       "  'RepVGGB0',\n",
       "  'RepVGGB1',\n",
       "  'RepVGGB2',\n",
       "  'RepVGGB3',\n",
       "  'ResNet101',\n",
       "  'ResNet152',\n",
       "  'ResNet18',\n",
       "  'ResNet34',\n",
       "  'ResNet50',\n",
       "  'TinyNetA',\n",
       "  'TinyNetB',\n",
       "  'TinyNetC',\n",
       "  'TinyNetD',\n",
       "  'TinyNetE',\n",
       "  'VGG11',\n",
       "  'VGG13',\n",
       "  'VGG16',\n",
       "  'VGG19',\n",
       "  'VisionTransformerBase16',\n",
       "  'VisionTransformerBase32',\n",
       "  'VisionTransformerLarge16',\n",
       "  'VisionTransformerLarge32',\n",
       "  'VisionTransformerSmall16',\n",
       "  'VisionTransformerSmall32',\n",
       "  'VisionTransformerTiny16',\n",
       "  'VisionTransformerTiny32',\n",
       "  'Xception'],\n",
       " 'models_from_keras': ['effnet',\n",
       "  'effnet_small',\n",
       "  'effnet_base',\n",
       "  'convnext',\n",
       "  'convnext_small',\n",
       "  'convnext_base',\n",
       "  'mlpmixer_patch_depth_dims',\n",
       "  'convmixer_patch_depth_dims']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl_module\n",
    "from ssl_module import get_map_fn, get_gcvit_configs, get_flops, att_visualize, get_full_model, AttentionPooling, BarlowModel, VICRegModel, Moco, SimSiam, CLIP, SigLIP\n",
    "import nas_ftp_module\n",
    "from nas_ftp_module import upload_file, download_file\n",
    "ssl_module.available_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c05b1ce",
   "metadata": {
    "papermill": {
     "duration": 0.006739,
     "end_time": "2024-06-19T04:33:44.739792",
     "exception": false,
     "start_time": "2024-06-19T04:33:44.733053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- radimagenet tfrecord key : image, label\n",
    "- nih cxr tfrecord key : image_raw, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d16efca",
   "metadata": {
    "papermill": {
     "duration": 0.006622,
     "end_time": "2024-06-19T04:33:44.753215",
     "exception": false,
     "start_time": "2024-06-19T04:33:44.746593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RadImageNet decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e157c983",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-06-19T04:33:44.768052Z",
     "iopub.status.busy": "2024-06-19T04:33:44.767746Z",
     "iopub.status.idle": "2024-06-19T04:33:53.253748Z",
     "shell.execute_reply": "2024-06-19T04:33:53.252421Z"
    },
    "papermill": {
     "duration": 8.496282,
     "end_time": "2024-06-19T04:33:53.256151",
     "exception": false,
     "start_time": "2024-06-19T04:33:44.759869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 384, 384, 1)\n",
      "tf.Tensor([114  30 114 157  83 146 107 151], shape=(8,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def _parse_tfrecord(res = res):\n",
    "    def parse_tfrecord(tfrecord):\n",
    "        features = {'image': tf.io.FixedLenFeature([], tf.string),\n",
    "                    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "                    }\n",
    "        x = tf.io.parse_single_example(tfrecord, features)\n",
    "        image_train = tf.image.decode_jpeg(x['image'], channels=1)\n",
    "        image_train = _transform_images(res = res)(image_train)\n",
    "        label = tf.cast(x[\"label\"], tf.int32)\n",
    "        return (image_train, label)\n",
    "    \n",
    "    return parse_tfrecord\n",
    "\n",
    "\n",
    "def _transform_images(res = res):\n",
    "    def transform_images(x_train):\n",
    "        x_train = tf.image.resize_with_pad(x_train, res, res, antialias = True)\n",
    "        x_train = tf.cast(x_train, tf.uint8)\n",
    "        return x_train\n",
    "    return transform_images\n",
    "\n",
    "def load_tfrecord_dataset(tfrecord_name, res = res, batch_size = batch_size, shuffle=True, buffer_size=10240):\n",
    "    \"\"\"load dataset from tfrecord\"\"\"\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name, compression_type = \"GZIP\")\n",
    "    raw_dataset = raw_dataset.repeat()\n",
    "    if shuffle:\n",
    "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = raw_dataset.map(\n",
    "        _parse_tfrecord(),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_radimagenet_ds = load_tfrecord_dataset(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/RagImageNet_Train_GZIP.tfrecord\")\n",
    "val_ds = load_tfrecord_dataset(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/RagImageNet_Test_GZIP.tfrecord\")\n",
    "for img, label in val_ds.take(1):\n",
    "    print(ops.shape(img))\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167839ed",
   "metadata": {
    "papermill": {
     "duration": 0.007096,
     "end_time": "2024-06-19T04:33:53.270759",
     "exception": false,
     "start_time": "2024-06-19T04:33:53.263663",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NIH CXR decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0853b7c7",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-06-19T04:33:53.287257Z",
     "iopub.status.busy": "2024-06-19T04:33:53.286882Z",
     "iopub.status.idle": "2024-06-19T04:33:53.555425Z",
     "shell.execute_reply": "2024-06-19T04:33:53.554575Z"
    },
    "papermill": {
     "duration": 0.279352,
     "end_time": "2024-06-19T04:33:53.557826",
     "exception": false,
     "start_time": "2024-06-19T04:33:53.278474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _parse_tfrecord(res = res):\n",
    "    def parse_tfrecord(tfrecord):\n",
    "        features = {'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "                    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "                    }\n",
    "        x = tf.io.parse_single_example(tfrecord, features)\n",
    "        image_train = tf.image.decode_jpeg(x['image_raw'], channels=1)\n",
    "        image_train = _transform_images(res = res)(image_train)\n",
    "        label = tf.cast(x[\"label\"], tf.int32)\n",
    "        return (image_train, label)\n",
    "    \n",
    "    return parse_tfrecord\n",
    "\n",
    "\n",
    "def _transform_images(res = res):\n",
    "    def transform_images(x_train):\n",
    "        x_train = tf.image.resize_with_pad(x_train, res, res, antialias = True)\n",
    "        x_train = tf.cast(x_train, tf.uint8)\n",
    "        return x_train\n",
    "    return transform_images\n",
    "\n",
    "def load_tfrecord_dataset(tfrecord_name, res = res, batch_size = batch_size, shuffle=True, buffer_size=10240):\n",
    "    \"\"\"load dataset from tfrecord\"\"\"\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n",
    "    raw_dataset = raw_dataset.repeat()\n",
    "    if shuffle:\n",
    "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = raw_dataset.map(\n",
    "        _parse_tfrecord(),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    if batch_size:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "nih_cxr_ds = load_tfrecord_dataset(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/nih_cxr_images.tfrecords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdef553",
   "metadata": {
    "papermill": {
     "duration": 0.006821,
     "end_time": "2024-06-19T04:33:53.572027",
     "exception": false,
     "start_time": "2024-06-19T04:33:53.565206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Merging 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760397c9",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-06-19T04:33:53.591982Z",
     "iopub.status.busy": "2024-06-19T04:33:53.590970Z",
     "iopub.status.idle": "2024-06-19T04:34:35.867184Z",
     "shell.execute_reply": "2024-06-19T04:34:35.866268Z"
    },
    "papermill": {
     "duration": 42.29101,
     "end_time": "2024-06-19T04:34:35.869756",
     "exception": false,
     "start_time": "2024-06-19T04:33:53.578746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.sample_from_datasets([train_radimagenet_ds.unbatch(), nih_cxr_ds.unbatch()], weights = [0.75, 0.25]).batch(batch_size).repeat().prefetch(tf.data.AUTOTUNE)\n",
    "val_ds_ = tf.data.Dataset.sample_from_datasets([train_radimagenet_ds.unbatch(), nih_cxr_ds.unbatch()], weights = [0.75, 0.25]).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "# train data curation\n",
    "for images, labels in val_ds_.take(1):\n",
    "    sample_img = images\n",
    "    labels = labels\n",
    "del val_ds_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381fa292",
   "metadata": {
    "papermill": {
     "duration": 0.007091,
     "end_time": "2024-06-19T04:34:35.884413",
     "exception": false,
     "start_time": "2024-06-19T04:34:35.877322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Convert supervised dataset into SSL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f428e609",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T04:34:35.900784Z",
     "iopub.status.busy": "2024-06-19T04:34:35.899857Z",
     "iopub.status.idle": "2024-06-19T04:34:40.633805Z",
     "shell.execute_reply": "2024-06-19T04:34:40.632760Z"
    },
    "papermill": {
     "duration": 4.745263,
     "end_time": "2024-06-19T04:34:40.636778",
     "exception": false,
     "start_time": "2024-06-19T04:34:35.891515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "multiview_fn = get_map_fn(res = res, input_type = \"supervised\", output_type = \"ssl\",\n",
    "                         n_view = n_multicrop)\n",
    "two_view_fn = get_map_fn(res = res, input_type = \"supervised\", output_type = \"ssl\",\n",
    "                         n_view = 2)\n",
    "train_ds_multiview = train_ds.unbatch().map(multiview_fn, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds_multiview = val_ds.unbatch().map(multiview_fn, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f7ee373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T04:34:40.653232Z",
     "iopub.status.busy": "2024-06-19T04:34:40.652500Z",
     "iopub.status.idle": "2024-06-19T04:34:44.862933Z",
     "shell.execute_reply": "2024-06-19T04:34:44.862125Z"
    },
    "papermill": {
     "duration": 4.221279,
     "end_time": "2024-06-19T04:34:44.865223",
     "exception": false,
     "start_time": "2024-06-19T04:34:40.643944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for test_set in val_ds_multiview.take(1):\n",
    "    test_set = test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f296fc",
   "metadata": {
    "papermill": {
     "duration": 0.006771,
     "end_time": "2024-06-19T04:34:44.879319",
     "exception": false,
     "start_time": "2024-06-19T04:34:44.872548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "----------\n",
    "# Experiment - helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c850b17c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T04:34:44.895531Z",
     "iopub.status.busy": "2024-06-19T04:34:44.894922Z",
     "iopub.status.idle": "2024-06-19T04:34:47.635909Z",
     "shell.execute_reply": "2024-06-19T04:34:47.634765Z"
    },
    "papermill": {
     "duration": 2.751579,
     "end_time": "2024-06-19T04:34:47.638221",
     "exception": false,
     "start_time": "2024-06-19T04:34:44.886642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train cases : 1303237, validation cases : 163796\n"
     ]
    }
   ],
   "source": [
    "df_train_rad = pd.read_csv(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/RadImgNet_train.csv\")\n",
    "df_train_nih = pd.read_csv(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/nih_trainval_split.csv\"\n",
    "                          )\n",
    "df_val_rad = pd.read_csv(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/RadImgNet_test.csv\")\n",
    "df_val_nih = pd.read_csv(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/nih_test_split.csv\")\n",
    "\n",
    "\n",
    "train_cases = len(df_train_rad) + len(df_train_nih) + len(df_val_nih)\n",
    "val_cases = len(df_val_rad)\n",
    "\n",
    "train_steps = train_cases//batch_size\n",
    "val_steps = val_cases//batch_size\n",
    "print(f\"Total train cases : {train_cases}, validation cases : {val_cases}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce2c066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T04:34:47.654656Z",
     "iopub.status.busy": "2024-06-19T04:34:47.654341Z",
     "iopub.status.idle": "2024-06-19T04:34:47.681555Z",
     "shell.execute_reply": "2024-06-19T04:34:47.680600Z"
    },
    "papermill": {
     "duration": 0.037811,
     "end_time": "2024-06-19T04:34:47.683378",
     "exception": false,
     "start_time": "2024-06-19T04:34:47.645567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelSaveCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, exp_name, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.exp_name = exp_name\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        save_dir = \"/kaggle/working/\" ; target_dir = '/kaggle/working/model_save'\n",
    "        os.makedirs(target_dir, exist_ok = True)\n",
    "        if (epoch % 1 == 0):\n",
    "            try:\n",
    "                print(\"\\nModel Saving to local notebook...\")\n",
    "                file_name = f\"{self.exp_name}_{self.model.name}_keras_v3_Epoch{epoch}.keras\"\n",
    "                filepath = os.path.join(target_dir, file_name)\n",
    "                saved_dir = self.model.save(filepath, overwrite=True)\n",
    "                if (epoch+1) % 5 == 0:\n",
    "                    print(\"\\nModel Uploading to NAS...\")\n",
    "                    upload_file(file_name, filepath)\n",
    "                    print(\"\\nModel Saved to Local NAS\")\n",
    "            except Exception as e: \n",
    "                print('Model Saving Error:\\n', e)\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        save_dir = \"/kaggle/working/\" ; target_dir = '/kaggle/working/model_save'\n",
    "        os.makedirs(target_dir, exist_ok = True)\n",
    "        if (batch % 50000 == 0) and (batch != 0): \n",
    "            try:\n",
    "                print(\"\\nModel Saving to local notebook...\")\n",
    "                file_name = f\"{self.exp_name}_{self.model.name}_keras_v3_Batch{batch}.keras\"\n",
    "                filepath = os.path.join(target_dir, file_name)\n",
    "                saved_dir = self.model.save(filepath, overwrite=True)\n",
    "                if (batch % 10000 == 0):\n",
    "                    print(\"\\nModel Uploading to NAS...\")\n",
    "                    upload_file(file_name, filepath)\n",
    "                    print(\"\\nModel Saved to Local NAS\")\n",
    "            except Exception as e: \n",
    "                print('Model Saving Error:\\n', e)\n",
    "                \n",
    "                \n",
    "class TrainingViz(keras.callbacks.Callback):\n",
    "    def __init__(self, run):\n",
    "        super().__init__()\n",
    "        self.run = run\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        try:\n",
    "            configs = self.model.get_config() ; method = configs[\"SSL_method\"]\n",
    "            if method in [\"CLIP\" , \"SigLIP\", \"SPARC\"]:\n",
    "                feature_extractor = self.model\n",
    "            else:\n",
    "                try:\n",
    "                    feature_extractor = self.model.feature_extractor\n",
    "                except:\n",
    "                    feature_extractor = self.model.get_full_model(res = res)\n",
    "            viz_weights = ssl_module.att_visualize(feature_extractor, sample_img, res,\n",
    "                                                  thresholding = True)\n",
    "            viz_weights = np.array(viz_weights) #batch, heads, res, res, 3\n",
    "            heads = viz_weights.shape[1]\n",
    "            origin = [\"Original Image\"]\n",
    "            col = [f\"Head{idx + 1}\" for idx in range(heads)]\n",
    "            col = origin + col\n",
    "\n",
    "            visualize_data = []\n",
    "            for idx, weights in enumerate(viz_weights):\n",
    "                origin_img = [wandb.Image(sample_img[idx])]\n",
    "                tmp = [wandb.Image(weights[idx]) for idx in range(heads)]\n",
    "                tmp = origin_img + tmp\n",
    "                visualize_data.append(tmp)\n",
    "                del tmp, origin_img\n",
    "            tbl = wandb.Table(columns = col, data = visualize_data)\n",
    "            wandb.log({f\"Epoch{epoch+1}_{method}_result\": tbl})\n",
    "            del feature_extractor, tbl\n",
    "            tf.keras.backend.clear_session()\n",
    "        except Exception as e: \n",
    "                print('Model Saving Error:\\n', e)\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if (batch % (10000) == 0) : \n",
    "            try:\n",
    "                configs = self.model.get_config() ; method = configs[\"SSL_method\"]\n",
    "                if method in [\"CLIP\" , \"SigLIP\", \"SPARC\"]:\n",
    "                    feature_extractor = self.model\n",
    "                else:\n",
    "                    try:\n",
    "                        feature_extractor = self.model.feature_extractor\n",
    "                    except:\n",
    "                        feature_extractor = self.model.get_full_model(res = res)\n",
    "                viz_weights = ssl_module.att_visualize(feature_extractor, sample_img, res,\n",
    "                                                      thresholding = True)\n",
    "                viz_weights = np.array(viz_weights) #batch, heads, res, res, 3\n",
    "                heads = viz_weights.shape[1]\n",
    "                origin = [\"Original Image\"]\n",
    "                col = [f\"Head{idx + 1}\" for idx in range(heads)]\n",
    "                col = origin + col\n",
    "                visualize_data = []\n",
    "                for idx, weights in enumerate(viz_weights):\n",
    "                    origin_img = [wandb.Image(sample_img[idx])]\n",
    "                    tmp = [wandb.Image(weights[idx]) for idx in range(heads)]\n",
    "                    tmp = origin_img + tmp\n",
    "                    visualize_data.append(tmp)\n",
    "                    del tmp, origin_img\n",
    "                tbl = wandb.Table(columns = col, data = visualize_data)\n",
    "                if batch == 0:\n",
    "                    wandb.log({f\"ZeroBatch_{method}_result\": tbl})\n",
    "                else:\n",
    "                    wandb.log({f\"MidEpoch_{method}_result\": tbl})\n",
    "                del feature_extractor, tbl\n",
    "                tf.keras.backend.clear_session()\n",
    "            except Exception as e:\n",
    "                print(\"Error code in callback : \", e)\n",
    "           \n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "147aea7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T04:34:47.699046Z",
     "iopub.status.busy": "2024-06-19T04:34:47.698660Z",
     "iopub.status.idle": "2024-06-19T04:34:47.711297Z",
     "shell.execute_reply": "2024-06-19T04:34:47.710406Z"
    },
    "papermill": {
     "duration": 0.022713,
     "end_time": "2024-06-19T04:34:47.713221",
     "exception": false,
     "start_time": "2024-06-19T04:34:47.690508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_exp(model, train_ds = train_ds, val_ds = val_ds, epochs = 10, note= None, exp_name = None):\n",
    "    try:\n",
    "        wandb.finish()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if True :\n",
    "        wandb_config()\n",
    "        configs = model.get_config()\n",
    "        method = configs[\"SSL_method\"]\n",
    "        try:\n",
    "            feature_extractor = model.feature_extractor\n",
    "        except:\n",
    "            feature_extractor = model.get_full_model(res = res)\n",
    "        \n",
    "        if method in ['CLIP', \"SigLIP\", \"SPARC\"]:\n",
    "            _ = model((example_images[:2], example_reports[:2]))\n",
    "        else:\n",
    "            _ = model(test_set)\n",
    "        feature_extractor_flops = get_flops(feature_extractor, [tf.random.normal([1,res,res,1])])\n",
    "        del feature_extractor\n",
    "        \n",
    "        env_config = {\"batch_size\" : batch_size, \"original resolution\" : res, \"local view resolution\" : small_res,\n",
    "                     \"Training steps\" : train_steps,\n",
    "                     \"Val steps\" : val_steps,\n",
    "                     \"train cases\" : train_cases,\n",
    "                     \"val cases\" : val_cases,\n",
    "                     \"embed_dims\" : embed_dims,\n",
    "                     \"Image resolution\" : res,\n",
    "                     \"(Image) Encoder Flops(G)\" : feature_extractor_flops,\n",
    "                     \"dtype\" : keras.mixed_precision.dtype_policy(),\n",
    "                      \"Optimizer configs\" : model.optimizer.get_config(),\n",
    "                      \"Multicrop N\" : n_multicrop,\n",
    "                     }\n",
    "        configs.update(env_config)\n",
    "        \n",
    "        wd = \"/kaggle/working/\"\n",
    "        file_name = os.path.join(wd, f\"{method}_radimgnet_mini.keras\")\n",
    "        print(configs, \"\\n\\n\")\n",
    "        model.summary()\n",
    "        run = wandb.init(project=\"RadImageNet\", \n",
    "                         entity=\"gongbungkim\", config = configs, notes = note,\n",
    "                        name = exp_name)\n",
    "\n",
    "        pass_error = keras.callbacks.TerminateOnNaN()\n",
    "        wb_callback = wandb.keras.WandbMetricsLogger(log_freq = 100)\n",
    "        \n",
    "        callbacks = [pass_error, wb_callback, ModelSaveCallback(f\"RI_SSL_{method}\"), \n",
    "                     TrainingViz(run)]\n",
    "        if val_ds is not None:\n",
    "            hist = model.fit(train_ds, \n",
    "                             steps_per_epoch = train_steps, \n",
    "                             epochs = epochs, \n",
    "                             validation_data = val_ds, \n",
    "                             validation_steps = val_steps, \n",
    "                             verbose = 1,\n",
    "                             callbacks = callbacks)\n",
    "        else:\n",
    "            hist = model.fit(train_ds, \n",
    "                         steps_per_epoch = train_steps, \n",
    "                         epochs = epochs, \n",
    "                         verbose = 1,\n",
    "                         callbacks = callbacks)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f9f1fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T04:34:47.728996Z",
     "iopub.status.busy": "2024-06-19T04:34:47.728305Z",
     "iopub.status.idle": "2024-06-19T04:34:47.733716Z",
     "shell.execute_reply": "2024-06-19T04:34:47.732877Z"
    },
    "papermill": {
     "duration": 0.015116,
     "end_time": "2024-06-19T04:34:47.735528",
     "exception": false,
     "start_time": "2024-06-19T04:34:47.720412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cosine_decay = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate = 1e-6,\n",
    "    decay_steps = int(0.5*train_steps),\n",
    "    alpha=1e-5,\n",
    "    name='CosineDecay',\n",
    "    warmup_target=2e-4,\n",
    "    warmup_steps=train_steps - int(0.3*train_steps)\n",
    ")\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = 2e-4,\n",
    "    decay_steps=20000,\n",
    "    decay_rate=0.75,\n",
    "    staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f49336ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T04:34:47.750925Z",
     "iopub.status.busy": "2024-06-19T04:34:47.750230Z",
     "iopub.status.idle": "2024-06-19T04:34:47.757742Z",
     "shell.execute_reply": "2024-06-19T04:34:47.756824Z"
    },
    "papermill": {
     "duration": 0.017179,
     "end_time": "2024-06-19T04:34:47.759578",
     "exception": false,
     "start_time": "2024-06-19T04:34:47.742399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ssl_train(module, feature_extractor, learning_rate = lr_schedule,\n",
    "              embed_dims = embed_dims, multiview = True, gradient_accumulation = None, use_ema = False,\n",
    "             note = \"\", name = \"\",\n",
    "             apply_barlow = False, apply_simclr = False):\n",
    "    try:\n",
    "        ssl_trainer = module(feature_extractor, embed_dims = 2048, multiview = multiview,\n",
    "                            apply_barlow = apply_barlow, apply_simclr = apply_simclr)\n",
    "    except Exception as e:\n",
    "        print(\"Error : \",e)\n",
    "        ssl_trainer = module(feature_extractor, embed_dims = 2048, multiview = multiview)\n",
    "    ssl_trainer.compile(optimizer = keras.optimizers.Adam(learning_rate = learning_rate,\n",
    "                                                         clipnorm = 0.5,\n",
    "                                                         #amsgrad = True,\n",
    "                                                           gradient_accumulation_steps=gradient_accumulation,\n",
    "                                                         use_ema = use_ema),\n",
    "                        jit_compile = False\n",
    "                      )\n",
    "    \n",
    "    run_exp(ssl_trainer, train_ds_multiview, None, epochs = 100,\n",
    "       note = \"Without validation d/t lack of resources\" + note, exp_name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f37c92d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T04:34:47.775139Z",
     "iopub.status.busy": "2024-06-19T04:34:47.774810Z",
     "iopub.status.idle": "2024-06-19T04:34:47.779928Z",
     "shell.execute_reply": "2024-06-19T04:34:47.779045Z"
    },
    "papermill": {
     "duration": 0.01526,
     "end_time": "2024-06-19T04:34:47.781909",
     "exception": false,
     "start_time": "2024-06-19T04:34:47.766649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ibot = 0\n",
    "other = 1\n",
    "\n",
    "depth = 8\n",
    "heads = 8\n",
    "att_dims = heads * 64\n",
    "patch_size = 24 #16, 24, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc06a5ac",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-06-19T04:34:47.798294Z",
     "iopub.status.busy": "2024-06-19T04:34:47.797980Z",
     "iopub.status.idle": "2024-06-19T04:34:47.803805Z",
     "shell.execute_reply": "2024-06-19T04:34:47.802989Z"
    },
    "papermill": {
     "duration": 0.016797,
     "end_time": "2024-06-19T04:34:47.805681",
     "exception": false,
     "start_time": "2024-06-19T04:34:47.788884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if ibot:\n",
    "    \n",
    "\n",
    "    ssl_trainer = ssl_module.iBOT(att_depth = depth, att_dims = att_dims, att_heads = heads,\n",
    "                                  embed_dims = 2048, patch_size = patch_size,\n",
    "\n",
    "                                  multiview = True, apply_simclr = False,\n",
    "                                  grayscale = True\n",
    "                                 )\n",
    "    ssl_trainer.compile(optimizer = keras.optimizers.AdamW(learning_rate = lr_schedule,\n",
    "                                                         clipnorm = 1.0, use_ema = True),\n",
    "                       jit_compile = False)\n",
    "    run_exp(ssl_trainer, train_ds_multiview, None, epochs = 100,\n",
    "           note = \"+ NEW aug, New Patching\", exp_name = \"iBOT_VanillaViT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40ed47e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-19T04:34:47.821117Z",
     "iopub.status.busy": "2024-06-19T04:34:47.820771Z",
     "iopub.status.idle": "2024-06-19T05:04:17.125216Z",
     "shell.execute_reply": "2024-06-19T05:04:17.123429Z"
    },
    "papermill": {
     "duration": 1769.403547,
     "end_time": "2024-06-19T05:04:17.216164",
     "exception": false,
     "start_time": "2024-06-19T04:34:47.812617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error :  Unrecognized keyword arguments passed to VICRegModel: {'apply_barlow': False, 'apply_simclr': False}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\r\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\r\n",
      "{'feature_extractor_name': 'Metaformer_res384_type_attention', 'embed_dims': 1024, 'Multiview(>2)': True, 'Variance_coefficient': 20, 'Invariance_coefficient': 20, 'Covariance_coefficient': 1, 'Variance_gamma': 5.0, 'SSL_method': 'VICReg', 'Linear Probe': False, 'N_Categories': 0, 'Probe Activation': 'NA', 'batch_size': 8, 'original resolution': 384, 'local view resolution': 64, 'Training steps': 162904, 'Val steps': 20474, 'train cases': 1303237, 'val cases': 163796, 'Image resolution': 384, '(Image) Encoder Flops(G)': 45.607580264, 'dtype': <FloatDTypePolicy \"float32\">, 'Optimizer configs': {'name': 'adam', 'learning_rate': {'module': 'keras.optimizers.schedules', 'class_name': 'ExponentialDecay', 'config': {'initial_learning_rate': 0.0002, 'decay_steps': 20000, 'decay_rate': 0.75, 'staircase': True, 'name': 'ExponentialDecay'}, 'registered_name': None}, 'weight_decay': None, 'clipnorm': 0.5, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': True, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': 16, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'Multicrop N': 4} \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vic_reg_model_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"vic_reg_model_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Metaformer_res384_type_attenti… │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">70,693,888</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Metaformer_res384_type_attenti… │ ?                      │    \u001b[38;5;34m70,693,888\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_3 (\u001b[38;5;33mSequential\u001b[0m)       │ ?                      │     \u001b[38;5;34m5,246,976\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_4 (\u001b[38;5;33mSequential\u001b[0m)       │ ?                      │     \u001b[38;5;34m5,246,976\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,187,840</span> (309.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81,187,840\u001b[0m (309.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,187,840</span> (309.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m81,187,840\u001b[0m (309.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgongbungkim\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.17.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.17.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20240619_043511-6p45tj39\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mVICReg_attention_reg\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/gongbungkim/RadImageNet\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/gongbungkim/RadImageNet/runs/6p45tj39\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Unable to log learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Raw model with Att pooling \n",
      " Possible error: \n",
      " 'Functional' object has no attribute 'get_full_model'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718771795.322026      69 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1718771795.344470      69 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1552/162904\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46:36:10\u001b[0m 1s/step - covariance_loss: 5.6187e-04 - invariance_loss: 0.0180 - loss: 199.2760 - variance_loss: 199.2573Batch 1552: Invalid loss, terminating training\n",
      "\u001b[1m  1553/162904\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46:36:14\u001b[0m 1s/step - covariance_loss: nan - invariance_loss: nan - loss: nan - variance_loss: nan                    \n",
      "Model Saving to local notebook...\n",
      "Using Raw model with Att pooling \n",
      " Possible error: \n",
      " 'Functional' object has no attribute 'get_full_model'\n",
      "\u001b[1m162904/162904\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1728s\u001b[0m 10ms/step - covariance_loss: nan - invariance_loss: nan - loss: nan - variance_loss: nan \n"
     ]
    }
   ],
   "source": [
    "if other:\n",
    "    model_ = 'attention'\n",
    "    vanilla_model = ssl_module.get_metaformer(model_, res = res, embed_dims = 512, \n",
    "                                              att_depth = depth, att_heads = heads,att_dims = att_dims,\n",
    "                                              grayscale = True, patch_size = patch_size, register_tokens = 2)\n",
    "    ssl_train(ssl_module.VICRegModel, vanilla_model, \n",
    "             note = \"+ register early, NEW aug, New Patching\",\n",
    "             name = f\"VICReg_{model_}_reg\",\n",
    "             #apply_barlow = 0, apply_simclr = 0,\n",
    "             learning_rate = lr_schedule, use_ema = True,\n",
    "             gradient_accumulation = 16)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5051531,
     "sourceId": 8471595,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5112865,
     "sourceId": 8556597,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 169421886,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 183683967,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1863.0224,
   "end_time": "2024-06-19T05:04:20.617406",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-19T04:33:17.595006",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
