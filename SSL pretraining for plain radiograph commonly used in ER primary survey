{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport pydicom\n\nfrom sklearn.manifold import TSNE\nimport re\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nseed = 2024\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# ML tools \n\nimport tensorflow as tf\nimport keras\nimport keras_cv\nimport keras_nlp\n#tf.keras.mixed_precision.set_global_policy('mixed_float16')\n\nimport cv2\nkeras.utils.set_random_seed(seed)\nimport tensorflow_io as tfio\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow_datasets as tfds\nimport tensorflow_probability as tfp\nimport tensorflow_decision_forests as tfdf\n\nprint(f\"Tensorflow version : {tf.__version__}\")\ntry:\n    print(f\"Keras version : {keras.__version__}\")\nexcept:\n    pass\n\nfrom keras import Input, Model, ops\nfrom keras.models import load_model\n\nfrom keras.layers import Conv2D, DepthwiseConv2D, Dense, Activation, BatchNormalization, LayerNormalization, MultiHeadAttention, Embedding, Subtract, Add, Multiply, GlobalAveragePooling2D, GlobalAveragePooling1D, LayerNormalization\nfrom keras.utils import load_img, img_to_array\nfrom keras.applications import *\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tqdm.notebook import tqdm\nimport wandb\nfrom wandb.keras import WandbCallback, WandbModelCheckpoint, WandbMetricsLogger\ndef wandb_config():\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    try:\n        secret_value_0 = user_secrets.get_secret(\"__gcloud_sdk_auth__\")\n        secret_value_1 = user_secrets.get_secret(\"huggingface_key\")\n        secret_value_2 = user_secrets.get_secret(\"wandb_key\")\n        !wandb login $secret_value_2\n    except:\n        secret_value_0 = user_secrets.get_secret(\"huggingface_key\")\n        secret_value_1 = user_secrets.get_secret(\"wandb_key\")\n        !wandb login $secret_value_1\n    \n\nres = int(1.5*256)\nsmall_res = 64\nbatch_size = 32\nembed_dims = 768\n\ndef auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        tpu = False\n        strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return tpu, strategy\n\ntpu, strategy = auto_select_accelerator()\nbatch_size = strategy.num_replicas_in_sync * batch_size\nprint('batch size', batch_size)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-17T15:45:37.874793Z","iopub.execute_input":"2024-04-17T15:45:37.875251Z","iopub.status.idle":"2024-04-17T15:45:37.915041Z","shell.execute_reply.started":"2024-04-17T15:45:37.875215Z","shell.execute_reply":"2024-04-17T15:45:37.914070Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Tensorflow version : 2.15.0\nKeras version : 3.1.1\nRunning on 1 replicas\nbatch size 32\n","output_type":"stream"}]},{"cell_type":"code","source":"import ssl_module\nfrom ssl_module import get_gcvit_configs, get_flops, att_visualize, get_full_model, AttentionPooling, BarlowModel, VICRegModel, Moco, SimSiam, CLIP, SigLIP\nimport nas_ftp_module\nfrom nas_ftp_module import upload_file, download_file","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:26.240792Z","iopub.execute_input":"2024-04-17T15:32:26.241413Z","iopub.status.idle":"2024-04-17T15:32:26.310920Z","shell.execute_reply.started":"2024-04-17T15:32:26.241382Z","shell.execute_reply":"2024-04-17T15:32:26.309620Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirements loaded, keras : v3.1.1, Tensorflow : v2.15.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data import (with Generator)\n- 목적 : CXR의 prior knowledge를 SwAV으로 feature map generator에 주입시키기\n- Bounding box의 information을 사용하지 않음 + External data를 사용하자","metadata":{}},{"cell_type":"code","source":"metainfo_dir = \"/kaggle/input/chexdet-image-and-annotations/ChestXDet_Metainformations/ChestX-Det-Dataset-main\"\ntrain_det_dir = \"/kaggle/input/chexdet-image-and-annotations/train_data/train\"\nval_det_dir = \"/kaggle/input/chexdet-image-and-annotations/test_data/test\"\n\ndf_det_train = pd.read_json(\"/kaggle/input/chexdet-image-and-annotations/ChestXDet_Metainformations/ChestX-Det-Dataset-main/ChestX_Det_train.json\")\ndf_det_train[\"file_name\"] = [os.path.join(train_det_dir, fname) for fname in df_det_train.file_name.values]\ndf_det_train = df_det_train.loc[:, [\"file_name\"]]\n\ndf_val = pd.read_json(\"/kaggle/input/chexdet-image-and-annotations/ChestXDet_Metainformations/ChestX-Det-Dataset-main/ChestX_Det_test.json\")\ndf_val[\"file_name\"] = [os.path.join(val_det_dir, fname) for fname in df_val.file_name.values]\ndf_val_cxr = df_val.loc[:, [\"file_name\"]]\n\n#\next_dir = \"/kaggle/input/vinbigdata-chest-xray-original-png/train\"\ndict_ext = {\"file_name\" : [os.path.join(ext_dir, fname) for fname in os.listdir(ext_dir)] }\ndf_ext = pd.DataFrame(dict_ext)\ndf_train_cxr = pd.concat([df_det_train, df_ext], axis = 0)\nprint(f\"Total training cases for CXR : {len(df_train_cxr)} cases, Validation case : {len(df_val_cxr)} case\")","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-17T15:32:26.313014Z","iopub.execute_input":"2024-04-17T15:32:26.313878Z","iopub.status.idle":"2024-04-17T15:32:27.167841Z","shell.execute_reply.started":"2024-04-17T15:32:26.313838Z","shell.execute_reply":"2024-04-17T15:32:27.166408Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Total training cases for CXR : 18025 cases, Validation case : 553 case\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> Deeplesion metainformation dataframe 생성","metadata":{}},{"cell_type":"code","source":"ct_fname = []\nbase_img_dir = '/kaggle/input/nih-deeplesion-subset/minideeplesion'\nfor dirname, _, filenames in tqdm(os.walk(base_img_dir)):\n    for filename in filenames:\n        ct_fname.append(os.path.join(dirname, filename))\n        \ndf_ct_whole = pd.DataFrame({\"file_name\" : ct_fname})\n\ndf_ct_train, df_ct_val = train_test_split(df_ct_whole, \n                                         test_size = 134,\n                                         random_state = seed)\nprint(f\"Total training cases of Chest/Abdomen CT : {len(df_ct_train)} cases, Validation case : {len(df_ct_val)} case\")","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:27.171220Z","iopub.execute_input":"2024-04-17T15:32:27.171789Z","iopub.status.idle":"2024-04-17T15:32:35.934508Z","shell.execute_reply.started":"2024-04-17T15:32:27.171750Z","shell.execute_reply":"2024-04-17T15:32:35.933389Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74ee028a35d642cba4fb3c42a96bdffb"}},"metadata":{}},{"name":"stdout","text":"Total training cases of Chest/Abdomen CT : 33200 cases, Validation case : 134 case\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> import RSNA ICH dataset metainformation dataframe","metadata":{}},{"cell_type":"code","source":"dicom_dir = \"/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train\"\ndf_train_brainct = pd.read_csv(\"/kaggle/input/rsna-ich-detection-metadata/df_train_split.csv\")\ndf_val_brainct = pd.read_csv(\"/kaggle/input/rsna-ich-detection-metadata/df_val_splt.csv\").head(300)\n\nfor df in [df_train_brainct, df_val_brainct]:\n    df[\"file_name\"] = [os.path.join(dicom_dir, fname + \".dcm\") for fname in df['SOPInstanceUID']]\n    \nprint(f\"Total training cases of Brain, NonCE CT : {len(df_train_brainct)} cases, Validation case : {len(df_val_brainct)} case\")","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:35.936017Z","iopub.execute_input":"2024-04-17T15:32:35.936421Z","iopub.status.idle":"2024-04-17T15:32:36.115383Z","shell.execute_reply.started":"2024-04-17T15:32:35.936393Z","shell.execute_reply":"2024-04-17T15:32:36.114278Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Total training cases of Brain, NonCE CT : 32000 cases, Validation case : 300 case\n","output_type":"stream"}]},{"cell_type":"code","source":"df_train = pd.concat([df_ct_train, df_train_cxr, df_train_brainct], axis = 0, join='inner')\ndf_val = pd.concat([df_val_cxr, df_ct_val, df_val_brainct], axis = 0, join='inner')\n\ndf_train.to_csv(\"df_train_ER_SSL.csv\", index = False)\ndf_val.to_csv(\"df_val_ER_SSL.csv\", index = False)\n\nprint(f\"Total train cases : {len(df_train)}, val cases : {len(df_val)} cases\")\ndf_train.sample(10)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:36.116897Z","iopub.execute_input":"2024-04-17T15:32:36.117321Z","iopub.status.idle":"2024-04-17T15:32:36.577965Z","shell.execute_reply.started":"2024-04-17T15:32:36.117292Z","shell.execute_reply":"2024-04-17T15:32:36.576621Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Total train cases : 83225, val cases : 987 cases\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                               file_name\n27863  /kaggle/input/rsna-intracranial-hemorrhage-det...\n1222   /kaggle/input/nih-deeplesion-subset/minideeple...\n12077  /kaggle/input/nih-deeplesion-subset/minideeple...\n25883  /kaggle/input/nih-deeplesion-subset/minideeple...\n11373  /kaggle/input/vinbigdata-chest-xray-original-p...\n13095  /kaggle/input/vinbigdata-chest-xray-original-p...\n2090   /kaggle/input/nih-deeplesion-subset/minideeple...\n10721  /kaggle/input/vinbigdata-chest-xray-original-p...\n1321   /kaggle/input/chexdet-image-and-annotations/tr...\n30151  /kaggle/input/rsna-intracranial-hemorrhage-det...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27863</th>\n      <td>/kaggle/input/rsna-intracranial-hemorrhage-det...</td>\n    </tr>\n    <tr>\n      <th>1222</th>\n      <td>/kaggle/input/nih-deeplesion-subset/minideeple...</td>\n    </tr>\n    <tr>\n      <th>12077</th>\n      <td>/kaggle/input/nih-deeplesion-subset/minideeple...</td>\n    </tr>\n    <tr>\n      <th>25883</th>\n      <td>/kaggle/input/nih-deeplesion-subset/minideeple...</td>\n    </tr>\n    <tr>\n      <th>11373</th>\n      <td>/kaggle/input/vinbigdata-chest-xray-original-p...</td>\n    </tr>\n    <tr>\n      <th>13095</th>\n      <td>/kaggle/input/vinbigdata-chest-xray-original-p...</td>\n    </tr>\n    <tr>\n      <th>2090</th>\n      <td>/kaggle/input/nih-deeplesion-subset/minideeple...</td>\n    </tr>\n    <tr>\n      <th>10721</th>\n      <td>/kaggle/input/vinbigdata-chest-xray-original-p...</td>\n    </tr>\n    <tr>\n      <th>1321</th>\n      <td>/kaggle/input/chexdet-image-and-annotations/tr...</td>\n    </tr>\n    <tr>\n      <th>30151</th>\n      <td>/kaggle/input/rsna-intracranial-hemorrhage-det...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_lists = df_train[\"file_name\"].values.tolist()\nval_lists = df_val[\"file_name\"].values.tolist()\n\ntrain_path_loader = tf.data.Dataset.from_tensor_slices(train_lists).shuffle(10240)\nval_path_loader = tf.data.Dataset.from_tensor_slices(val_lists).shuffle(10240)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:32:53.388237Z","iopub.execute_input":"2024-04-17T16:32:53.388655Z","iopub.status.idle":"2024-04-17T16:32:53.414065Z","shell.execute_reply.started":"2024-04-17T16:32:53.388621Z","shell.execute_reply":"2024-04-17T16:32:53.412766Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"a = [pydicom.dcmread(path) for path in tqdm(train_lists)]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:38:23.340111Z","iopub.execute_input":"2024-04-17T16:38:23.340639Z","iopub.status.idle":"2024-04-17T16:38:25.588041Z","shell.execute_reply.started":"2024-04-17T16:38:23.340598Z","shell.execute_reply":"2024-04-17T16:38:25.586827Z"},"trusted":true},"execution_count":140,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31f1b5f8cd4f4c64808208d17d7e88fd"}},"metadata":{}}]},{"cell_type":"code","source":"a_set = tf.data.Dataset.from_tensor_slices(a).batch(1)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:38:51.623307Z","iopub.execute_input":"2024-04-17T16:38:51.623719Z","iopub.status.idle":"2024-04-17T16:38:52.347279Z","shell.execute_reply.started":"2024-04-17T16:38:51.623689Z","shell.execute_reply":"2024-04-17T16:38:52.340839Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":142,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:105\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:514\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    511\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[0;32m--> 514\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    515\u001b[0m     element,\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n","\u001b[0;31mTypeError\u001b[0m: Could not build a `TypeSpec` for [Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.286050220430966349617535173237563649514\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_082852b5f\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_01e02077'\n(0020, 000d) Study Instance UID                  UI: ID_a964d7e151\n(0020, 000e) Series Instance UID                 UI: ID_6f92599dd8\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -89.462, 191.061]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.939693, -0.342020]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.139014906589890941072382591999818249250\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_1836ae40e\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_7aa00c2d'\n(0020, 000d) Study Instance UID                  UI: ID_325559137f\n(0020, 000e) Series Instance UID                 UI: ID_d5edb8973d\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-100, 44.5854776, 144.294621]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.920504853, -0.390731128]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.36706396645844225182267188902262362297\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_05f0fdb62\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_f5d684a0'\n(0020, 000d) Study Instance UID                  UI: ID_7239522f60\n(0020, 000e) Series Instance UID                 UI: ID_cd81e3fdcf\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-136.5, -30.5732023, 269.586989]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.945518576, -0.325568154]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.533203125, 0.533203125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000032057\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_01d2b04bf\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_0ea9cb99'\n(0020, 000d) Study Instance UID                  UI: ID_74d7fac730\n(0020, 000e) Series Instance UID                 UI: ID_e6a4ce918d\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, -30, 215.5]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.311682692699571569539276787793915634651\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_05a12a50e\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_3f829916'\n(0020, 000d) Study Instance UID                  UI: ID_3145b296fe\n(0020, 000e) Series Instance UID                 UI: ID_10dbe704c7\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -126.746239, 29.356157]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.972370, -0.233445]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.303284772449989091072005759105287310950\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_04eb19c0f\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_65d504b0'\n(0020, 000d) Study Instance UID                  UI: ID_f0eef2bc93\n(0020, 000e) Series Instance UID                 UI: ID_f9dbfcb3ee\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -119.852, 76.610]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.958820, -0.284015]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.99494614043293020177692138407792065283\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_1d4ffee04\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_054a5dfc'\n(0020, 000d) Study Instance UID                  UI: ID_5fcaecda2d\n(0020, 000e) Series Instance UID                 UI: ID_39c1febd77\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -118.189819, 127.710327]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.945519, -0.325568]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '100.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.275151489176820803583607335066169296526\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_1b721c3a3\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_5da92828'\n(0020, 000d) Study Instance UID                  UI: ID_234e0b2492\n(0020, 000e) Series Instance UID                 UI: ID_ccd6a6fc20\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, 32.6419574, 247.990275]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.933580426, -0.35836795]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.152579102812957011239209853204664350946\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_015fc9759\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_127cc03c'\n(0020, 000d) Study Instance UID                  UI: ID_2b500114e4\n(0020, 000e) Series Instance UID                 UI: ID_29ecf20f76\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-126.408875, -126.408875, 12.500000]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.494750976563, 0.494750976563]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '35.0'\n(0028, 1051) Window Width                        DS: '135.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.284308658402612451717161138361556413483\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_06cb05218\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_ffd91f66'\n(0020, 000d) Study Instance UID                  UI: ID_17343690a6\n(0020, 000e) Series Instance UID                 UI: ID_3a663c607d\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -123.461, 166.367]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.987688, -0.156434]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000082649\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0586f3c59\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_083f644d'\n(0020, 000d) Study Instance UID                  UI: ID_236f841120\n(0020, 000e) Series Instance UID                 UI: ID_f097692361\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-138, -9, 204]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00032, 00032]\n(0028, 1051) Window Width                        DS: [00083, 00083]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.299013012223889530314848564549064354091\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0530bea6e\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_f4719582'\n(0020, 000d) Study Instance UID                  UI: ID_d57d540e54\n(0020, 000e) Series Instance UID                 UI: ID_f92bf484d9\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -129.818451, 92.046844]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.968148, -0.250380]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.190901153979172388751667851782629329807\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0738e78b3\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_f3e79598'\n(0020, 000d) Study Instance UID                  UI: ID_46c48430df\n(0020, 000e) Series Instance UID                 UI: ID_e118039923\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -97.515, 34.823]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.953717, -0.300706]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.147208707215623513635878540871864763172\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_06c3a1998\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_4f792b45'\n(0020, 000d) Study Instance UID                  UI: ID_379a775fb9\n(0020, 000e) Series Instance UID                 UI: ID_45805d0601\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -125.552460, 182.985077]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.958820, -0.284015]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '100.0'\n(0028, 1052) Rescale Intercept                   DS: '0.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.242281113931578433517874958105728456590\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_06dc1057b\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_a19a1530'\n(0020, 000d) Study Instance UID                  UI: ID_0978618658\n(0020, 000e) Series Instance UID                 UI: ID_4d82c788a3\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -149.300, 48.750]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000266122\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_002a132d3\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_b6e62169'\n(0020, 000d) Study Instance UID                  UI: ID_d14dfcbaae\n(0020, 000e) Series Instance UID                 UI: ID_2adbb4060c\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-115.5, -2.5, 246.699951]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.451171875, 0.451171875]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.20127908583658813406695056274990196801\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_068e95c9b\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_c5f74b91'\n(0020, 000d) Study Instance UID                  UI: ID_4656e4a033\n(0020, 000e) Series Instance UID                 UI: ID_2c74d82f10\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-126.408875, -126.408875, 176.882339]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.494750976563, 0.494750976563]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '35.0'\n(0028, 1051) Window Width                        DS: '135.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.173849377154678981492991565310328978173\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_008346fdc\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_9810ef5e'\n(0020, 000d) Study Instance UID                  UI: ID_3d26cc94b9\n(0020, 000e) Series Instance UID                 UI: ID_debcb4d142\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -138.396255, 87.452820]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.974370, -0.224951]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 186\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.27256460564373524905895452161012857911\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_00783a2b5\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_12e62dd1'\n(0020, 000d) Study Instance UID                  UI: ID_26a483499f\n(0020, 000e) Series Instance UID                 UI: ID_1706d42d37\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -92.784027, 9.286617]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.936672, -0.350207]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.11404548472171268974320277372704935870\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_2997cb7a6\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_d219aa25'\n(0020, 000d) Study Instance UID                  UI: ID_dad6fababa\n(0020, 000e) Series Instance UID                 UI: ID_b984a4caa0\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-108.000, -129.200, 34.500]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.421875, 0.421875]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.295094361427060170102891682675374363882\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_066d65d99\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_5b4138bb'\n(0020, 000d) Study Instance UID                  UI: ID_3e6638e253\n(0020, 000e) Series Instance UID                 UI: ID_5b45b215ee\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, 15.9242722, 186.643989]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.920504853, -0.390731128]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00047, 00047]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.249989606059909152545317097050122467586\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_21788e18f\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_f846d361'\n(0020, 000d) Study Instance UID                  UI: ID_d0653b52db\n(0020, 000e) Series Instance UID                 UI: ID_4567bbcc71\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -105.497978, 108.119293]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.927184, -0.374607]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.326197848269138163147709191058811026534\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_28090fecb\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_859756af'\n(0020, 000d) Study Instance UID                  UI: ID_f0d83260df\n(0020, 000e) Series Instance UID                 UI: ID_f1f92204cc\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-153, 54.4074155, 383.553542]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.965925826, -0.258819045]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000136333\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_06c595657\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_f2eceaf2'\n(0020, 000d) Study Instance UID                  UI: ID_4270858c07\n(0020, 000e) Series Instance UID                 UI: ID_c62455f56e\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-114.5, 3.5, 123.799988]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.447265625, 0.447265625]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 186\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.54980311792109983740002443645817310250\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_023b02213\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_f500f072'\n(0020, 000d) Study Instance UID                  UI: ID_07468f18da\n(0020, 000e) Series Instance UID                 UI: ID_d98f20db99\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -136.597977, 185.894501]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.927184, -0.374607]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.181198417744273088020121609209265326595\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_064ce9b9a\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_751df220'\n(0020, 000d) Study Instance UID                  UI: ID_4c26128a8d\n(0020, 000e) Series Instance UID                 UI: ID_a3da73fd37\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-145, 53.7979186, -40.5711677]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.874619707, -0.48480962]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.55859375, 0.55859375]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00047, 00047]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000072764\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_076d526e1\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_15cabc35'\n(0020, 000d) Study Instance UID                  UI: ID_b5b5caba6d\n(0020, 000e) Series Instance UID                 UI: ID_5f393b863c\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, -22, 139.800049]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.231270175666779778203284894321808328948\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_04c397d01\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_ff97b14f'\n(0020, 000d) Study Instance UID                  UI: ID_fd1a7e118a\n(0020, 000e) Series Instance UID                 UI: ID_d4535e8d83\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -127.691, 60.184]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.979925, -0.199368]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 186\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.1262421086618211435299584018758916812\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_053aaf32d\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_10b06cb8'\n(0020, 000d) Study Instance UID                  UI: ID_72c567dcbe\n(0020, 000e) Series Instance UID                 UI: ID_3296a53d0f\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -121.062, 82.810]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.939693, -0.342020]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000288986\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_2a9b5cf92\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_8fcaa953'\n(0020, 000d) Study Instance UID                  UI: ID_36c95a93e2\n(0020, 000e) Series Instance UID                 UI: ID_fa5411f207\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-132.894737, 43.8421049, 145]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000005381\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_04428329f\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_34469f25'\n(0020, 000d) Study Instance UID                  UI: ID_bd17c463a1\n(0020, 000e) Series Instance UID                 UI: ID_5934007345\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, -9, 93.5999756]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.215263941618076816415710532714491331488\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_000d253a8\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_0d1ce574'\n(0020, 000d) Study Instance UID                  UI: ID_73beb035db\n(0020, 000e) Series Instance UID                 UI: ID_024b71a40e\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, -10.4021239, 427.006767]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.984807753, -0.173648178]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.339132438197086021932439250334508339375\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_04facca6e\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_70e09078'\n(0020, 000d) Study Instance UID                  UI: ID_5f8e7cc7e7\n(0020, 000e) Series Instance UID                 UI: ID_bace9b6190\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -142.715, 33.214]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.996917, 0.078459]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000183913\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_00410185e\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_f2eceaf2'\n(0020, 000d) Study Instance UID                  UI: ID_6349710e0e\n(0020, 000e) Series Instance UID                 UI: ID_6633eb10ac\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-107.5, -55.5, 175.599976]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.419921875, 0.419921875]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.113998325333034250818411757776493117828\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0437df82c\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_bf201329'\n(0020, 000d) Study Instance UID                  UI: ID_1a76e12a6a\n(0020, 000e) Series Instance UID                 UI: ID_8fbbcbc485\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -108.197983, 91.782852]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.927184, -0.374607]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 186\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.27937942678186200389505358988517035953\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_134ac4929\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_c4bf40b7'\n(0020, 000d) Study Instance UID                  UI: ID_32fb5742e9\n(0020, 000e) Series Instance UID                 UI: ID_15520268ae\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -115.897980, 97.821175]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.927184, -0.374607]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000313402\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_000e17841\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_5c623a36'\n(0020, 000d) Study Instance UID                  UI: ID_26a200d550\n(0020, 000e) Series Instance UID                 UI: ID_a472e39d11\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, -12, 246]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000171466\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_2039aefb8\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_683fd24c'\n(0020, 000d) Study Instance UID                  UI: ID_405c292102\n(0020, 000e) Series Instance UID                 UI: ID_9c1e421cad\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-120.5, -11.5, 189]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.470703125, 0.470703125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.217293363076057569185982385849623795821\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_2c7238851\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_e7fb07db'\n(0020, 000d) Study Instance UID                  UI: ID_0062f95160\n(0020, 000e) Series Instance UID                 UI: ID_e3e69d7c53\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -102.568, 32.228]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.978148, -0.207912]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000024157\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_012d6904c\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_a645f07f'\n(0020, 000d) Study Instance UID                  UI: ID_abb81f6f77\n(0020, 000e) Series Instance UID                 UI: ID_ae0d38d578\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-108.5, 12.5, 126.599976]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.423828125, 0.423828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.202551610034020141600203986202054104034\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_1623e0082\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_b5f2914a'\n(0020, 000d) Study Instance UID                  UI: ID_6612ca4ba2\n(0020, 000e) Series Instance UID                 UI: ID_a2c241289d\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-88.587, -10.788, 158.49]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.376953125, 0.376953125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [40, 40]\n(0028, 1051) Window Width                        DS: [80, 80]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.23699921753892912666942034891865268718\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_079032184\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_75a34aa5'\n(0020, 000d) Study Instance UID                  UI: ID_d4ce0b88a6\n(0020, 000e) Series Instance UID                 UI: ID_68c51054e6\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, 28.8908351, 1337.03265]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.920504853, -0.390731128]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.339321348548673211961843272224334287558\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_06c8b4297\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_d46cb9db'\n(0020, 000d) Study Instance UID                  UI: ID_93f17e6c53\n(0020, 000e) Series Instance UID                 UI: ID_f3e1744e30\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -124.053802, 184.994293]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.963630, -0.267238]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.334480057620348840779083594951850982643\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_05d490a75\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_30a03751'\n(0020, 000d) Study Instance UID                  UI: ID_b60172e5c6\n(0020, 000e) Series Instance UID                 UI: ID_837a683449\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -118.538094, 171.509186]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.956305, -0.292372]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.273323071066942611277487868723919030461\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_214861980\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_ceef0912'\n(0020, 000d) Study Instance UID                  UI: ID_2e4825e3eb\n(0020, 000e) Series Instance UID                 UI: ID_e99656d748\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, 9.04862807, 205.979902]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.927183855, -0.374606593]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.120102136935857634283367959548941387170\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0ac7f34ac\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_d0e958be'\n(0020, 000d) Study Instance UID                  UI: ID_f0b4019b12\n(0020, 000e) Series Instance UID                 UI: ID_4cf25a9418\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -135.038, 97.062]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.956305, -0.292372]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.22956198580839075273061743184841153394\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_1d8940d1c\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_141edeee'\n(0020, 000d) Study Instance UID                  UI: ID_aa105414f3\n(0020, 000e) Series Instance UID                 UI: ID_645c34737c\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, -59, 216]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000303422\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_05655396d\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_28d8209b'\n(0020, 000d) Study Instance UID                  UI: ID_7f34fc0c17\n(0020, 000e) Series Instance UID                 UI: ID_138529031e\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-117.5, -3.5, 231.800049]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.462890625, 0.462890625]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000103436\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_068b8e0cb\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_0d564203'\n(0020, 000d) Study Instance UID                  UI: ID_7d48bb3bb4\n(0020, 000e) Series Instance UID                 UI: ID_deedd62574\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-132, -5, 436.900024]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000180339\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_02250b408\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_ac2b07f0'\n(0020, 000d) Study Instance UID                  UI: ID_c99504163b\n(0020, 000e) Series Instance UID                 UI: ID_f4455eec9e\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, -43, 108.400024]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.329080725725683192161407187086272529865\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0353070e1\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_85f6c9bb'\n(0020, 000d) Study Instance UID                  UI: ID_61c0ac9cf8\n(0020, 000e) Series Instance UID                 UI: ID_99b86890f2\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, 6.58884242, 222.994427]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.961261696, -0.275637356]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 174\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.2292990137079688077486778097513756856\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_286c456a8\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_76b85a9a'\n(0020, 000d) Study Instance UID                  UI: ID_120f4b936d\n(0020, 000e) Series Instance UID                 UI: ID_e3f79cddc9\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-107.844, -96.785, 65.008]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.417969, 0.417969]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '50.0'\n(0028, 1051) Window Width                        DS: '100.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.239703737767063079258147873863749814460\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_296d00574\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_934ddfce'\n(0020, 000d) Study Instance UID                  UI: ID_d10bab8da1\n(0020, 000e) Series Instance UID                 UI: ID_71c3f203a9\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-126.408875, -126.408875, 102.500000]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.494750976563, 0.494750976563]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '35.0'\n(0028, 1051) Window Width                        DS: '135.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.214963196299203969658668199714807428207\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_2b4c1c674\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_95b233f2'\n(0020, 000d) Study Instance UID                  UI: ID_8a85a7de9b\n(0020, 000e) Series Instance UID                 UI: ID_8686a27ad8\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, 13, 151.800049]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.234043313931784416054273542151345925105\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_16b437f48\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_d212cb48'\n(0020, 000d) Study Instance UID                  UI: ID_3527e593db\n(0020, 000e) Series Instance UID                 UI: ID_b1247990a5\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -121.097977, 130.814789]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.927184, -0.374607]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000061462\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_1c0a69565\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_e17609bb'\n(0020, 000d) Study Instance UID                  UI: ID_47c0be2c76\n(0020, 000e) Series Instance UID                 UI: ID_23cad09559\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-164.473682, -43.9473686, 70.4000244]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.282506104797395504908470649568142152205\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_044f232c1\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_ecd52975'\n(0020, 000d) Study Instance UID                  UI: ID_821702ce02\n(0020, 000e) Series Instance UID                 UI: ID_67c5f6403c\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -120.000969, 0.409409]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.984808, -0.173648]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000025726\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_00bfd6f34\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_46b12ac1'\n(0020, 000d) Study Instance UID                  UI: ID_f418a41a95\n(0020, 000e) Series Instance UID                 UI: ID_0bd3f66915\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, -2, 163.5]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.257475241376745686969764926298250417924\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_27091500d\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_8ea99099'\n(0020, 000d) Study Instance UID                  UI: ID_e35124c5ac\n(0020, 000e) Series Instance UID                 UI: ID_e947a606c2\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -125.425, 77.972]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.995396, -0.095846]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.282242576550733628719431776651140262004\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_28f83604a\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_fb1ff97a'\n(0020, 000d) Study Instance UID                  UI: ID_e9efa513b1\n(0020, 000e) Series Instance UID                 UI: ID_802485d2ab\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -121.796, 30.566]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.974370, -0.224951]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.140307632163200207607749642545975795218\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_24cc85b38\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_b393cba9'\n(0020, 000d) Study Instance UID                  UI: ID_731af71e64\n(0020, 000e) Series Instance UID                 UI: ID_c586807d57\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, -26.2774491, 150.714517]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.990268069, -0.139173101]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.337402818065131884636228681783252094646\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_00a234556\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_4f1f1821'\n(0020, 000d) Study Instance UID                  UI: ID_58bc9bf20d\n(0020, 000e) Series Instance UID                 UI: ID_100b71ced1\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -155.201, 76.559]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.984808, -0.173648]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.326020323804598679766686422469301963898\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_28bbb4b8a\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_9d434cc8'\n(0020, 000d) Study Instance UID                  UI: ID_9ad64b60f1\n(0020, 000e) Series Instance UID                 UI: ID_b7db8734fe\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -119.225, 93.782]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.995396, -0.095846]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000188347\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0cf5a7fb5\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_39d7d875'\n(0020, 000d) Study Instance UID                  UI: ID_2eb78a29c5\n(0020, 000e) Series Instance UID                 UI: ID_76ca0a45b0\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-147, -31, -243.799957]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.94284946144780382403109232518885395018\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_2375e6165\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_7c3602e4'\n(0020, 000d) Study Instance UID                  UI: ID_1b17dc5809\n(0020, 000e) Series Instance UID                 UI: ID_860df19590\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, 5.50170541, 297.642742]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.933580426, -0.35836795]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.109974652802775630778748177765497418677\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_07453f45c\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_6c10a84b'\n(0020, 000d) Study Instance UID                  UI: ID_def25edec8\n(0020, 000e) Series Instance UID                 UI: ID_d61ce6dd1c\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -124.915, 161.055]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.953717, -0.300706]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 186\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.26554298342268275541256124470752104028\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_06af4ec8a\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_49a7d3d4'\n(0020, 000d) Study Instance UID                  UI: ID_8b88e06d4b\n(0020, 000e) Series Instance UID                 UI: ID_24ed7b0fc5\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -121.518456, 72.749062]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.968148, -0.250380]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.166093996325893500739959734417682634810\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_02891f036\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_079b052f'\n(0020, 000d) Study Instance UID                  UI: ID_e8af45b175\n(0020, 000e) Series Instance UID                 UI: ID_2ba1fd8358\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-126.437378, -126.437378, -2.500000]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.494863, 0.494863]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '35.0'\n(0028, 1051) Window Width                        DS: '135.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.249415396491581320612126903337742863100\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_019a19707\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_f938d4b0'\n(0020, 000d) Study Instance UID                  UI: ID_a3b184e958\n(0020, 000e) Series Instance UID                 UI: ID_0c036423d7\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -116.698, 104.207]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.933580, -0.358368]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.44447275637879309668856287664707341140\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_052b45b0f\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_c6cb330b'\n(0020, 000d) Study Instance UID                  UI: ID_eb12533d03\n(0020, 000e) Series Instance UID                 UI: ID_dd2811117e\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-126.408875, -126.408875, -334.200623]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.494750976563, 0.494750976563]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '35.0'\n(0028, 1051) Window Width                        DS: '135.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 186\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.84768984953436574860421908862859487686\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_038469f83\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_bf201329'\n(0020, 000d) Study Instance UID                  UI: ID_1a76e12a6a\n(0020, 000e) Series Instance UID                 UI: ID_8fbbcbc485\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -108.197983, 124.137497]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.927184, -0.374607]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.134300559695589632314268077937938193468\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_08126532f\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_b9ef3244'\n(0020, 000d) Study Instance UID                  UI: ID_bf37a88ce0\n(0020, 000e) Series Instance UID                 UI: ID_f223262673\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -120.741, 144.190]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.965926, -0.258819]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000139745\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_053f1cdae\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_a990e72b'\n(0020, 000d) Study Instance UID                  UI: ID_d6909b4621\n(0020, 000e) Series Instance UID                 UI: ID_2cc5aea938\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-122.5, -13.5, 148.699951]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.478515625, 0.478515625]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.25680319092244556427085411561156642710\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0d758736c\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_bf703ef7'\n(0020, 000d) Study Instance UID                  UI: ID_0df04c34a5\n(0020, 000e) Series Instance UID                 UI: ID_11b6a4ac4e\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -116.230186, 17.099262]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.942641, -0.333807]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '120.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.332911472004828230880864565673274687128\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_27deaf726\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_04b8f708'\n(0020, 000d) Study Instance UID                  UI: ID_65ef69c730\n(0020, 000e) Series Instance UID                 UI: ID_30b565faee\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-115.700, -118.882, 112.671]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.951057, -0.309017]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.233181781079462196604288632056668325290\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_184b94be3\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_f4f7a9a6'\n(0020, 000d) Study Instance UID                  UI: ID_f5bdb6f7ba\n(0020, 000e) Series Instance UID                 UI: ID_d113ef4f71\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -136.787, 142.851]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.970296, -0.241922]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.284921993198915369427694728973906485739\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_027ba4636\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_ae5c7e4a'\n(0020, 000d) Study Instance UID                  UI: ID_135c953ca0\n(0020, 000e) Series Instance UID                 UI: ID_7258182665\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -125.415, 40.043]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.953717, -0.300706]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '100.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.102322607369466394097197363730348845184\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_09294d7fb\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_413a205e'\n(0020, 000d) Study Instance UID                  UI: ID_ba6286d01e\n(0020, 000e) Series Instance UID                 UI: ID_c3d12a5b00\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -109.758, 63.633]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.961262, -0.275637]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.11334915109629900358727533305899763327\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0dc868d02\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_39974c92'\n(0020, 000d) Study Instance UID                  UI: ID_7df34b5fc1\n(0020, 000e) Series Instance UID                 UI: ID_5e8f770d55\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -119.215, 47.523]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.953717, -0.300706]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 186\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.83189951186191227299826744456265434565\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_01f4c3e4b\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_16a23d6a'\n(0020, 000d) Study Instance UID                  UI: ID_869c73896d\n(0020, 000e) Series Instance UID                 UI: ID_03f9ecf2b6\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -115.897980, 171.888504]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.927184, -0.374607]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.75984486363380990972968535544712108644\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_28f964007\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_05ec6b2e'\n(0020, 000d) Study Instance UID                  UI: ID_bb525159f3\n(0020, 000e) Series Instance UID                 UI: ID_968bef18e4\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-126.438, -126.438, -432.190]\n(0020, 0037) Image Orientation (Patient)         DS: [1.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.4949, 0.4949]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '35.0'\n(0028, 1051) Window Width                        DS: '135.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000163365\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_039032212\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_56d2a0e3'\n(0020, 000d) Study Instance UID                  UI: ID_79876635bb\n(0020, 000e) Series Instance UID                 UI: ID_9e6c2674df\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, -10, 113]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.65517233576327007521756558430419634012\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_17f45d0c1\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_b4ecbf05'\n(0020, 000d) Study Instance UID                  UI: ID_9d2576346b\n(0020, 000e) Series Instance UID                 UI: ID_c4ee150a07\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, 32.0958836, 181.25721]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.920504853, -0.390731128]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.208299040643567095465146530901426786285\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_00aa77b02\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_6ba93da8'\n(0020, 000d) Study Instance UID                  UI: ID_3188a299a9\n(0020, 000e) Series Instance UID                 UI: ID_d466774275\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-126.437378, -126.437378, -233.525787]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.494863, 0.494863]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '35.0'\n(0028, 1051) Window Width                        DS: '135.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000175682\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_03d828662\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_7bbf4a91'\n(0020, 000d) Study Instance UID                  UI: ID_93fdf86e04\n(0020, 000e) Series Instance UID                 UI: ID_c6f35ad8cc\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-124.5, -15.5, 146.699951]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.486328125, 0.486328125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.257076691680286919789380424022231557507\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0b245b760\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_5ae36db5'\n(0020, 000d) Study Instance UID                  UI: ID_17014b11f1\n(0020, 000e) Series Instance UID                 UI: ID_fac62d4a0c\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -142.515, 79.337]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.994522, -0.104528]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.188621736256590587120297839407119190778\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_019901b86\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_5a7e1077'\n(0020, 000d) Study Instance UID                  UI: ID_0a7b931817\n(0020, 000e) Series Instance UID                 UI: ID_17ba753f7e\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -109.697983, 110.210861]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.927184, -0.374607]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.279339755283610199904680168538987984919\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_201276b5a\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_0aaccb0b'\n(0020, 000d) Study Instance UID                  UI: ID_ba69f569f3\n(0020, 000e) Series Instance UID                 UI: ID_91e2ccf2a8\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, 40.6339087, 27.0702026]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.913545458, -0.406736643]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00047, 00047]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.236013527605439802962314001396335575500\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0508c67fd\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_b2dbfd2b'\n(0020, 000d) Study Instance UID                  UI: ID_307f25f387\n(0020, 000e) Series Instance UID                 UI: ID_d67abba35d\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -138.433, 79.226]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.917060, -0.398749]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 10000000121667\n(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.3.4\n(0002, 0013) Implementation Version Name         SH: 'RSNA Challenge 2019'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0125fa423\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_926197e9'\n(0020, 000d) Study Instance UID                  UI: ID_ed37e882bc\n(0020, 000e) Series Instance UID                 UI: ID_f1f9f8d7eb\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-116.5, 0.5, 208.099976]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 1, 0]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.455078125, 0.455078125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00036, 00036]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 186\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.97357260401356957768828083156764700733\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_1e0e67a69\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_a678d75a'\n(0020, 000d) Study Instance UID                  UI: ID_69e7109b28\n(0020, 000e) Series Instance UID                 UI: ID_fc502de1b9\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -98.197983, 108.347237]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.927184, -0.374607]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.148223275308884738659159924999886511381\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_21ccfb732\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_0032e9ab'\n(0020, 000d) Study Instance UID                  UI: ID_a1775061a1\n(0020, 000e) Series Instance UID                 UI: ID_ddee0cab29\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-126.408875, -126.408875, -325.756134]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.494750976563, 0.494750976563]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '35.0'\n(0028, 1051) Window Width                        DS: '135.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.196569194980152980612216500677648153659\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_0bf1d5cd0\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_ecd26563'\n(0020, 000d) Study Instance UID                  UI: ID_f4c2bb29bd\n(0020, 000e) Series Instance UID                 UI: ID_15f66eb4b8\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -125.000, 20.250]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.27536209630067798042901596865668388055\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_121216057\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_a226893e'\n(0020, 000d) Study Instance UID                  UI: ID_9bb3b3d7e1\n(0020, 000e) Series Instance UID                 UI: ID_41e3d6a0cc\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -120.158, 70.364]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.961262, -0.275637]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '100.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.239427140765060550734338017807922300656\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_01562df58\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_3e516427'\n(0020, 000d) Study Instance UID                  UI: ID_651e9d47a0\n(0020, 000e) Series Instance UID                 UI: ID_a59287d751\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, 53.0550966, 151.659763]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.945518576, -0.325568154]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.266454375605309738080655190284313028222\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_01e87cbb2\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_74a78727'\n(0020, 000d) Study Instance UID                  UI: ID_d8a723cada\n(0020, 000e) Series Instance UID                 UI: ID_412cc55491\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-135.899994, -89.961578, 28.533503]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.939693, -0.342020]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.309875571111284233532200561688870669905\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_044060954\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_0d22c5ac'\n(0020, 000d) Study Instance UID                  UI: ID_2becb8037c\n(0020, 000e) Series Instance UID                 UI: ID_5698b8137a\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -139.590591, 171.122452]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.979925, -0.199368]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.107702611716650583764597018776020806201\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_01e7a9d10\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_d864df2c'\n(0020, 000d) Study Instance UID                  UI: ID_79b8f0df2d\n(0020, 000e) Series Instance UID                 UI: ID_ce91f5b243\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -123.627, 33.003]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.989016, -0.147809]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '40.0'\n(0028, 1051) Window Width                        DS: '150.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.225962732691221708680265216779089678775\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_07a703d80\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_8cef2aec'\n(0020, 000d) Study Instance UID                  UI: ID_633b59b6b9\n(0020, 000e) Series Instance UID                 UI: ID_cf40593c2b\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000, -114.298, 141.492]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.927184, -0.374607]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements, Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 176\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 9999.306623741704233151979433242613804566806\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.38'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_07b3dbc8a\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_8054225b'\n(0020, 000d) Study Instance UID                  UI: ID_5369288e73\n(0020, 000e) Series Instance UID                 UI: ID_3f2ce9052e\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125, 33.8453253, 136.380506]\n(0020, 0037) Image Orientation (Patient)         DS: [1, 0, 0, 0, 0.945518576, -0.325568154]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.48828125, 0.48828125]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 12\n(0028, 0102) High Bit                            US: 11\n(0028, 0103) Pixel Representation                US: 0\n(0028, 1050) Window Center                       DS: [00040, 00040]\n(0028, 1051) Window Width                        DS: [00080, 00080]\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements] with type list","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[142], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a_set \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:825\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[0;32m--> 825\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/util/structure.py:110\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    105\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 110\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m   \u001b[38;5;66;03m# To avoid a circular dependency between dataset_ops and structure,\u001b[39;00m\n\u001b[1;32m    113\u001b[0m   \u001b[38;5;66;03m# we check the class name instead of using `isinstance`.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:696\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    695\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:335\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    333\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    334\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    174\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    176\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:284\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    283\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 284\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    288\u001b[0m )\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:296\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    293\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    294\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mValueError\u001b[0m: TypeError: object of type 'DataElement' has no len()\n"],"ename":"ValueError","evalue":"TypeError: object of type 'DataElement' has no len()\n","output_type":"error"}]},{"cell_type":"markdown","source":"# Building Dataloader in keras-3 style\n- For SwAV training, consider multi-crop with high-res and low-res","metadata":{}},{"cell_type":"code","source":"RescaleIntercept = tfio.image.dicom_tags.RescaleIntercept\nRescaleSlope = tfio.image.dicom_tags.RescaleSlope\nWindowCenter = tfio.image.dicom_tags.WindowCenter\nWindowWidth = tfio.image.dicom_tags.WindowWidth\npix_data = tfio.image.dicom_tags.PixelData","metadata":{"execution":{"iopub.status.busy":"2024-04-17T17:47:15.669713Z","iopub.execute_input":"2024-04-17T17:47:15.670108Z","iopub.status.idle":"2024-04-17T17:47:15.676596Z","shell.execute_reply.started":"2024-04-17T17:47:15.670079Z","shell.execute_reply":"2024-04-17T17:47:15.675243Z"},"trusted":true},"execution_count":268,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-17T17:48:36.734877Z","iopub.execute_input":"2024-04-17T17:48:36.735656Z","iopub.status.idle":"2024-04-17T17:48:36.744046Z","shell.execute_reply.started":"2024-04-17T17:48:36.735612Z","shell.execute_reply":"2024-04-17T17:48:36.742851Z"},"trusted":true},"execution_count":273,"outputs":[{"execution_count":273,"output_type":"execute_result","data":{"text/plain":"Dataset.file_meta -------------------------------\n(0002, 0000) File Meta Information Group Length  UL: 188\n(0002, 0001) File Meta Information Version       OB: b'\\x00\\x01'\n(0002, 0002) Media Storage SOP Class UID         UI: CT Image Storage\n(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.840.4267.32.162913613590029796866673494045672074853\n(0002, 0010) Transfer Syntax UID                 UI: Explicit VR Little Endian\n(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n(0002, 0013) Implementation Version Name         SH: 'dcm4che-1.4.35'\n-------------------------------------------------\n(0008, 0018) SOP Instance UID                    UI: ID_000039fa0\n(0008, 0060) Modality                            CS: 'CT'\n(0010, 0020) Patient ID                          LO: 'ID_eeaf99e7'\n(0020, 000d) Study Instance UID                  UI: ID_134d398b61\n(0020, 000e) Series Instance UID                 UI: ID_5f8484c3e0\n(0020, 0010) Study ID                            SH: ''\n(0020, 0032) Image Position (Patient)            DS: [-125.000000, -141.318451, 62.720940]\n(0020, 0037) Image Orientation (Patient)         DS: [1.000000, 0.000000, 0.000000, 0.000000, 0.968148, -0.250380]\n(0028, 0002) Samples per Pixel                   US: 1\n(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n(0028, 0010) Rows                                US: 512\n(0028, 0011) Columns                             US: 512\n(0028, 0030) Pixel Spacing                       DS: [0.488281, 0.488281]\n(0028, 0100) Bits Allocated                      US: 16\n(0028, 0101) Bits Stored                         US: 16\n(0028, 0102) High Bit                            US: 15\n(0028, 0103) Pixel Representation                US: 1\n(0028, 1050) Window Center                       DS: '30.0'\n(0028, 1051) Window Width                        DS: '80.0'\n(0028, 1052) Rescale Intercept                   DS: '-1024.0'\n(0028, 1053) Rescale Slope                       DS: '1.0'\n(7fe0, 0010) Pixel Data                          OW: Array of 524288 elements"},"metadata":{}}]},{"cell_type":"code","source":"def get_dicom_tensor(path, res):\n    image_bytes = tf.io.read_file(path)\n    lossy_image = tfio.image.decode_dicom_image(image_bytes, scale='preserve', \n                                                on_error='lossy', dtype=tf.float16)[0]\n    lossy_image = tf.cast(lossy_image, \"int16\")\n    print(ops.min(lossy_image), ops.max(lossy_image))\n    intercept, slope, center, width = tfio.image.decode_dicom_data(image_bytes, tags=RescaleIntercept), tfio.image.decode_dicom_data(image_bytes, tags=RescaleSlope), tfio.image.decode_dicom_data(image_bytes, tags=WindowCenter), tfio.image.decode_dicom_data(image_bytes, tags=WindowWidth)\n    intercept, slope, center, width = tf.strings.to_number(intercept, tf.int32), tf.strings.to_number(slope, tf.int32), tf.strings.to_number(center, tf.int32), tf.strings.to_number(width, tf.int32)\n    intercept, slope, center, width = [tf.cast(c, tf.int16) for c in [intercept, slope, center, width]]\n    \n    tensor = slope*lossy_image + intercept\n    lbound = center - tf.cast(width/2, tf.float32)\n    ubound = center + tf.cast(width/2, tf.float32)\n    tensor = ops.clip(tensor, lbound, ubound)\n    \n    tensor = tf.image.resize_with_pad(tensor, res, res)\n    tensor = (tensor - tf.reduce_min(tensor)) / (tf.reduce_max(tensor) - tf.reduce_min(tensor) + 1e-4) #HU unit to Uint8\n    tensor = ops.cast(tensor*255.0, \"uint8\")\n    \n    return tensor\nplt.imshow(get_dicom_tensor(\"/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/ID_000039fa0.dcm\",\n                res = res))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T17:45:08.787110Z","iopub.execute_input":"2024-04-17T17:45:08.787587Z","iopub.status.idle":"2024-04-17T17:45:09.002533Z","shell.execute_reply.started":"2024-04-17T17:45:08.787532Z","shell.execute_reply":"2024-04-17T17:45:09.000632Z"},"trusted":true},"execution_count":266,"outputs":[{"name":"stdout","text":"tf.Tensor(-32768, shape=(), dtype=int16) tf.Tensor(32767, shape=(), dtype=int16)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[266], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(tensor\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m255.0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n\u001b[0;32m---> 21\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mget_dicom_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/ID_000039fa0.dcm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                \u001b[49m\u001b[43mres\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mres\u001b[49m\u001b[43m)\u001b[49m)\n","Cell \u001b[0;32mIn[266], line 12\u001b[0m, in \u001b[0;36mget_dicom_tensor\u001b[0;34m(path, res)\u001b[0m\n\u001b[1;32m      9\u001b[0m intercept, slope, center, width \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mcast(c, tf\u001b[38;5;241m.\u001b[39mint16) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m [intercept, slope, center, width]]\n\u001b[1;32m     11\u001b[0m tensor \u001b[38;5;241m=\u001b[39m slope\u001b[38;5;241m*\u001b[39mlossy_image \u001b[38;5;241m+\u001b[39m intercept\n\u001b[0;32m---> 12\u001b[0m lbound \u001b[38;5;241m=\u001b[39m \u001b[43mcenter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m ubound \u001b[38;5;241m=\u001b[39m center \u001b[38;5;241m+\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     14\u001b[0m tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mclip(tensor, lbound, ubound)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Sub as input #1(zero-based) was expected to be a int16 tensor but is a float tensor [Op:Sub] name: "],"ename":"InvalidArgumentError","evalue":"cannot compute Sub as input #1(zero-based) was expected to be a int16 tensor but is a float tensor [Op:Sub] name: ","output_type":"error"}]},{"cell_type":"code","source":"dataset = pydicom.dcmread(\"/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/ID_000039fa0.dcm\")\ntensor = np.array(dataset.pixel_array)\nprint(ops.min(tensor), ops.max(tensor), tensor.dtype)\nslope = dataset.RescaleSlope   # dicom header (Rescale slope)\nintercept = dataset.RescaleIntercept   # dicom header (Rescale intercept)\ncenter = dataset.WindowCenter   # dicom header (Window center)\nwidth = dataset.WindowWidth   # dicom header (Window width)\ntensor = slope*tensor + intercept\nlbound, ubound = center - 0.5*width, center + 0.5*width\nprint(intercept, slope, center, width)\nops.min(tensor), ops.max(tensor)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T17:43:47.431185Z","iopub.execute_input":"2024-04-17T17:43:47.431621Z","iopub.status.idle":"2024-04-17T17:43:47.455624Z","shell.execute_reply.started":"2024-04-17T17:43:47.431579Z","shell.execute_reply":"2024-04-17T17:43:47.454548Z"},"trusted":true},"execution_count":259,"outputs":[{"name":"stdout","text":"tf.Tensor(-2000, shape=(), dtype=int16) tf.Tensor(2848, shape=(), dtype=int16) int16\n-1024 1 30 80\n","output_type":"stream"},{"execution_count":259,"output_type":"execute_result","data":{"text/plain":"(<tf.Tensor: shape=(), dtype=float64, numpy=-3024.0>,\n <tf.Tensor: shape=(), dtype=float64, numpy=1824.0>)"},"metadata":{}}]},{"cell_type":"code","source":"@tf.py_function(Tout=tf.uint8)\ndef dicom_to_tensor(dicom_path, res):\n        dataset = pydicom.dcmread(dicom_path)\n        tensor = np.array(dataset.pixel_array)\n        slope = dataset.RescaleSlope   # dicom header (Rescale slope)\n        intercept = dataset.RescaleIntercept   # dicom header (Rescale intercept)\n        center = dataset.WindowCenter   # dicom header (Window center)\n        width = dataset.WindowWidth   # dicom header (Window width)\n\n        if(type(dataset.WindowCenter) == pydicom.multival.MultiValue):\n                center = float(dataset.WindowCenter[0])\n                width = float(dataset.WindowWidth[0])       \n        else:    \n                center = float(dataset.WindowCenter)\n                width = float(dataset.WindowWidth)\n\n        tensor = slope*tensor + intercept\n        lbound, ubound = center - 0.5*width, center + 0.5*width\n        tensor[np.where(tensor < lbound)] = lbound\n        tensor[np.where(tensor > ubound)] = ubound\n        tensor = tf.image.resize(tensor[:,:,tf.newaxis], [res,res]) #HU unit\n        if tf.shape(tensor)[-1] == 1 :#gray\n            tensor = tf.image.grayscale_to_rgb(tensor)\n            \n        tensor = (tensor - tf.reduce_min(tensor)) / (tf.reduce_max(tensor) - tf.reduce_min(tensor)) #HU unit to Uint8\n        tensor = ops.cast(tensor*255.0, \"uint8\")\n        \n        try:\n            del dataset\n        except:\n            pass\n        return tensor\n    \n@tf.py_function(Tout=tf.uint8)\ndef image_to_tensor(path, res):\n        if tf.strings.split(path, sep = '.')[-1] == \"dicom\" or tf.strings.split(path, sep = '.')[-1] == \"dcm\":\n            return dicom_to_tensor(path, res)\n        else:\n            img_bytes_ = tf.io.read_file(path)\n            \n            if \"minideeplesion\" in tf.strings.split(path, sep = '/'):\n                image = tf.io.decode_png(img_bytes_)-32768\n                image = tf.clip_by_value(image, -1000, 700)\n                image = ops.cast(image, \"float32\")\n            else:           \n                image = tf.io.decode_png(img_bytes_)\n                image = ops.cast(image, \"float32\")\n                \n            image = tf.image.resize_with_pad(image, res, res)\n            image = (image - ops.min(image))/(ops.max(image) - ops.min(image) + 1e-3)\n            image = image * 255.0\n            if ops.shape(image)[-1] == 1 :#gray\n                image = tf.image.grayscale_to_rgb(image)\n            image = ops.cast(image, \"uint8\")\n            \n        return image\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:35:00.507029Z","iopub.execute_input":"2024-04-17T16:35:00.507501Z","iopub.status.idle":"2024-04-17T16:35:00.724698Z","shell.execute_reply.started":"2024-04-17T16:35:00.507468Z","shell.execute_reply":"2024-04-17T16:35:00.721192Z"},"trusted":true},"execution_count":139,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[139], line 60\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m image\n\u001b[1;32m     59\u001b[0m train_ds_ \u001b[38;5;241m=\u001b[39m train_path_loader\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x : image_to_tensor(x, res))\u001b[38;5;241m.\u001b[39mbatch(\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m train_ds_\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m img:\n\u001b[1;32m     62\u001b[0m         plt\u001b[38;5;241m.\u001b[39mimshow(image)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3029\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3029\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3031\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} InvalidArgumentError: {{function_node __wrapped__EagerPyFunc_Tin_2_Tout_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: dcmread: Expected a file path or a file-like, but got EagerTensor\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_33/1097243612.py\", line 3, in dicom_to_tensor\n    dataset = pydicom.dcmread(dicom_path)\n\n  File \"/opt/conda/lib/python3.10/site-packages/pydicom/filereader.py\", line 1004, in dcmread\n    raise TypeError(\"dcmread: Expected a file path or a file-like, \"\n\nTypeError: dcmread: Expected a file path or a file-like, but got EagerTensor\n\n [Op:EagerPyFunc] name: \nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_33/1097243612.py\", line 37, in image_to_tensor\n    return dicom_to_tensor(path, res)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 444, in py_function_wrapper\n    return script_op(fun, inp=args, Tout=Tout, **kwargs)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 5883, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__EagerPyFunc_Tin_2_Tout_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: dcmread: Expected a file path or a file-like, but got EagerTensor\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_33/1097243612.py\", line 3, in dicom_to_tensor\n    dataset = pydicom.dcmread(dicom_path)\n\n  File \"/opt/conda/lib/python3.10/site-packages/pydicom/filereader.py\", line 1004, in dcmread\n    raise TypeError(\"dcmread: Expected a file path or a file-like, \"\n\nTypeError: dcmread: Expected a file path or a file-like, but got EagerTensor\n\n [Op:EagerPyFunc] name: \n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: "],"ename":"UnknownError","evalue":"{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} InvalidArgumentError: {{function_node __wrapped__EagerPyFunc_Tin_2_Tout_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: dcmread: Expected a file path or a file-like, but got EagerTensor\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_33/1097243612.py\", line 3, in dicom_to_tensor\n    dataset = pydicom.dcmread(dicom_path)\n\n  File \"/opt/conda/lib/python3.10/site-packages/pydicom/filereader.py\", line 1004, in dcmread\n    raise TypeError(\"dcmread: Expected a file path or a file-like, \"\n\nTypeError: dcmread: Expected a file path or a file-like, but got EagerTensor\n\n [Op:EagerPyFunc] name: \nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_33/1097243612.py\", line 37, in image_to_tensor\n    return dicom_to_tensor(path, res)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 444, in py_function_wrapper\n    return script_op(fun, inp=args, Tout=Tout, **kwargs)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py\", line 5883, in raise_from_not_ok_status\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__EagerPyFunc_Tin_2_Tout_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: dcmread: Expected a file path or a file-like, but got EagerTensor\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/tmp/ipykernel_33/1097243612.py\", line 3, in dicom_to_tensor\n    dataset = pydicom.dcmread(dicom_path)\n\n  File \"/opt/conda/lib/python3.10/site-packages/pydicom/filereader.py\", line 1004, in dcmread\n    raise TypeError(\"dcmread: Expected a file path or a file-like, \"\n\nTypeError: dcmread: Expected a file path or a file-like, but got EagerTensor\n\n [Op:EagerPyFunc] name: \n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: ","output_type":"error"}]},{"cell_type":"code","source":"image_bytes = tf.io.read_file(\"/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/ID_000012eaf.dcm\")\nimage = tfio.image.decode_dicom_image(image_bytes, scale='auto', on_error='lossy', dtype=tf.uint8)\nimage = tf.clip_by_value(image, -1000, 1000)\nimage = tf.image.resize_with_pad(image, res, res)\nimage = tf.image.grayscale_to_rgb(image)\nimage = (image - ops.min(image))/(ops.max(image) - ops.min(image) + 1e-3)\nimage = image * 255.0\nplt.imshow(ops.cast(image[0],\n                   \"uint8\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:23:07.353891Z","iopub.execute_input":"2024-04-17T16:23:07.354509Z","iopub.status.idle":"2024-04-17T16:23:07.736779Z","shell.execute_reply.started":"2024-04-17T16:23:07.354477Z","shell.execute_reply":"2024-04-17T16:23:07.735285Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7e0f68a476a0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-17T16:27:46.101421Z","iopub.execute_input":"2024-04-17T16:27:46.101889Z","iopub.status.idle":"2024-04-17T16:27:46.633686Z","shell.execute_reply.started":"2024-04-17T16:27:46.101847Z","shell.execute_reply":"2024-04-17T16:27:46.631688Z"},"trusted":true},"execution_count":129,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[129], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_ds_ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_path_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_to_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m train_ds_:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(img)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2280\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n","File \u001b[0;32m/tmp/__autograph_generated_fileri24csb_.py:78\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__image_to_tensor\u001b[0;34m(path, res)\u001b[0m\n\u001b[1;32m     76\u001b[0m img_bytes_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_bytes_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     77\u001b[0m image \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mor_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdicom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdcm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdo_return\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mretval_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fscope\u001b[38;5;241m.\u001b[39mret(retval_, do_return)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/operators/control_flow.py:1215\u001b[0m, in \u001b[0;36mif_stmt\u001b[0;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;66;03m# Note: tf.cond doesn't support SparseTensor.\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mis_dense_tensor(cond):\n\u001b[0;32m-> 1215\u001b[0m   \u001b[43m_tf_if_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morelse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnouts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1217\u001b[0m   _py_if_stmt(cond, body, orelse)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/operators/control_flow.py:1261\u001b[0m, in \u001b[0;36m_tf_if_stmt\u001b[0;34m(cond, body, orelse, get_state, set_state, symbol_names, nouts)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     _verify_tf_cond_vars(new_body_vars_[\u001b[38;5;241m0\u001b[39m], new_orelse_vars, symbol_names)\n\u001b[1;32m   1259\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m new_orelse_vars\n\u001b[0;32m-> 1261\u001b[0m final_cond_vars \u001b[38;5;241m=\u001b[39m \u001b[43mtf_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maug_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maug_orelse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1263\u001b[0m final_cond_vars \u001b[38;5;241m=\u001b[39m final_cond_vars \u001b[38;5;241m+\u001b[39m init_vars[nouts:]\n\u001b[1;32m   1265\u001b[0m set_state(final_cond_vars)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_fileri24csb_.py:22\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__image_to_tensor.<locals>.if_body_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(dicom_to_tensor), (ag__\u001b[38;5;241m.\u001b[39mld(path),), \u001b[38;5;28mdict\u001b[39m(res\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(res)), fscope)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_33/3597077337.py\", line 37, in image_to_tensor  *\n        return dicom_to_tensor(path, res = res)\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__py_function_wrapper() got an unexpected keyword argument 'res'\n"],"ename":"TypeError","evalue":"in user code:\n\n    File \"/tmp/ipykernel_33/3597077337.py\", line 37, in image_to_tensor  *\n        return dicom_to_tensor(path, res = res)\n\n    TypeError: outer_factory.<locals>.inner_factory.<locals>.tf__py_function_wrapper() got an unexpected keyword argument 'res'\n","output_type":"error"}]},{"cell_type":"code","source":"class ImageDataLoader(keras.utils.Sequence):\n    def __init__(self, dataframe, x_col, res, batch_size, y_col = None, shuffle = True):\n        self.df = dataframe\n        self.x_col = x_col ; self.y_col = y_col\n        self.res = res\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n    def dicom_to_tensor(self, dicom_path):\n        dataset = pydicom.dcmread(dicom_path)\n        tensor = np.array(dataset.pixel_array)\n        slope = dataset.RescaleSlope   # dicom header (Rescale slope)\n        intercept = dataset.RescaleIntercept   # dicom header (Rescale intercept)\n        center = dataset.WindowCenter   # dicom header (Window center)\n        width = dataset.WindowWidth   # dicom header (Window width)\n\n        if(type(dataset.WindowCenter) == pydicom.multival.MultiValue):\n                center = float(dataset.WindowCenter[0])\n                width = float(dataset.WindowWidth[0])       \n        else:    \n                center = float(dataset.WindowCenter)\n                width = float(dataset.WindowWidth)\n\n        tensor = slope*tensor + intercept\n        lbound, ubound = center - 0.5*width, center + 0.5*width\n        tensor[np.where(tensor < lbound)] = lbound\n        tensor[np.where(tensor > ubound)] = ubound\n        tensor = tf.image.resize(tensor[:,:,tf.newaxis], [self.res,self.res]) #HU unit\n        if tf.shape(tensor)[-1] == 1 :#gray\n            tensor = tf.image.grayscale_to_rgb(tensor)\n            \n        tensor = (tensor - tf.reduce_min(tensor)) / (tf.reduce_max(tensor) - tf.reduce_min(tensor)) #HU unit to Uint8\n        tensor = tensor*255.0\n        tensor = np.array(tensor).astype(np.uint8)\n        try:\n            del dataset\n        except:\n            pass\n        return tensor\n    \n    def image_to_tensor(self, path):\n        if path.split(\".\")[-1] == \"dcm\":\n            return self.dicom_to_tensor(path)\n        \n        if \"minideeplesion\" in str(path).split(\"/\"):\n            image = imread(path).astype(np.float32)-32768\n            image = image[..., tf.newaxis]\n            image = tf.image.resize(image, [self.res, self.res])\n            image = tf.clip_by_value(image, -750.0, 700.0)\n            image = (image - tf.reduce_min(image))/(tf.reduce_max(image) - tf.reduce_min(image) + 1e-3)\n            image = image * 255.0\n        else:           \n            image = load_img(path, target_size = [self.res, self.res])\n            image = img_to_array(image)\n            \n        if tf.shape(image)[-1] == 1 :#gray\n            image = tf.image.grayscale_to_rgb(image)\n            image = np.array(image)\n            \n        image = np.array(image).astype(\"uint8\")\n        return image\n        \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle:\n            np.random.shuffle(self.indexes)\n            \n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def __data_generation(self, img_name):\n        ## path를 받아 img화 및 token화 하여 실제로 Feeding할 데이터를 반환\n        X = []\n        for i, fname in enumerate(img_name):\n            img = self.image_to_tensor(fname)\n            X.append(img)\n        X = np.array(X)\n        return X\n        \n                \n    def __getitem__(self, index):\n        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n        \n        img_name = [self.df.iloc[k].loc[self.x_col] for k in indexes]\n        \n        X = self.__data_generation(img_name)\n        #X = np.array(X).reshape([-1, self.res, self.res, 3])\n        return X\n    \n\ndef get_train_gen():\n    return ImageDataLoader(df_train, x_col = \"file_name\",\n                         res = original_res, batch_size = batch_size)\n\ndef get_val_gen():\n    return ImageDataLoader(df_val, x_col = \"file_name\",\n                         res = original_res, batch_size = batch_size)\ntest_ds = tf.data.Dataset.from_generator(get_val_gen, (tf.uint8), output_shapes = (batch_size, res, res,3) ).repeat()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:48:02.890855Z","iopub.execute_input":"2024-04-17T15:48:02.891719Z","iopub.status.idle":"2024-04-17T15:48:02.954663Z","shell.execute_reply.started":"2024-04-17T15:48:02.891671Z","shell.execute_reply":"2024-04-17T15:48:02.953100Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.data.Dataset.from_generator(get_train_gen, (tf.uint8), output_shapes = (batch_size, res, res,3) ).repeat()\nval_ds = tf.data.Dataset.from_generator(get_val_gen, (tf.uint8), output_shapes = (batch_size, res, res,3) ).repeat()\nprint(\"Original\")\nfor img in train_ds.take(1):\n    for i in img:\n        plt.imshow(i)\n        plt.colorbar()\n        plt.show()\n# Multi-Crop dataset 제작\n# 한 개의 이미지로부터 총 5개의 이미지를 만드는데, 2개는 원본 크기와 같은 high-resolution, \n# 나머지 3개는 작은 resolution \n# 전자는 Sinkhorn 알고리즘으로 Matrix C를 학습시키는 데 사용 (즉, Code Q를 만드는 데 사용)\n# 그렇게 계산한 Matrix C (Code Q)를 후자인 3개의 이미지로부터 encoder가 생성한 feature vector Z로 예측함\n\naug = album.Compose([ \n                     album.CoarseDropout(), album.RandomResizedCrop(res, res,\n                                                                   scale = (0.75, 1),\n                                                                   p=1.0),\n                    album.OneOf([album.HorizontalFlip(p=1),\n                                album.Rotate(limit = 60, p = 1),\n                                album.VerticalFlip(p=1)            \n                                ], p=1),\n                    album.OneOf([album.ColorJitter(), \n                                 album.GaussNoise()],\n                                p = 1.0),\n                    album.CLAHE(p = 1.0),\n                    ]\n                   )\n \naug_low_res = album.Compose([ \n                     album.CoarseDropout(),\n                    album.RandomResizedCrop(small_res, small_res, scale = (0.1, 0.5), p=1.0),\n                    album.OneOf([album.HorizontalFlip(p=1),\n                                album.Rotate(limit = 60, p = 1),\n                                album.VerticalFlip(p=1)            \n                                ], p=1),\n                    album.OneOf([album.ColorJitter(), \n                                 album.GaussNoise()],\n                                p = 1.0),\n                    album.CLAHE(p = 1.0),\n                    ]\n                   )    \n\ndef aug_fn(image):\n    high_resolution_set = []\n    low_resolution_set = []\n    for idx in highres_idx:\n        aug_data = aug(image = image)\n        aug_img = aug_data['image']\n        aug_img = np.array(aug_img).astype(np.uint8)\n        high_resolution_set.append(aug_img)\n        del aug_img\n    for idx in lowres_idx:\n        aug_data = aug_low_res(image = image)\n        aug_img = aug_data['image']\n        aug_img = np.array(aug_img).astype(np.uint8)\n        high_resolution_set.append(aug_img)\n        del aug_img\n    result = high_resolution_set + low_resolution_set\n    return result\n\n\ndef swav_preprocess_data(image):\n    data = tf.numpy_function(func = aug_fn, inp = [image], \n                                Tout = ([tf.uint8 for _ in range(n_tot)])\n                               )\n    \n    return data\n\ntrain_ds = train_ds.unbatch().map(swav_preprocess_data, num_parallel_calls = tf.data.AUTOTUNE).batch(batch_size = batch_size).prefetch(tf.data.AUTOTUNE)\ntrain_ds = train_ds.repeat()\nval_ds = val_ds.unbatch().map(swav_preprocess_data, num_parallel_calls = tf.data.AUTOTUNE).batch(batch_size = batch_size).prefetch(tf.data.AUTOTUNE)\nval_ds = val_ds.repeat()\n\nfor imgset in train_ds.take(1):\n    data = imgset\n    for sub_img in data:\n        print(sub_img.shape)\n        \nfor show_n in range(batch_size):\n    fig, axes = plt.subplots(1, len(highres_idx), figsize = (10, 20))\n    axes = axes.flatten()\n    for idx, ax in zip(highres_idx, axes):\n        ax.imshow(data[idx][show_n])\n        ax.set_title(f\"Image index : {idx}\")\n\n    plt.show()\n\n    fig, axes = plt.subplots(2, len(lowres_idx)//2, figsize = (12,8))\n    axes = axes.flatten()\n    for idx, ax in zip(lowres_idx, axes):\n        ax.imshow(data[idx][show_n])\n        ax.set_title(f\"Image index : {idx}\")\n\n    plt.show()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-17T15:48:06.197771Z","iopub.execute_input":"2024-04-17T15:48:06.198164Z","iopub.status.idle":"2024-04-17T15:49:03.201720Z","shell.execute_reply.started":"2024-04-17T15:48:06.198133Z","shell.execute_reply":"2024-04-17T15:49:03.200210Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Original\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","Cell \u001b[0;32mIn[40], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_generator(get_val_gen, (tf\u001b[38;5;241m.\u001b[39muint8), output_shapes \u001b[38;5;241m=\u001b[39m (batch_size, res, res,\u001b[38;5;241m3\u001b[39m) )\u001b[38;5;241m.\u001b[39mrepeat()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m train_ds\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m img:\n\u001b[1;32m      6\u001b[0m         plt\u001b[38;5;241m.\u001b[39mimshow(i)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    809\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 773\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3029\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3028\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3029\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3031\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (32, 384, 384) + inhomogeneous part.\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 171, in __iter__\n    yield self[i]\n\n  File \"/tmp/ipykernel_33/2060988821.py\", line 88, in __getitem__\n    X = self.__data_generation(img_name)\n\n  File \"/tmp/ipykernel_33/2060988821.py\", line 79, in __data_generation\n    X = np.array(X)\n\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (32, 384, 384) + inhomogeneous part.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "],"ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (32, 384, 384) + inhomogeneous part.\nTraceback (most recent call last):\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 270, in __call__\n    ret = func(*args)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 171, in __iter__\n    yield self[i]\n\n  File \"/tmp/ipykernel_33/2060988821.py\", line 88, in __getitem__\n    X = self.__data_generation(img_name)\n\n  File \"/tmp/ipykernel_33/2060988821.py\", line 79, in __data_generation\n    X = np.array(X)\n\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 3 dimensions. The detected shape was (32, 384, 384) + inhomogeneous part.\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ","output_type":"error"}]},{"cell_type":"markdown","source":"# Teacher and Student network modeling\n- SwAV이나 다른 네트워크와는 다르게, DINO는 Student와 teacher 모두 정확히 동일한 network 구조를 가짐\n- image input을 받아 K-dimension feature vector를 생성하는 모델","metadata":{}},{"cell_type":"code","source":"# transformer base\ndef get_vision_transformer(patch_size,\n                           att_depth,\n                          att_dims, att_heads, K_dims = K_dims,\n                          use_local_attention = False):\n    # Get Adjusted Vision Transformer base\n    \n    model_name = f\"ViT{patch_size}_depth{att_depth}_with_{att_heads}heads\"\n    inputs = Input([None,None,3], name = \"ImageInput\")\n    scaled_inputs = inputs/255\n    patches = Conv2D(filters = att_dims, kernel_size = patch_size, strides = patch_size, padding = \"SAME\", name = f\"Patching_Convolution_PatchSize{patch_size}\")(scaled_inputs)\n    patches = LayerNormalization()(patches)\n    patches = Activation(\"gelu\", name = \"PatchAct\")(patches)\n    \n    batch_size = tf.shape(inputs)[0]\n    patch_dims = patches.shape[-1]\n    patches = tf.reshape(patches, [batch_size, -1, patch_dims]) #batch_size, seq_len, patch_dims\n    seq_len = tf.shape(patches)[1]\n    \n    class_token = tf.random.normal([batch_size, 1, patch_dims])\n    patches = tf.concat([class_token, patches],\n                       axis = 1) #batch_size, seq_len+1, patch_dims\n    \n    #positional encoding, learnable\n    pos_info = tf.random.normal([1, seq_len+1, patch_dims])/(tf.math.sqrt(tf.cast(patch_dims, tf.float32)))\n    encoded_patches = patches + pos_info\n    #encoded_patches = patches\n    \n    # Optional) local attention : patch간 attention시 자기 자신에 관한 attention은 수행하지 않도록\n    attn_mask = 1-tf.eye(seq_len + 1)\n    attn_mask = tf.reshape(attn_mask, [1, seq_len + 1, seq_len + 1])\n    attn_mask = tf.tile(attn_mask, [batch_size, 1, 1])\n    attn_mask = tf.cast(attn_mask, tf.int32 )\n    if use_local_attention:\n        mask = attn_mask\n    else:\n        mask = None\n    #Transformer Encoder block\n    for idx in range(att_depth):\n        \n        x0, attention_score = MultiHeadAttention(att_heads, att_dims)(encoded_patches, \n                                                     encoded_patches, \n                                                    attention_mask = mask,\n                                                     return_attention_scores = True\n                                                    )\n        x1 = x0 + encoded_patches\n        x2 = LayerNormalization()(x1)\n        \n        x3 = Dense(units = 2*att_dims)(x2)\n        x4 = LayerNormalization()(x3)\n        x5 = Activation(\"gelu\")(x4)\n        x6 = Dense(units = att_dims)(x5)\n        x7 = LayerNormalization()(x6)\n        x8 = Activation('gelu')(x7)\n        \n        x9 = x2 + x8\n        encoded_patches = LayerNormalization()(x9)\n    \n    encoded_token = encoded_patches[:, 0, :]\n    encoded_token = tf.reshape(encoded_token, [batch_size, att_dims])\n    proj = get_proj(encoded_token)\n    feature_vector = Dense(units = K_dims, name = \"FinalLinear\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-4, l2=1e-4))(proj)\n    \n    model = Model(inputs = inputs,\n                 outputs = [feature_vector, attention_score],\n                 name = model_name)\n    return model","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-17T15:32:37.374741Z","iopub.status.idle":"2024-04-17T15:32:37.375132Z","shell.execute_reply.started":"2024-04-17T15:32:37.374943Z","shell.execute_reply":"2024-04-17T15:32:37.374960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Visualize the attention scores\n- Attention block을 다 거친 뒤에,\n- 모델이 어디를 보고 있는지를 시각화함 (Code below)","metadata":{}},{"cell_type":"code","source":"batch_n = 1\nhead_n = 3\n\ndef visualize_att_score(score, batch_n, head_n):\n    #input score : batch, heads, (seqlen+1), (seqlen+1) shape tensor\n    example_weight = score[batch_n, head_n, ...]\n    parsed_weight = example_weight[0, 1:] #class token의, (class token을 제외한) 다른 patches(tokens) 간의 attention weight\n    print(f\"Mean of Attention weight between each patches ifself: {tf.reduce_mean(tf.linalg.tensor_diag_part(example_weight))}\")\n    vis_res = tf.math.sqrt(tf.cast(tf.shape(parsed_weight)[-1], tf.float32))\n    \n    parsed_weight = tf.reshape(parsed_weight, [vis_res, vis_res])\n    plt.figure(figsize = (6,6))\n    plt.imshow(parsed_weight)\n    plt.colorbar()\n    plt.title(f\"Attention Weight, img idx{batch_n}, att head idx{head_n}\")\n    plt.show()\n    return parsed_weight","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-17T15:32:37.376385Z","iopub.status.idle":"2024-04-17T15:32:37.377086Z","shell.execute_reply.started":"2024-04-17T15:32:37.376886Z","shell.execute_reply":"2024-04-17T15:32:37.376904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> 중간 점검\n- 각 Head마다 주로 보는 곳이 다름\n    - 어떤 head는 radiopaque한 곳 위주로 (bone, soft tissue)\n    - 어떤 head는 lung tissue 위주로 (radiolucent한 곳 - lung, 배경 등)\n- 거의 같은 크기의 weight -> Dino를 거쳐 정말 중요한 부분에 weight를 극대화하여야 함","metadata":{}},{"cell_type":"code","source":"def sinkhorn(c, temp = 0.05, repeat = 3): #q_example = [batch, K]\n    c = tf.cast(c, tf.float32)\n    q = tf.transpose(tf.exp(c/temp)) #transpose 후 -> [K, batch]\n    # q도 확률 분포여야 함 -> sum of q == 1이 되게 Normalize\n    q /= tf.reduce_sum(q)\n    k, batch = tf.shape(c)[0], tf.shape(c)[1]\n    \n    r = tf.ones_like(k, dtype = tf.float32)/tf.cast(k, dtype = tf.float32) #생산하는 측은 k개의 cluster에 uniform하게 배당될 수 있음\n    c = tf.ones_like(batch, tf.float32)/tf.cast(batch, tf.float32) #수용하는 측은 b개의 생산자로부터 동일한 확률로 (prior가 없음) 받을 수 있음\n    for idx in range(repeat):\n        # 이 때의 목적은, q가 여전히 stochastic하면서\n        # 열 방향의 합과 행 방향의 합 벡터가 각각 (Transpose 이후의 기준으로) 1/batch, 1/k로 채워진 vector가 되게 하는 것\n        u = tf.reduce_sum(q, axis=1) #Q matrix의 행방향 합 -> u는 합이 1인(stochastic한) K-length vector가 된다.\n        u_other = tf.reduce_sum(q, axis = 0)\n        \n        q *= tf.expand_dims((r/u), axis = 1) # Code reference) https://github.com/ayulockin/SwAV-TF/blob/master/Train_SwAV_10_epochs.ipynb\n        q *= tf.expand_dims(c/u_other, axis = 0) #이 과정에서 n번째 \n        \n    # 다시 원래 모양으로 Transpose해 주고, ---(1)\n    # 나아가 Stochastic하게 만듬 -> 출발점에 상관없이,임의의 출발점(Mine, Producer)에서 모든 도착지로 갈 확률을 구한 뒤 합하면 1이 되어야 함\n    # 즉, (transpose한 뒤) 열방향 합으로 나눠, N번째 행의 모든 열 원소의 합이 1이 되게 Normalize. --- (2)\n    final_q = tf.transpose(q) #(1)\n    final_q /= tf.reduce_sum(final_q, axis = -1, keepdims = True) #(2)\n    return final_q","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-04-17T15:32:37.378217Z","iopub.status.idle":"2024-04-17T15:32:37.378644Z","shell.execute_reply.started":"2024-04-17T15:32:37.378417Z","shell.execute_reply":"2024-04-17T15:32:37.378433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> 생각해 볼 점\n- DINO에서 teacher centering을 담당하는 C는 epoch이나 step마다 초기화되는 것이 아님\n- 한 step 즉 dataset에서 한 batch를 받고 loss를 계산한 뒤에 update됨.\n    - fit method를 그대로 쓰지 않고 for loop으로 custom fit cycle을 만들기는 keras 기본 UI나 callback 등이 좋아서 별로 내키지 않음\n    - 그러므로 DINO module을 만들기 전에, 혹은 initialize하면서, random한 one batch에 대해 Center를 계산하고 이것을 update하는 식으로 진행\n    \n- 한 SSL pretrainer module은 다음과 같은 SSL method를 포함:\n    - DINO\n    - SwAV\n    - Barlow twins","metadata":{}},{"cell_type":"markdown","source":"# SwAV implementation","metadata":{}},{"cell_type":"code","source":"class SwAV_module(keras.Model):\n    def __init__(self, \n                 patch_size = patch_size, att_depth = 3, att_dims = 256, att_heads = 8, prototype_c_dim = K_dims, #<-transformer 관련 hyperparameter\n                 conv_base = None, \n                 use_local_attention = False,\n                 t_teacher = t_teacher,\n                 highres_idx = highres_idx, lowres_idx = lowres_idx, **kwargs\n                ):\n        super().__init__(**kwargs)\n        if conv_base is None:\n        #feature extractors\n            self.patch_size = patch_size\n            self.att_depth = att_depth\n            self.att_dims = att_dims\n            self.att_heads = att_heads\n            self.K_dims = prototype_c_dim\n            self.use_local_attention = use_local_attention\n\n            self.teacher = self.get_vision_transformer()\n        else:\n            self.conv = conv_base\n            self.patch_size = 0\n            self.att_depth = 0\n            self.att_dims = 0\n            self.att_heads = 0\n            self.K_dims = prototype_c_dim\n            self.use_local_attention = use_local_attention\n            \n            self.teacher = self.build_conv_base()\n            \n        #hyperparameters\n        self.temp = t_teacher\n        self.highres_idx = highres_idx\n        self.lowres_idx = lowres_idx\n        #datasets\n        self.n_highres = len(highres_idx)\n        self.n_lowres = len(lowres_idx)\n        self.n_tot_view = self.n_highres + self.n_lowres\n        \n        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n        self.collapse_tracker = tf.keras.metrics.Mean(name=\"Entropy\")\n        self.std_tracker = tf.keras.metrics.Mean(name=\"StDev\")\n        \n        self.ce_loss = tf.keras.losses.CategoricalCrossentropy(reduction=\"none\")\n        self.collapse_tracker = tf.keras.metrics.Mean(name=\"Entropy\")\n        self.std_tracker = tf.keras.metrics.Mean(name=\"STDEV\")\n        \n    def build_conv_base(self):\n        conv = self.conv\n        K_dims = self.K_dims\n        try:\n            name = conv.name\n        except:\n            name = \"ConvolutionBaseModel\"\n        inputs = conv.inputs\n        conv_out = conv.output\n        dims = conv_out.shape[-1]\n        #dims = tf.shape(conv_out)[-1]\n        encoded_patches = keras.layers.Reshape([-1, dims], name = \"EncodedPatches\")(conv_out)\n        pool = tf.keras.layers.GlobalAveragePooling1D(name = \"PoolingFromEncodedPatches\")(encoded_patches)\n        proj = get_proj(pool)\n        feature_vector = Dense(units = K_dims, name = \"FinalLinear\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-4, l2=1e-4))(proj)\n\n        return Model(inputs, feature_vector,\n                        name = name)\n\n    def get_vision_transformer(self):\n        # Get Adjusted Vision Transformer base\n        \n        patch_size = self.patch_size\n        att_depth = self.att_depth\n        att_dims = self.att_dims\n        att_heads = self.att_heads \n        K_dims = self.K_dims\n        use_local_attention = self.use_local_attention\n        \n        model_name = f\"ViT{patch_size}_depth{att_depth}_with_{att_heads}heads\"\n        inputs = Input([None,None,3], name = \"ImageInput\")\n        scaled_inputs = inputs/255\n        patches = Conv2D(filters = att_dims, kernel_size = patch_size, strides = patch_size, padding = \"SAME\", name = f\"Patching_Convolution_PatchSize{patch_size}\")(scaled_inputs)\n        patches = LayerNormalization()(patches)\n        patches = Activation(\"gelu\", name = \"PatchAct\")(patches)\n\n        batch_size = tf.shape(inputs)[0]\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch_size, -1, patch_dims]) #batch_size, seq_len, patch_dims\n        seq_len = tf.shape(patches)[1]\n\n        class_token = tf.random.normal([batch_size, 1, patch_dims])\n        patches = tf.concat([class_token, patches],\n                           axis = 1) #batch_size, seq_len+1, patch_dims\n\n        #positional encoding, learnable\n        pos_info = tf.random.normal([1, seq_len+1, patch_dims])\n        encoded_patches = patches + pos_info\n        #encoded_patches = patches\n\n        # Optional) local attention : patch간 attention시 자기 자신에 관한 attention은 수행하지 않도록\n        attn_mask = 1-tf.eye(seq_len + 1)\n        attn_mask = tf.reshape(attn_mask, [1, seq_len + 1, seq_len + 1])\n        attn_mask = tf.tile(attn_mask, [batch_size, 1, 1])\n        attn_mask = tf.cast(attn_mask, tf.int32 )\n        if use_local_attention:\n            mask = attn_mask\n        else:\n            mask = None\n        #Transformer Encoder block\n        for idx in range(att_depth):\n\n            x0, attention_score = MultiHeadAttention(att_heads, att_dims)(encoded_patches, \n                                                         encoded_patches, \n                                                        attention_mask = mask,\n                                                         return_attention_scores = True\n                                                        )\n            x1 = x0 + encoded_patches\n            x2 = LayerNormalization()(x1)\n\n            x3 = Dense(units = att_dims)(x2)\n            x4 = LayerNormalization()(x3)\n            x5 = Activation(\"gelu\")(x4)\n            \n            x6 = x2 + x5\n            if idx == att_depth - 1:\n                layer_name = \"EncodedPatches\"\n            else:\n                layer_name = f\"Feature_Sequence_DepthIdx{idx}\"\n            encoded_patches = LayerNormalization(name = layer_name)(x6)\n\n        encoded_token = encoded_patches[:, 0, :]\n        encoded_token = tf.reshape(encoded_token, [batch_size, att_dims])\n        proj = get_proj(encoded_token)\n        feature_vector = Dense(units = K_dims, name = \"FinalLinear\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-4, l2=1e-4))(proj)\n\n        model = Model(inputs = inputs,\n                     outputs = [feature_vector, attention_score],\n                     name = model_name)\n        return model\n    \n    \n    def get_config(self):\n        return {\"TrainMethod\" : \"SwAV\",\n                \"feature_extractor_name\" : self.teacher.name,\n                \"N_params\" : self.teacher.count_params(),\n                \"patch_size\" : self.patch_size,\n                \"att_depth\" : self.att_depth,\n                \"att_dims\" : self.att_dims,\n                \"att_heads\" : self.att_heads,\n                \"K_dims\" : self.K_dims,\n                \"use_local_attention\" : self.use_local_attention,\n                \"feature_extractor_name\" : self.teacher.name,\n                \"softmax_temperature\" : self.temp,\n                \"Global_view_index\" : self.highres_idx,\n                \"Local_view_index\" : self.lowres_idx\n               }\n    \n    def sinkhorn(self, q_example):\n        q = tf.transpose(tf.exp(q_example/self.temp)) #transpose 후 -> [K, batch]\n        q /= tf.reduce_sum(q)\n        k, batch = tf.shape(q_example)[0], tf.shape(q_example)[1]\n\n        r = tf.ones_like(k, dtype = tf.float32)/tf.cast(k, dtype = tf.float32) #생산하는 측은 k개의 cluster에 uniform하게 배당될 수 있음\n        c = tf.ones_like(batch, tf.float32)/tf.cast(batch, tf.float32) #수용하는 측은 b개의 생산자로부터 동일한 확률로 (prior가 없음) 받을 수 있음\n        for idx in range(3):\n            # 이 때의 목적은, q가 여전히 stochastic하면서\n            # 열 방향의 합과 행 방향의 합 벡터가 각각 (Transpose 이후의 기준으로) 1/batch, 1/k로 채워진 vector가 되게 하는 것\n            u = tf.reduce_sum(q, axis=1) #Q matrix의 행방향 합 -> u는 합이 1인(stochastic한) K-length vector가 된다.\n            u_other = tf.reduce_sum(q, axis = 0)\n\n            q *= tf.expand_dims((r/u), axis = 1) # Code reference) https://github.com/ayulockin/SwAV-TF/blob/master/Train_SwAV_10_epochs.ipynb\n            q *= tf.expand_dims(c/u_other, axis = 0) #이 과정에서 n번째 \n\n        # 다시 원래 모양으로 Transpose해 주고, ---(1)\n        # 나아가 Stochastic하게 만듬 -> 출발점에 상관없이,임의의 출발점(Mine, Producer)에서 모든 도착지로 갈 확률을 구한 뒤 합하면 1이 되어야 함\n        # 즉, (transpose한 뒤) 열방향 합으로 나눠, N번째 행의 모든 열 원소의 합이 1이 되게 Normalize. --- (2)\n        final_q = tf.transpose(q) #(1)\n        final_q /= tf.reduce_sum(final_q, axis = -1, keepdims = True) #(2)\n        return final_q\n    \n    def compute_loss(self, dataset, training = True):\n        \n        feature_output = []\n        \n        for idx in self.highres_idx:\n            if len(self.teacher.outputs) >= 2:\n                f = self.teacher(dataset[idx], training = training)[0]                \n            else:\n                f = self.teacher(dataset[idx], training = training)\n            feature_output.append(f)\n\n        for idx in self.lowres_idx:\n            if len(self.teacher.outputs) >= 2:\n                f = self.teacher(dataset[idx], training = training)[0]\n            else:\n                f = self.teacher(dataset[idx], training = training)\n            feature_output.append(f)\n        \n        # SwAV에서는 feature output이 Prototype C로 작동 (L2 normalize를 거친 K-dimensional vector)\n        prototype = feature_output\n        \n        loss = [] #initialize\n        for idx_global in self.highres_idx:\n            global_prototype = prototype[idx_global]\n            q_global = self.sinkhorn(global_prototype)\n            tf.stop_gradient(q_global) #true 역할을 하는 q는 stop gradient\n            for idx, feature in enumerate(prototype):\n                if idx == idx_global:\n                    continue\n                else:\n                    p = tf.nn.softmax(feature / self.temp, axis = -1)\n                    _loss = self.ce_loss(y_true = q_global, y_pred = p)\n                    _loss = tf.reduce_mean(_loss)\n                    loss.append(_loss)\n        loss = tf.reduce_mean(loss)\n        return loss, tf.concat(feature_output, axis = 0)\n    \n    #2. training and validation loop\n    def train_step(self, dataset, testing_stage = False, training = True):\n        if testing_stage:\n            print(\"Loss Computation\")\n        with tf.GradientTape() as tape:\n            loss, features = self.compute_loss(dataset, training = training)\n        \n        if testing_stage:\n            print(\"Teacher Backpropagation\")\n        training_vars = self.teacher.trainable_variables\n        gradients = tape.gradient(loss, training_vars) #teacher update without momentum encoding\n        self.optimizer.apply_gradients(zip(gradients, training_vars))\n        \n        \n        global_entropy = self.ce_loss(y_true = features, y_pred = features)\n        global_entropy = tf.reduce_mean(global_entropy)\n        std = tf.math.reduce_std(features) \n        self.loss_tracker.update_state(loss)\n        self.collapse_tracker.update_state(global_entropy)\n        self.std_tracker.update_state(std)\n        if testing_stage:\n            print(\"Single training stage over!\")\n            \n        return {\"loss\": self.loss_tracker.result(),\n               \"H_glob_glob\" : self.collapse_tracker.result(),\n               \"std\" : self.std_tracker.result()}\n    \n    def call(self, dataset, training = False): \n        return self.teacher(dataset, training = training)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:37.380428Z","iopub.status.idle":"2024-04-17T15:32:37.380836Z","shell.execute_reply.started":"2024-04-17T15:32:37.380641Z","shell.execute_reply":"2024-04-17T15:32:37.380658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DINO implementation","metadata":{}},{"cell_type":"code","source":"class DINO_module(keras.Model):\n    def __init__(self, conv_base = None, \n                 patch_size = patch_size, att_depth = 3, att_heads = 8, att_dims = 512, use_local_attention = False,\n                 K_dims = K_dims,\n                 t_stu = t_stu, t_teacher = t_teacher,\n                 lamb = lamb, m = m,\n                 highres_idx = highres_idx, lowres_idx = lowres_idx, **kwargs\n                ):\n        super().__init__(**kwargs)\n        #feature extractors\n        if conv_base is None:\n            self.patch_size = patch_size\n            self.att_depth = att_depth\n            self.att_dims = att_dims\n            self.att_heads = att_heads\n            self.K_dims = K_dims\n            self.use_local_attention = use_local_attention\n\n            self.teacher = self.get_vision_transformer()\n            self.student = self.get_vision_transformer()\n        else:\n            self.conv = conv_base\n            self.patch_size = 0\n            self.att_depth = 0\n            self.att_dims = 0\n            self.att_heads = 0\n            self.K_dims = K_dims\n            self.use_local_attention = use_local_attention\n            \n            self.teacher = self.build_conv_base()\n            self.student = self.build_conv_base()\n            \n        \n        #hyperparameters\n        self.k = K_dims\n        self.tps = t_stu\n        self.tpt = t_teacher\n        self.lamb = float(lamb)\n        self.m = m\n        self.highres_idx = highres_idx\n        self.lowres_idx = lowres_idx\n        #datasets\n        self.n_highres = len(highres_idx)\n        self.n_lowres = len(lowres_idx)\n        self.n_tot_view = self.n_highres + self.n_lowres\n        \n        #Basic initializing\n        self.initialize_weight_and_center()\n        \n        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n        self.collapse_tracker = tf.keras.metrics.Mean(name=\"Entropy\")\n        self.std_tracker = tf.keras.metrics.Mean(name=\"Entropy\")\n        \n        self.ce_loss = tf.keras.losses.CategoricalCrossentropy(reduction=\"none\")\n    \n    \n    # Get feature extractors\n    def build_conv_base(self):\n        conv = self.conv\n        K_dims = self.K_dims\n        try:\n            name = conv.name\n        except:\n            name = \"ConvolutionBaseModel\"\n        inputs = conv.inputs\n        conv_out = conv.output\n        dims = conv_out.shape[-1]\n        #dims = tf.shape(conv_out)[-1]\n        encoded_patches = keras.layers.Reshape([-1, dims], name = \"EncodedPatches\")(conv_out)\n        pool = tf.keras.layers.GlobalAveragePooling1D(name = \"PoolingFromEncodedPatches\")(encoded_patches)\n        proj = get_proj(pool)\n        feature_vector = Dense(units = K_dims, name = \"FinalLinear\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-4, l2=1e-4))(proj)\n\n        return Model(inputs, feature_vector,\n                        name = name)\n\n    def get_vision_transformer(self):\n        # Get Adjusted Vision Transformer base\n        \n        patch_size = self.patch_size\n        att_depth = self.att_depth\n        att_dims = self.att_dims\n        att_heads = self.att_heads \n        K_dims = self.K_dims\n        use_local_attention = self.use_local_attention\n        \n        model_name = f\"ViT{patch_size}_depth{att_depth}_with_{att_heads}heads\"\n        inputs = Input([None,None,3], name = \"ImageInput\")\n        scaled_inputs = inputs/255\n        patches = Conv2D(filters = att_dims, kernel_size = patch_size, strides = patch_size, padding = \"SAME\", name = f\"Patching_Convolution_PatchSize{patch_size}\")(scaled_inputs)\n        patches = LayerNormalization()(patches)\n        patches = Activation(\"gelu\", name = \"PatchAct\")(patches)\n\n        batch_size = tf.shape(inputs)[0]\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch_size, -1, patch_dims]) #batch_size, seq_len, patch_dims\n        seq_len = tf.shape(patches)[1]\n\n        class_token = tf.random.normal([batch_size, 1, patch_dims])\n        patches = tf.concat([class_token, patches],\n                           axis = 1) #batch_size, seq_len+1, patch_dims\n\n        #positional encoding, learnable\n        pos_info = tf.random.normal([1, seq_len+1, patch_dims])\n        encoded_patches = patches + pos_info\n        #encoded_patches = patches\n\n        # Optional) local attention : patch간 attention시 자기 자신에 관한 attention은 수행하지 않도록\n        attn_mask = 1-tf.eye(seq_len + 1)\n        attn_mask = tf.reshape(attn_mask, [1, seq_len + 1, seq_len + 1])\n        attn_mask = tf.tile(attn_mask, [batch_size, 1, 1])\n        attn_mask = tf.cast(attn_mask, tf.int32 )\n        if use_local_attention:\n            mask = attn_mask\n        else:\n            mask = None\n        #Transformer Encoder block\n        for idx in range(att_depth):\n\n            x0, attention_score = MultiHeadAttention(att_heads, att_dims)(encoded_patches, \n                                                         encoded_patches, \n                                                        attention_mask = mask,\n                                                         return_attention_scores = True\n                                                        )\n            x1 = x0 + encoded_patches\n            x2 = LayerNormalization()(x1)\n\n            x3 = Dense(units = att_dims)(x2)\n            x4 = LayerNormalization()(x3)\n            x5 = Activation(\"gelu\")(x4)\n            \n            x6 = x2 + x5\n            if idx == att_depth - 1:\n                layer_name = \"EncodedPatches\"\n            else:\n                layer_name = f\"Feature_Sequence_DepthIdx{idx}\"\n            encoded_patches = LayerNormalization(name = layer_name)(x6)\n\n        encoded_token = encoded_patches[:, 0, :]\n        encoded_token = tf.reshape(encoded_token, [batch_size, att_dims])\n        proj = get_proj(encoded_token)\n        feature_vector = Dense(units = K_dims, name = \"FinalLinear\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-4, l2=1e-4))(proj)\n\n        model = Model(inputs = inputs,\n                     outputs = [feature_vector, attention_score],\n                     name = model_name)\n        return model\n    \n    def initialize_weight_and_center(self):\n        # Initially, teacher weight == student weight\n        self.teacher.set_weights(self.student.get_weights())\n        self.C = 0.0    \n    def get_config(self):\n        return {\"TrainMethod\" : \"DINO\",\n                \"feature_extractor_name\" : self.teacher.name,\n                \"N_params\" : self.teacher.count_params(),\n               'patch_size' : self.patch_size, \n                \"K_dims\" : self.k,\n                \"softmax_temperature_student\" : self.tps,\n                \"softmax_temperature_teacher\" : self.tpt,\n               'teacher_weight_lambda': self.lamb,\n                \"centering_rate_parameter_m\" : self.m,\n                \"Global_view_index\" : self.highres_idx,\n                \"Local_view_index\" : self.lowres_idx\n               }\n    \n    \n    def compute_loss(self, dataset, training):\n        #dataset 중 high resolution images는 highres_idx, low resolution images는 lowres_idx에 있음\n        teacher_features = [] #<- for teacher net\n        student_features = [] #<- for student net\n        \n        # Stage 1. teacher and student features 생성\n        # teacher's feature set에는 global feature\n        # student's feature set에는 both global and local feature\n        \n        for idx in self.highres_idx:\n            if len(self.teacher.outputs) >= 2:\n                f = self.teacher(dataset[idx], training = training)[0]\n                f_s = self.student(dataset[idx], training = training)[0]\n                tf.stop_gradient(f)\n            else:\n                f = self.teacher(dataset[idx], training = training)\n                f_s = self.student(dataset[idx], training = training)\n                tf.stop_gradient(f)\n            teacher_features.append(f)\n            student_features.append(f_s)\n            \n        for idx in self.lowres_idx:\n            if len(self.student.outputs) >= 2:\n                f = self.student(dataset[idx], training = training)[0]\n            else:\n                f = self.student(dataset[idx], training = training)\n            student_features.append(f)\n            \n        # Stage 2. loss computation\n        # n_highres = 2라 가정할 때\n        # teacher's features set을 T1, T2 (<- 둘 다 global features)\n        # student's feature set을 S1, S2, ..., Sk (<- S1, S2만 global features)\n        # ce loss를 구하는데, T1과는 S2, S3, S4,..., Sk 간 loss를,\n        # T2와는 S1, S3, S4, ..., Sk 간 loss를 구한 뒤 평균\n        \n        # Global view(teacher)는 stop gradient 및 centering(C with self.m) + sharpening(self.tpt)\n        # student view는 sharpening만 (self.tps)\n        loss = []\n\n        for idx, teacher_f in enumerate(teacher_features):\n            tf.stop_gradient(teacher_f) #batch, K shape tensor\n            #teacher softmax with sharpening and centering\n            teacher_f = tf.nn.softmax((teacher_f - self.C)/self.tpt, axis = -1)\n            for j, student_f in enumerate(student_features):\n                if j == idx:\n                    # if, teacher_features의 첫 번째 feature vector에 대해 loss를 계산할 때,\n                    # student features의 첫 번째 feature vector는,\n                    # teacher features의 첫 번째 feature vector와 같은 view이므로 건너뜀(Loss 계산 X)\n                    continue\n                else:\n                    #print(f\"Troubleshooting, Teacher feature idx {idx} (out of {len(teacher_features)} features) and student feature idx {j} (out of {len(student_features)} features) loss comput.\")\n                    #student softmax with scaling(sharpening, self.tps)\n                    student_f = tf.nn.softmax(student_f/self.tps, axis = -1)\n                    # 각 pair별로 Loss 계산 후 reduce mean\n                    _loss = tf.reduce_mean(self.ce_loss(y_true = teacher_f, #<--이부분 hand-craft해보기\n                                                        y_pred = student_f)\n                                          )\n                    loss.append(_loss)\n\n        loss = tf.reduce_mean(loss)\n        \n        return loss, tf.concat(teacher_features, axis = 0)\n    \n    #2. training and validation loop\n    def train_step(self, dataset, testing_stage = False, training = True):\n        #A. Loss computation\n        if testing_stage:\n            print(\"Loss Computation\")\n        with tf.GradientTape() as tape:\n            loss, teacher_features = self.compute_loss(dataset, training = training)\n        \n        # B. Backpropa to student network\n        if testing_stage:\n            print(\"Backpropagation to student network\")\n        student_vars = self.student.trainable_variables\n        gradients = tape.gradient(loss, student_vars)\n        self.optimizer.apply_gradients(zip(gradients, student_vars))\n        \n        #C. EMA update the teacher variables\n        if testing_stage:\n            print(\"Teacher network update\")\n        \n        w_student_total = self.student.get_weights()\n        w_teacher_total = self.teacher.get_weights()\n        w_teacher_total_new = []\n        for w_t, w_s in zip(w_teacher_total, w_student_total):\n            w_teacher_new = self.lamb * w_t + (1-self.lamb) * w_s\n            w_teacher_total_new.append(w_teacher_new)\n        \n        self.teacher.set_weights(w_teacher_total_new)\n\n        # D. self.C의 EMA식 Update\n        if testing_stage:\n            print(\"Centering value update\")\n        \n        self.C = self.m*self.C + (1-self.m) * (tf.reduce_mean(teacher_features,\n                                                              axis = 0, keepdims = True))\n        if testing_stage:\n            print(\"Single Training step is over!\")\n        \n        global_entropy = self.ce_loss(y_true = teacher_features, y_pred = teacher_features)\n        global_entropy = tf.reduce_mean(global_entropy)\n        std = tf.math.reduce_std(teacher_features) \n        \n        self.loss_tracker.update_state(loss)\n        self.collapse_tracker.update_state(global_entropy)\n        self.std_tracker.update_state(std)\n        \n        return {\"loss\": self.loss_tracker.result(),\n               \"H_glob_glob\" : self.collapse_tracker.result(),\n               \"std\" : self.std_tracker.result()}\n\n    \n    def call(self, image, training = False): #각각 float tensor, string, string\n        teacher_output = self.teacher(image)\n        student_output = self.student(image)\n        return {\"teacher_output\" : teacher_output,\n               \"student_output\" : student_output}","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:37.382444Z","iopub.status.idle":"2024-04-17T15:32:37.382853Z","shell.execute_reply.started":"2024-04-17T15:32:37.382663Z","shell.execute_reply":"2024-04-17T15:32:37.382679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Barlow Twins (adjusted)\n- Cosine Similarity matrix에:\n    - diagonal하게는 1\n    - 반대는 0\n    - 과 MSE or huber loss 적용","metadata":{}},{"cell_type":"code","source":"class Barlow_module(keras.Model):\n    def __init__(self, \n                 patch_size = patch_size, att_depth = 3, att_dims = 256, att_heads = 8, prototype_c_dim = K_dims, #<-transformer 관련 hyperparameter\n                 conv_base = None, \n                 use_local_attention = False,\n                 t_teacher = t_teacher,\n                 highres_idx = highres_idx, lowres_idx = lowres_idx, **kwargs\n                ):\n        super().__init__(**kwargs)\n        if conv_base is None:\n        #feature extractors\n            self.patch_size = patch_size\n            self.att_depth = att_depth\n            self.att_dims = att_dims\n            self.att_heads = att_heads\n            self.K_dims = prototype_c_dim\n            self.use_local_attention = use_local_attention\n\n            self.teacher = self.get_vision_transformer()\n        else:\n            self.conv = conv_base\n            self.patch_size = 0\n            self.att_depth = 0\n            self.att_dims = 0\n            self.att_heads = 0\n            self.K_dims = prototype_c_dim\n            self.use_local_attention = use_local_attention\n            \n            self.teacher = self.build_conv_base()\n            \n        #hyperparameters\n        self.temp = t_teacher\n        self.highres_idx = highres_idx\n        self.lowres_idx = lowres_idx\n        #datasets\n        self.n_highres = len(highres_idx)\n        self.n_lowres = len(lowres_idx)\n        self.n_tot_view = self.n_highres + self.n_lowres\n        \n        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n        self.collapse_tracker = tf.keras.metrics.Mean(name=\"Entropy\")\n        self.std_tracker = tf.keras.metrics.Mean(name=\"StDev\")\n        \n        self.reg_loss = tf.keras.losses.Huber(reduction=\"none\")\n        self.ce_loss = tf.keras.losses.CategoricalCrossentropy(reduction=\"none\")\n        self.collapse_tracker = tf.keras.metrics.Mean(name=\"Entropy\")\n        self.std_tracker = tf.keras.metrics.Mean(name=\"STDEV\")\n        \n    def build_conv_base(self):\n        conv = self.conv\n        K_dims = self.K_dims\n        try:\n            name = conv.name\n        except:\n            name = \"ConvolutionBaseModel\"\n        inputs = conv.inputs\n        conv_out = conv.output\n        dims = conv_out.shape[-1]\n        #dims = tf.shape(conv_out)[-1]\n        encoded_patches = keras.layers.Reshape([-1, dims], name = \"EncodedPatches\")(conv_out)\n        pool = tf.keras.layers.GlobalAveragePooling1D(name = \"PoolingFromEncodedPatches\")(encoded_patches)\n        proj = get_proj(pool)\n        feature_vector = Dense(units = K_dims, name = \"FinalLinear\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-4, l2=1e-4))(proj)\n\n        return Model(inputs, feature_vector,\n                        name = name)\n\n    def get_vision_transformer(self):\n        # Get Adjusted Vision Transformer base\n        \n        patch_size = self.patch_size\n        att_depth = self.att_depth\n        att_dims = self.att_dims\n        att_heads = self.att_heads \n        K_dims = self.K_dims\n        use_local_attention = self.use_local_attention\n        \n        model_name = f\"ViT{patch_size}_depth{att_depth}_with_{att_heads}heads\"\n        inputs = Input([None,None,3], name = \"ImageInput\")\n        scaled_inputs = inputs/255\n        patches = Conv2D(filters = att_dims, kernel_size = patch_size, strides = patch_size, padding = \"SAME\", name = f\"Patching_Convolution_PatchSize{patch_size}\")(scaled_inputs)\n        patches = LayerNormalization()(patches)\n        patches = Activation(\"gelu\", name = \"PatchAct\")(patches)\n\n        batch_size = tf.shape(inputs)[0]\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch_size, -1, patch_dims]) #batch_size, seq_len, patch_dims\n        seq_len = tf.shape(patches)[1]\n\n        class_token = tf.random.normal([batch_size, 1, patch_dims])\n        patches = tf.concat([class_token, patches],\n                           axis = 1) #batch_size, seq_len+1, patch_dims\n\n        #positional encoding, learnable\n        pos_info = tf.random.normal([1, seq_len+1, patch_dims])\n        encoded_patches = patches + pos_info\n        #encoded_patches = patches\n\n        # Optional) local attention : patch간 attention시 자기 자신에 관한 attention은 수행하지 않도록\n        attn_mask = 1-tf.eye(seq_len + 1)\n        attn_mask = tf.reshape(attn_mask, [1, seq_len + 1, seq_len + 1])\n        attn_mask = tf.tile(attn_mask, [batch_size, 1, 1])\n        attn_mask = tf.cast(attn_mask, tf.int32 )\n        if use_local_attention:\n            mask = attn_mask\n        else:\n            mask = None\n        #Transformer Encoder block\n        for idx in range(att_depth):\n\n            x0, attention_score = MultiHeadAttention(att_heads, att_dims)(encoded_patches, \n                                                         encoded_patches, \n                                                        attention_mask = mask,\n                                                         return_attention_scores = True\n                                                        )\n            x1 = x0 + encoded_patches\n            x2 = LayerNormalization()(x1)\n\n            x3 = Dense(units = att_dims)(x2)\n            x4 = LayerNormalization()(x3)\n            x5 = Activation(\"gelu\")(x4)\n            \n            x6 = x2 + x5\n            \n            if idx == att_depth - 1:\n                layer_name = \"EncodedPatches\"\n            else:\n                layer_name = f\"Feature_Sequence_DepthIdx{idx}\"\n            encoded_patches = LayerNormalization(name = layer_name)(x6)\n\n        encoded_token = encoded_patches[:, 0, :]\n        encoded_token = tf.reshape(encoded_token, [batch_size, att_dims])\n        proj = get_proj(encoded_token)\n        feature_vector = Dense(units = K_dims, name = \"FinalLinear\", kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-4, l2=1e-4))(proj)\n\n        model = Model(inputs = inputs,\n                     outputs = [feature_vector, attention_score],\n                     name = model_name)\n        return model\n    \n    \n    def get_config(self):\n        return {\"TrainMethod\" : \"Barlow\",\n                \"feature_extractor_name\" : self.teacher.name,\n                \"N_params\" : self.teacher.count_params(),\n                \"patch_size\" : self.patch_size,\n                \"att_depth\" : self.att_depth,\n                \"att_dims\" : self.att_dims,\n                \"att_heads\" : self.att_heads,\n                \"K_dims\" : self.K_dims,\n                \"use_local_attention\" : self.use_local_attention,\n                \"feature_extractor_name\" : self.teacher.name,\n                \"softmax_temperature\" : self.temp,\n                \"Global_view_index\" : self.highres_idx,\n                \"Local_view_index\" : self.lowres_idx\n               }\n    \n    def get_cos_sim_matrix(self, feature_a, feature_b):\n        # input = [batch, K_dims] shape feature vectors (feature a, feature b) 모두\n        \n        feature_a = tf.nn.softmax(feature_a/self.temp,\n                                      axis = -1)\n        feature_a = tf.math.l2_normalize(feature_a, axis = -1)\n        \n        feature_b = tf.nn.softmax(feature_b/self.temp,\n                                      axis = -1)\n        feature_b = tf.math.l2_normalize(feature_b, axis = -1)\n        \n        cos_matrix = tf.matmul(feature_a, feature_b, transpose_b = True)\n        \n        return cos_matrix\n    \n    def compute_loss(self, dataset, training = True):\n        \n        feature_output = []\n        \n        for idx in self.highres_idx:\n            if len(self.teacher.outputs) >= 2:\n                f = self.teacher(dataset[idx], training = training)[0]                \n            else:\n                f = self.teacher(dataset[idx], training = training)\n            feature_output.append(f)\n\n        for idx in self.lowres_idx:\n            if len(self.teacher.outputs) >= 2:\n                f = self.teacher(dataset[idx], training = training)[0]\n            else:\n                f = self.teacher(dataset[idx], training = training)\n            feature_output.append(f)\n        \n        loss = [] #initialize\n        for i in self.highres_idx:\n            view_i = feature_output[i]\n            for j, feature in enumerate(feature_output):\n                if i == j:\n                    continue\n                else:\n                    view_j = feature\n                    cos_matrix = self.get_cos_sim_matrix(view_i, view_j)\n                    _loss = self.reg_loss(y_true = tf.eye(tf.shape(cos_matrix)[0]),\n                                          y_pred = cos_matrix)\n                    _loss = tf.reduce_mean(_loss)\n                    loss.append(_loss)\n        loss = tf.reduce_mean(loss)\n        \n        return loss, tf.concat(feature_output, axis = 0)\n    \n    #2. training and validation loop\n    def train_step(self, dataset, testing_stage = False, training = True):\n        if testing_stage:\n            print(\"Loss Computation\")\n        with tf.GradientTape() as tape:\n            loss, features = self.compute_loss(dataset, training = training)\n        \n        if testing_stage:\n            print(\"Teacher Backpropagation\")\n        training_vars = self.teacher.trainable_variables\n        gradients = tape.gradient(loss, training_vars) #teacher update without momentum encoding\n        self.optimizer.apply_gradients(zip(gradients, training_vars))\n        \n        \n        global_entropy = self.ce_loss(y_true = features, y_pred = features)\n        global_entropy = tf.reduce_mean(global_entropy)\n        std = tf.math.reduce_std(features) \n        self.loss_tracker.update_state(loss)\n        self.collapse_tracker.update_state(global_entropy)\n        self.std_tracker.update_state(std)\n        if testing_stage:\n            print(\"Single training step over!\")\n            \n        return {\"loss\": self.loss_tracker.result(),\n               \"H_glob_glob\" : self.collapse_tracker.result(),\n               \"std\" : self.std_tracker.result()}\n    \n    def call(self, dataset, training = False): \n        return self.teacher(dataset, training = training)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:37.385116Z","iopub.status.idle":"2024-04-17T15:32:37.385496Z","shell.execute_reply.started":"2024-04-17T15:32:37.385312Z","shell.execute_reply":"2024-04-17T15:32:37.385328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Optimizing Technique\n- AdamW optimizer with Warmup + Cosine decay learning rate\n- Learning rate schedule : code below, customized lr schedule!\n     - Lr setting은 original paper를 따름\n     - code reference) https://stackabuse.com/learning-rate-warmup-with-cosine-decay-in-keras-and-tensorflow/","metadata":{}},{"cell_type":"code","source":"target_lr = 0.0001\nsteps_per_epoch = len(df_train)//batch_size\ntotal_steps = 50000\nwarmup_steps = 1000 # due to restricted resources, warmsteps is lower than original paper\n\nfrom keras import backend as K\ndef lr_warmup_cosine_decay(global_step,\n                           warmup_steps,\n                           hold = 0,\n                           total_steps=0,\n                           start_lr=0.0,\n                           target_lr=1e-3):\n    # Cosine decay\n    # There is no tf.pi so we wrap np.pi as a TF constant\n    learning_rate = 0.5 * target_lr * (1 + tf.cos(tf.constant(np.pi) * (global_step - warmup_steps - hold) / float(total_steps - warmup_steps - hold)))\n\n    # Target LR * progress of warmup (=1 at the final warmup step)\n    warmup_lr = target_lr * (global_step / warmup_steps)\n\n    # Choose between `warmup_lr`, `target_lr` and `learning_rate` based on whether `global_step < warmup_steps` and we're still holding.\n    # i.e. warm up if we're still warming up and use cosine decayed lr otherwise\n    if hold > 0:\n        learning_rate = tf.where(global_step > warmup_steps + hold,\n                                 learning_rate, target_lr)\n    \n    learning_rate = tf.where(global_step < warmup_steps, warmup_lr, learning_rate)\n    return learning_rate\n\n# Visualization\nsteps = np.arange(0, total_steps//100, 1)\nlrs = []\nfor step in steps:\n    lrs.append(lr_warmup_cosine_decay(step, \n                                      total_steps=len(steps), \n                                      warmup_steps=warmup_steps//100, \n                                      hold=0, target_lr = target_lr))\nplt.figure(figsize = (10, 7))\nplt.plot(lrs)\nplt.title(\"Naive Learning Rate Schedule visualization\")\nplt.grid()\nplt.show()\n\nclass WarmUpCosineDecay(keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, start_lr, target_lr, warmup_steps, total_steps, hold):\n        super().__init__()\n        self.start_lr = start_lr\n        self.target_lr = target_lr\n        self.warmup_steps = warmup_steps\n        self.total_steps = total_steps\n        self.hold = hold\n\n    def __call__(self, step):\n        lr = lr_warmup_cosine_decay(global_step=step,\n                                    total_steps=self.total_steps,\n                                    warmup_steps=self.warmup_steps,\n                                    start_lr=self.start_lr,\n                                    target_lr=self.target_lr,\n                                    hold=self.hold)\n\n        return tf.where(\n            step > self.total_steps, 1e-7, lr, name=\"learning_rate\"\n        )","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-04-17T15:32:37.386789Z","iopub.status.idle":"2024-04-17T15:32:37.387163Z","shell.execute_reply.started":"2024-04-17T15:32:37.386978Z","shell.execute_reply":"2024-04-17T15:32:37.386993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adamw = tfa.optimizers.AdamW(weight_decay = 0.08, #<-original paper와는 다르게 그냥 Constant로..\n                                learning_rate = WarmUpCosineDecay(start_lr = 2e-5,\n                                                                 target_lr = target_lr,\n                                                                  warmup_steps = 500,\n                                                                  total_steps = total_steps,\n                                                                  hold = 0\n                                                                 )\n                                )\nadam = tf.keras.optimizers.Adam(learning_rate = WarmUpCosineDecay(start_lr = 2e-5,\n                                                                 target_lr = target_lr,\n                                                                  warmup_steps = 500,\n                                                                  total_steps = total_steps,\n                                                                  hold = 0\n                                                                 ))","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:37.388261Z","iopub.status.idle":"2024-04-17T15:32:37.388670Z","shell.execute_reply.started":"2024-04-17T15:32:37.388450Z","shell.execute_reply":"2024-04-17T15:32:37.388465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Training!\n- with training loop customizing.\n- keras의 fit 메소드를 사용하면 중간에 에러가 자주 난다","metadata":{}},{"cell_type":"code","source":"def normalize_and_int(img_tensor):\n    img_tensor = np.array(img_tensor)\n    if np.max(img_tensor) > np.min(img_tensor):\n        img_tensor = (img_tensor - np.min(img_tensor)) / (np.max(img_tensor) - np.min(img_tensor))\n    else:\n        img_tensor = img_tensor\n    img_tensor = img_tensor * 255\n    img_tensor = img_tensor.astype(np.uint8)\n    return img_tensor\n\ndef visualize_model(feature_extractor, val_ds, title = \"dummy\", log = False, n_heads = 5, batch_n = 0):\n    output = []\n    for imgs in test_ds.take(1):\n        input_image = imgs[:1]\n    input_image = tf.image.resize(input_image, \n                                  [res,res]\n                                 )\n    if len(feature_extractor.outputs) == 2:\n        example_vector, score = feature_extractor(input_image) \n        for head_n in range(n_heads):\n            #input score : batch, heads, (seqlen+1), (seqlen+1) shape tensor\n            example_weight = score[batch_n, head_n, ...]\n            parsed_weight = example_weight[0, 1:] #class token의, (class token을 제외한) 다른 patches(tokens) 간의 attention weight\n            print(f\"Mean of Attention weight between each patches ifself: {tf.reduce_mean(tf.linalg.tensor_diag_part(example_weight))}\")\n            \n            vis_res = tf.math.sqrt(tf.cast(tf.shape(parsed_weight)[-1], tf.float32))\n            parsed_weight = tf.cast(tf.reshape(parsed_weight, [vis_res, vis_res]), tf.float32)\n            plt.figure(figsize = (6,6))\n            plt.imshow(parsed_weight)\n            plt.colorbar()\n            plt.title(f\"Attention Weight, img idx{batch_n}, att head idx{head_n}\")\n            plt.show()\n            print(f\"Mean of Attention weight, pixelwise: {tf.reduce_mean(parsed_weight)}, shape : {tf.shape(parsed_weight)}, max/min/std : {tf.reduce_max(parsed_weight)}, {tf.reduce_min(parsed_weight)}, {tf.math.reduce_std(parsed_weight)}\")\n            output.append(parsed_weight)\n    else:\n        inputs_ = feature_extractor.input\n        feature_map_ = feature_extractor.get_layer(\"EncodedPatches\").input\n        model_ = Model(inputs_, feature_map_)\n        feature_map = model_(input_image)\n        _, w, h, dims = feature_map.shape\n        var = tf.math.reduce_std(feature_map, axis = (0, 1, 2))\n        high_var_indices = tf.math.top_k(var, k = n_heads).indices.numpy()\n        feature_map = feature_map[0]\n        for idx in high_var_indices:\n            output.append(feature_map[:,:,idx])\n            plt.figure(figsize = (6,6))\n            plt.imshow(feature_map[:,:,idx])\n            plt.colorbar()\n            plt.title(f\"Feature map, img idx{batch_n}, high std idx{idx}\")\n            plt.show()\n    if log : \n        data = [[wandb.Image(input_image)] + [wandb.Image(normalize_and_int(tensor)) for tensor in output]]\n        tbl = wandb.Table(data = data,\n                          columns = [\"Original img\"] + [f\"Vis_map{idx}\" for idx in range(n_heads)])\n        wandb.log({f\"{title}_table\" : tbl})\n    else:\n        pass\n    return output","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:37.390003Z","iopub.status.idle":"2024-04-17T15:32:37.390359Z","shell.execute_reply.started":"2024-04-17T15:32:37.390182Z","shell.execute_reply":"2024-04-17T15:32:37.390197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_train_loop(model, train_ds, val_ds, epochs = epochs,\n                      exp_name = None, configs = None, show_head_n = 3,\n                      log = False, troubleshoot = False):\n    if configs is None:\n        teacher_name = \"teacher\"\n        student_name = \"student\"\n    else:\n        ext_name = configs[\"feature_extractor_name\"]\n        teacher_name = f\"teacher_{ext_name}\"\n        student_name = f\"student_{ext_name}\"\n        \n    if troubleshoot:\n        epochs = 2\n        show_interval = 3\n        train_steps_per_epoch = 6\n        exp_name = exp_name + \"_test_delete\"\n    else:\n        show_interval = 1000\n        train_steps_per_epoch = 50000\n        \n    if log:\n        run = wandb.init(project=\"[Train]ScaleUp_SSL_ScreeningRadiology_AdamCosAneal\", \n                         entity=\"gongbungkim\",\n              name = exp_name, config = configs)\n    else:\n        pass\n    #============================================#\n    \n    for epoch in tqdm(range(epochs)):\n        #============================================#\n        for step, data in tqdm(enumerate(train_ds), total = train_steps_per_epoch):\n            if step > train_steps_per_epoch:\n                break\n            hist = model.train_step(data, \n                                    testing_stage = troubleshoot, \n                                    training = True)\n            loss = float(hist[\"loss\"])\n            h = float(hist[\"H_glob_glob\"])\n            std = float(hist[\"std\"])\n            \n            \n            if (step + 1) % show_interval == 0 or step == 0:\n                print(f\"{step + 1} step, loss : {loss}, entropy of global view : {h}, std. dev of global view vector : {std}\")\n                \n                visualize_model(model.teacher, val_ds = val_ds, title = f\"{step+1}step_visualize\", \n                                    log = log, n_heads = show_head_n, \n                                    batch_n = 0)  \n                print(\"Save the feature extractor\")\n                model.teacher.save(teacher_name)\n                if log:\n                    trained_teacher_artifact = wandb.Artifact(f\"{exp_name}_teacher\", type = \"model\",\n                                                 description = f\"SSL-trained feature extractor (teacher) at the end of step {step+1}, epoch {epoch}\")\n                    wd = \"/kaggle/working/\"\n                    teacher_dir = os.path.join(wd, teacher_name)\n                    trained_teacher_artifact.add_dir(teacher_dir)\n                    run.log_artifact(trained_teacher_artifact)\n                \n            if log:\n                wandb.log({\"step_loss\": loss, \"H(global_view)\" : h, \"Stdev(global_view)\" : std,\n                          \"step\" : step})\n                \n                \n        if log:\n            wandb.log({\"epoch_loss\": loss, \"epoch_H(global_view)\" : h, \"epoch_Stdev(global_view)\" : std,\n                     \"epoch\" : epoch})\n                        \n        print(f\"Epoch {epoch} Training loss : {loss}, Global View Entropy : {h}, std. dev of global view vector : {std}\")\n        \n        #----------------------------------------------#\n        \n        print(\"Save the feature extractor\")\n        model.teacher.save(teacher_name)\n        if log:\n            trained_teacher_artifact = wandb.Artifact(f\"{exp_name}_teacher\", type = \"model\",\n                                                 description = f\"SSL-trained feature extractor (teacher) at the end of epoch {epoch}\")\n            wd = \"/kaggle/working/\"\n            teacher_dir = os.path.join(wd, teacher_name)\n            trained_teacher_artifact.add_dir(teacher_dir)\n            run.log_artifact(trained_teacher_artifact)\n            \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:37.393788Z","iopub.status.idle":"2024-04-17T15:32:37.394298Z","shell.execute_reply.started":"2024-04-17T15:32:37.394035Z","shell.execute_reply":"2024-04-17T15:32:37.394057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"class TrainingModule:\n    def __init__(self, train_type = \"swav\",\n                 patch_size = patch_size, att_depth = 3, att_dims = 512, att_heads = 8, use_local_attention = False,\n                conv_base = None):\n        if train_type == \"swav\":\n            self.ssl_module = SwAV_module(conv_base = conv_base,\n                                     patch_size = patch_size, att_depth = att_depth, att_dims = att_dims, att_heads = att_heads, \n                                     use_local_attention = use_local_attention)\n        elif train_type == \"dino\":\n            self.ssl_module = DINO_module(conv_base = conv_base,\n                                     patch_size = patch_size, att_depth = att_depth, att_dims = att_dims, att_heads = att_heads, \n                                     use_local_attention = use_local_attention)\n        elif train_type == \"barlow\":\n            self.ssl_module = Barlow_module(conv_base = conv_base,\n                                     patch_size = patch_size, att_depth = att_depth, att_dims = att_dims, att_heads = att_heads, \n                                     use_local_attention = use_local_attention)\n        self.ssl_module.compile(adam)\n        self.configs = self.ssl_module.get_config()\n        self.exp_name = train_type + \"_\" + self.configs[\"feature_extractor_name\"]\n        print(\"SSL module Configuration : \", self.configs, \"\\n\", \"--------------\", \"\\n\", \"SSL experiment name : \", self.exp_name, \"\\n\")\n        \n    def init_train(self, log, troubleshoot, show_head_n = 6,\n                  ):\n        model = custom_train_loop(self.ssl_module, \n                          train_ds = train_ds, val_ds = val_ds, \n                          exp_name = self.exp_name, configs = self.configs, show_head_n = min(show_head_n, 20),\n                          log = log, troubleshoot = troubleshoot)\n        return model","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:37.395596Z","iopub.status.idle":"2024-04-17T15:32:37.396104Z","shell.execute_reply.started":"2024-04-17T15:32:37.395847Z","shell.execute_reply":"2024-04-17T15:32:37.395868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Deep Transformer training","metadata":{}},{"cell_type":"code","source":"DeepTF_swav = TrainingModule(train_type = \"swav\",\n                     patch_size = patch_size, att_depth = 4, att_dims = 768, att_heads = 6, use_local_attention = False,\n                    conv_base = None)\nDeepTF_barlow = TrainingModule(train_type = \"barlow\",\n                     patch_size = patch_size, att_depth = 4, att_dims = 768, att_heads = 6, use_local_attention = False,\n                    conv_base = None)\nDeepTF_dino = TrainingModule(train_type = \"dino\",\n                     patch_size = patch_size, att_depth = 4, att_dims = 768, att_heads = 6, use_local_attention = False,\n                    conv_base = None)\n\n#DeepTF_swav.init_train(log = True, troubleshoot = False, show_head_n = 6)\nDeepTF_barlow.init_train(log = True, troubleshoot = True, show_head_n = 6)\n#DeepTF_dino.init_train(log = True, troubleshoot = False, show_head_n = 8)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:37.397697Z","iopub.status.idle":"2024-04-17T15:32:37.398201Z","shell.execute_reply.started":"2024-04-17T15:32:37.397947Z","shell.execute_reply":"2024-04-17T15:32:37.397968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Wide Transformer training","metadata":{}},{"cell_type":"code","source":"WideTF_swav = TrainingModule(train_type = \"swav\",\n                 patch_size = patch_size, att_depth = 1, att_dims = 256, att_heads = 24, use_local_attention = False,\n                conv_base = None)\nWideTF_barlow = TrainingModule(train_type = \"barlow\",\n                 patch_size = patch_size, att_depth = 1, att_dims = 256, att_heads = 24, use_local_attention = False,\n                conv_base = None)\nWideTF_dino = TrainingModule(train_type = \"dino\",\n                 patch_size = patch_size, att_depth = 2, att_dims = 256, att_heads = 12, use_local_attention = False,\n                conv_base = None)\n\n#WideTF_swav.init_train(log = True, troubleshoot = False, show_head_n = 12)\n#WideTF_barlow.init_train(log = True, troubleshoot = False, show_head_n = 12)\n#WideTF_dino.init_train(log = True, troubleshoot = False, show_head_n = 12)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:37.399578Z","iopub.status.idle":"2024-04-17T15:32:37.400084Z","shell.execute_reply.started":"2024-04-17T15:32:37.399828Z","shell.execute_reply":"2024-04-17T15:32:37.399849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> EfficientNet lineage training","metadata":{}},{"cell_type":"code","source":"eff0_swav = TrainingModule(train_type = \"swav\",\n                 patch_size = patch_size, att_depth = 1, att_dims = 256, att_heads = 24, use_local_attention = False,\n                conv_base = eff0)\neff0_barlow = TrainingModule(train_type = \"barlow\",\n                 patch_size = patch_size, att_depth = 1, att_dims = 256, att_heads = 24, use_local_attention = False,\n                conv_base = eff0)\neff0_dino = TrainingModule(train_type = \"dino\",\n                 patch_size = patch_size, att_depth = 1, att_dims = 256, att_heads = 24, use_local_attention = False,\n                conv_base = eff0)\n\n\n#eff0_swav.init_train(log = True, troubleshoot = False,show_head_n = 6)\n#eff0_barlow.init_train(log = True, troubleshoot = False,show_head_n = 6)\n#eff0_dino.init_train(log = True, troubleshoot = False,show_head_n = 6)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:37.401509Z","iopub.status.idle":"2024-04-17T15:32:37.402071Z","shell.execute_reply.started":"2024-04-17T15:32:37.401813Z","shell.execute_reply":"2024-04-17T15:32:37.401833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eff1_swav = TrainingModule(train_type = \"swav\",\n                 patch_size = patch_size, att_depth = 1, att_dims = 256, att_heads = 24, use_local_attention = False,\n                conv_base = eff1)\neff1_barlow = TrainingModule(train_type = \"barlow\",\n                 patch_size = patch_size, att_depth = 1, att_dims = 256, att_heads = 24, use_local_attention = False,\n                conv_base = eff1)\neff1_dino = TrainingModule(train_type = \"dino\",\n                 patch_size = patch_size, att_depth = 1, att_dims = 256, att_heads = 24, use_local_attention = False,\n                conv_base = eff1)\n\n\n#eff1_swav.init_train(log = True, troubleshoot = False,show_head_n = 6)\n#eff1_barlow.init_train(log = True, troubleshoot = False,show_head_n = 6)\n#eff1_dino.init_train(log = True, troubleshoot = False,show_head_n = 6)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:37.403582Z","iopub.status.idle":"2024-04-17T15:32:37.404093Z","shell.execute_reply.started":"2024-04-17T15:32:37.403832Z","shell.execute_reply":"2024-04-17T15:32:37.403853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eff2_swav = TrainingModule(train_type = \"swav\",\n                 patch_size = patch_size, att_depth = 1, att_dims = 256, att_heads = 24, use_local_attention = False,\n                conv_base = eff2)\neff2_barlow = TrainingModule(train_type = \"barlow\",\n                 patch_size = patch_size, att_depth = 1, att_dims = 256, att_heads = 24, use_local_attention = False,\n                conv_base = eff2)\neff2_dino = TrainingModule(train_type = \"dino\",\n                 patch_size = patch_size, att_depth = 1, att_dims = 256, att_heads = 24, use_local_attention = False,\n                conv_base = eff2)\n\n\n#eff2_swav.init_train(log = True, troubleshoot = False,show_head_n = 6)\n#eff2_barlow.init_train(log = True, troubleshoot = False,show_head_n = 6)\n#eff2_dino.init_train(log = True, troubleshoot = False,show_head_n = 6)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:32:37.408488Z","iopub.status.idle":"2024-04-17T15:32:37.409109Z","shell.execute_reply.started":"2024-04-17T15:32:37.408806Z","shell.execute_reply":"2024-04-17T15:32:37.408830Z"},"trusted":true},"execution_count":null,"outputs":[]}]}