{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac39cb54",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-21T07:38:31.909952Z",
     "iopub.status.busy": "2024-05-21T07:38:31.909577Z",
     "iopub.status.idle": "2024-05-21T07:38:54.872415Z",
     "shell.execute_reply": "2024-05-21T07:38:54.871270Z"
    },
    "papermill": {
     "duration": 22.978815,
     "end_time": "2024-05-21T07:38:54.874392",
     "exception": false,
     "start_time": "2024-05-21T07:38:31.895577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 07:38:35.564202: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-21 07:38:35.564296: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-21 07:38:35.672788: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version : 2.15.0\n",
      "Keras version : 3.2.1\n",
      "Running on 1 replicas\n",
      "batch size 16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import random\n",
    "import pydicom\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "seed = 2024\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ML tools \n",
    "sys.path.append(\"/kaggle/input/kimm-keras-image-model-repository\"\n",
    "               )\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras #; keras.config.set_dtype_policy(\"mixed_float16\")\n",
    "import kimm\n",
    "import keras_cv\n",
    "import keras_nlp\n",
    "\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "keras.utils.set_random_seed(seed)\n",
    "import tensorflow_io as tfio\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "print(f\"Tensorflow version : {tf.__version__}\")\n",
    "try:\n",
    "    print(f\"Keras version : {keras.__version__}\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from keras import Input, Model, ops\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import Conv2D, DepthwiseConv2D, Dense, Activation, BatchNormalization, LayerNormalization, MultiHeadAttention, Embedding, Subtract, Add, Multiply, GlobalAveragePooling2D, GlobalAveragePooling1D, LayerNormalization\n",
    "from keras.utils import load_img, img_to_array\n",
    "from keras.applications import *\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback, WandbModelCheckpoint, WandbMetricsLogger\n",
    "def wandb_config():\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    try:\n",
    "        secret_value_0 = user_secrets.get_secret(\"__gcloud_sdk_auth__\")\n",
    "        secret_value_1 = user_secrets.get_secret(\"huggingface_key\")\n",
    "        secret_value_2 = user_secrets.get_secret(\"wandb_key\")\n",
    "        !wandb login $secret_value_2\n",
    "    except:\n",
    "        secret_value_0 = user_secrets.get_secret(\"huggingface_key\")\n",
    "        secret_value_1 = user_secrets.get_secret(\"wandb_key\")\n",
    "        !wandb login $secret_value_1\n",
    "    \n",
    "\n",
    "res = int(1.0*256)\n",
    "small_res = 64\n",
    "batch_size = 16\n",
    "embed_dims = 768\n",
    "n_multicrop = 5\n",
    "\n",
    "def auto_select_accelerator():\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        print(\"Running on TPU:\", tpu.master())\n",
    "    except ValueError:\n",
    "        tpu = False\n",
    "        strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "    \n",
    "    return tpu, strategy\n",
    "\n",
    "tpu, strategy = auto_select_accelerator()\n",
    "batch_size = strategy.num_replicas_in_sync * batch_size\n",
    "print('batch size', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7cc2a86",
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-21T07:38:54.899679Z",
     "iopub.status.busy": "2024-05-21T07:38:54.899342Z",
     "iopub.status.idle": "2024-05-21T07:38:55.011061Z",
     "shell.execute_reply": "2024-05-21T07:38:55.010122Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.126552,
     "end_time": "2024-05-21T07:38:55.013038",
     "exception": false,
     "start_time": "2024-05-21T07:38:54.886486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirements loaded, keras : v3.2.1, Tensorflow : v2.15.0\n",
      "RandAug Component in this SSL module :  ['random_color_degeneration', 'random_contrast', 'random_brightness', 'random_shear', 'random_shear_1', 'random_translation', 'random_translation_1', 'grid_mask']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'models_from_kimm': ['ConvMixer1024D20',\n",
       "  'ConvMixer1536D20',\n",
       "  'ConvMixer736D32',\n",
       "  'ConvNeXtAtto',\n",
       "  'ConvNeXtBase',\n",
       "  'ConvNeXtFemto',\n",
       "  'ConvNeXtLarge',\n",
       "  'ConvNeXtNano',\n",
       "  'ConvNeXtPico',\n",
       "  'ConvNeXtSmall',\n",
       "  'ConvNeXtTiny',\n",
       "  'ConvNeXtXLarge',\n",
       "  'DenseNet121',\n",
       "  'DenseNet161',\n",
       "  'DenseNet169',\n",
       "  'DenseNet201',\n",
       "  'EfficientNetB0',\n",
       "  'EfficientNetB1',\n",
       "  'EfficientNetB2',\n",
       "  'EfficientNetB3',\n",
       "  'EfficientNetB4',\n",
       "  'EfficientNetB5',\n",
       "  'EfficientNetB6',\n",
       "  'EfficientNetB7',\n",
       "  'EfficientNetLiteB0',\n",
       "  'EfficientNetLiteB1',\n",
       "  'EfficientNetLiteB2',\n",
       "  'EfficientNetLiteB3',\n",
       "  'EfficientNetLiteB4',\n",
       "  'EfficientNetV2B0',\n",
       "  'EfficientNetV2B1',\n",
       "  'EfficientNetV2B2',\n",
       "  'EfficientNetV2B3',\n",
       "  'EfficientNetV2L',\n",
       "  'EfficientNetV2M',\n",
       "  'EfficientNetV2S',\n",
       "  'EfficientNetV2XL',\n",
       "  'GhostNet050',\n",
       "  'GhostNet100',\n",
       "  'GhostNet100V2',\n",
       "  'GhostNet130',\n",
       "  'GhostNet130V2',\n",
       "  'GhostNet160V2',\n",
       "  'HGNetBase',\n",
       "  'HGNetSmall',\n",
       "  'HGNetTiny',\n",
       "  'HGNetV2B0',\n",
       "  'HGNetV2B1',\n",
       "  'HGNetV2B2',\n",
       "  'HGNetV2B3',\n",
       "  'HGNetV2B4',\n",
       "  'HGNetV2B5',\n",
       "  'HGNetV2B6',\n",
       "  'InceptionNeXtBase',\n",
       "  'InceptionNeXtSmall',\n",
       "  'InceptionNeXtTiny',\n",
       "  'InceptionV3',\n",
       "  'LCNet035',\n",
       "  'LCNet050',\n",
       "  'LCNet075',\n",
       "  'LCNet100',\n",
       "  'LCNet150',\n",
       "  'MobileNetV2W050',\n",
       "  'MobileNetV2W100',\n",
       "  'MobileNetV2W110',\n",
       "  'MobileNetV2W120',\n",
       "  'MobileNetV2W140',\n",
       "  'MobileNetV3W050Small',\n",
       "  'MobileNetV3W075Small',\n",
       "  'MobileNetV3W100Large',\n",
       "  'MobileNetV3W100LargeMinimal',\n",
       "  'MobileNetV3W100Small',\n",
       "  'MobileNetV3W100SmallMinimal',\n",
       "  'MobileOneS0',\n",
       "  'MobileOneS1',\n",
       "  'MobileOneS2',\n",
       "  'MobileOneS3',\n",
       "  'MobileViTS',\n",
       "  'MobileViTV2W050',\n",
       "  'MobileViTV2W075',\n",
       "  'MobileViTV2W100',\n",
       "  'MobileViTV2W125',\n",
       "  'MobileViTV2W150',\n",
       "  'MobileViTV2W175',\n",
       "  'MobileViTV2W200',\n",
       "  'MobileViTXS',\n",
       "  'MobileViTXXS',\n",
       "  'RegNetX002',\n",
       "  'RegNetX004',\n",
       "  'RegNetX006',\n",
       "  'RegNetX008',\n",
       "  'RegNetX016',\n",
       "  'RegNetX032',\n",
       "  'RegNetX040',\n",
       "  'RegNetX064',\n",
       "  'RegNetX080',\n",
       "  'RegNetX120',\n",
       "  'RegNetX160',\n",
       "  'RegNetX320',\n",
       "  'RegNetY002',\n",
       "  'RegNetY004',\n",
       "  'RegNetY006',\n",
       "  'RegNetY008',\n",
       "  'RegNetY016',\n",
       "  'RegNetY032',\n",
       "  'RegNetY040',\n",
       "  'RegNetY064',\n",
       "  'RegNetY080',\n",
       "  'RegNetY120',\n",
       "  'RegNetY160',\n",
       "  'RegNetY320',\n",
       "  'RepVGGA0',\n",
       "  'RepVGGA1',\n",
       "  'RepVGGA2',\n",
       "  'RepVGGB0',\n",
       "  'RepVGGB1',\n",
       "  'RepVGGB2',\n",
       "  'RepVGGB3',\n",
       "  'ResNet101',\n",
       "  'ResNet152',\n",
       "  'ResNet18',\n",
       "  'ResNet34',\n",
       "  'ResNet50',\n",
       "  'TinyNetA',\n",
       "  'TinyNetB',\n",
       "  'TinyNetC',\n",
       "  'TinyNetD',\n",
       "  'TinyNetE',\n",
       "  'VGG11',\n",
       "  'VGG13',\n",
       "  'VGG16',\n",
       "  'VGG19',\n",
       "  'VisionTransformerBase16',\n",
       "  'VisionTransformerBase32',\n",
       "  'VisionTransformerLarge16',\n",
       "  'VisionTransformerLarge32',\n",
       "  'VisionTransformerSmall16',\n",
       "  'VisionTransformerSmall32',\n",
       "  'VisionTransformerTiny16',\n",
       "  'VisionTransformerTiny32',\n",
       "  'Xception'],\n",
       " 'models_from_keras': ['effnet',\n",
       "  'effnet_small',\n",
       "  'effnet_base',\n",
       "  'convnext',\n",
       "  'convnext_small',\n",
       "  'convnext_base',\n",
       "  'mlpmixer_patch_depth_dims',\n",
       "  'convmixer_patch_depth_dims']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl_module\n",
    "from ssl_module import get_map_fn, get_gcvit_configs, get_flops, att_visualize, get_full_model, AttentionPooling, BarlowModel, VICRegModel, Moco, SimSiam, CLIP, SigLIP\n",
    "import nas_ftp_module\n",
    "from nas_ftp_module import upload_file, download_file\n",
    "ssl_module.available_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2639c9e4",
   "metadata": {
    "papermill": {
     "duration": 0.012375,
     "end_time": "2024-05-21T07:38:55.037790",
     "exception": false,
     "start_time": "2024-05-21T07:38:55.025415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data import (with Generator)\n",
    "- 목적 : CXR의 prior knowledge를 SwAV으로 feature map generator에 주입시키기\n",
    "- Bounding box의 information을 사용하지 않음 + External data를 사용하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8930ee",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-21T07:38:55.064281Z",
     "iopub.status.busy": "2024-05-21T07:38:55.063788Z",
     "iopub.status.idle": "2024-05-21T07:38:56.457063Z",
     "shell.execute_reply": "2024-05-21T07:38:56.455996Z"
    },
    "papermill": {
     "duration": 1.409305,
     "end_time": "2024-05-21T07:38:56.459126",
     "exception": false,
     "start_time": "2024-05-21T07:38:55.049821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training cases for CXR : 18025 cases, Validation case : 553 case\n"
     ]
    }
   ],
   "source": [
    "metainfo_dir = \"/kaggle/input/chexdet-image-and-annotations/ChestXDet_Metainformations/ChestX-Det-Dataset-main\"\n",
    "train_det_dir = \"/kaggle/input/chexdet-image-and-annotations/train_data/train\"\n",
    "val_det_dir = \"/kaggle/input/chexdet-image-and-annotations/test_data/test\"\n",
    "\n",
    "df_det_train = pd.read_json(\"/kaggle/input/chexdet-image-and-annotations/ChestXDet_Metainformations/ChestX-Det-Dataset-main/ChestX_Det_train.json\")\n",
    "df_det_train[\"file_name\"] = [os.path.join(train_det_dir, fname) for fname in df_det_train.file_name.values]\n",
    "df_det_train = df_det_train.loc[:, [\"file_name\"]]\n",
    "\n",
    "df_val = pd.read_json(\"/kaggle/input/chexdet-image-and-annotations/ChestXDet_Metainformations/ChestX-Det-Dataset-main/ChestX_Det_test.json\")\n",
    "df_val[\"file_name\"] = [os.path.join(val_det_dir, fname) for fname in df_val.file_name.values]\n",
    "df_val_cxr = df_val.loc[:, [\"file_name\"]]\n",
    "\n",
    "#\n",
    "ext_dir = \"/kaggle/input/vinbigdata-chest-xray-original-png/train\"\n",
    "dict_ext = {\"file_name\" : [os.path.join(ext_dir, fname) for fname in os.listdir(ext_dir)] }\n",
    "df_ext = pd.DataFrame(dict_ext)\n",
    "df_train_cxr = pd.concat([df_det_train, df_ext], axis = 0)\n",
    "print(f\"Total training cases for CXR : {len(df_train_cxr)} cases, Validation case : {len(df_val_cxr)} case\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6184d7f0",
   "metadata": {
    "papermill": {
     "duration": 0.012114,
     "end_time": "2024-05-21T07:38:56.483991",
     "exception": false,
     "start_time": "2024-05-21T07:38:56.471877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> Deeplesion metainformation dataframe 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1081b58b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:38:56.510271Z",
     "iopub.status.busy": "2024-05-21T07:38:56.509716Z",
     "iopub.status.idle": "2024-05-21T07:39:15.443159Z",
     "shell.execute_reply": "2024-05-21T07:39:15.441877Z"
    },
    "papermill": {
     "duration": 18.94884,
     "end_time": "2024-05-21T07:39:15.445112",
     "exception": false,
     "start_time": "2024-05-21T07:38:56.496272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66efb77ba4ae4d0a8e6a467c6daa26cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training cases of Chest/Abdomen CT : 33200 cases, Validation case : 134 case\n"
     ]
    }
   ],
   "source": [
    "ct_fname = []\n",
    "base_img_dir = '/kaggle/input/nih-deeplesion-subset/minideeplesion'\n",
    "for dirname, _, filenames in tqdm(os.walk(base_img_dir)):\n",
    "    for filename in filenames:\n",
    "        ct_fname.append(os.path.join(dirname, filename))\n",
    "        \n",
    "df_ct_whole = pd.DataFrame({\"file_name\" : ct_fname})\n",
    "\n",
    "df_ct_train, df_ct_val = train_test_split(df_ct_whole, \n",
    "                                         test_size = 134,\n",
    "                                         random_state = seed)\n",
    "print(f\"Total training cases of Chest/Abdomen CT : {len(df_ct_train)} cases, Validation case : {len(df_ct_val)} case\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e208df",
   "metadata": {
    "papermill": {
     "duration": 0.012434,
     "end_time": "2024-05-21T07:39:15.470470",
     "exception": false,
     "start_time": "2024-05-21T07:39:15.458036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> import RSNA ICH dataset metainformation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abae10e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:15.496379Z",
     "iopub.status.busy": "2024-05-21T07:39:15.496104Z",
     "iopub.status.idle": "2024-05-21T07:39:15.659725Z",
     "shell.execute_reply": "2024-05-21T07:39:15.658703Z"
    },
    "papermill": {
     "duration": 0.178905,
     "end_time": "2024-05-21T07:39:15.661760",
     "exception": false,
     "start_time": "2024-05-21T07:39:15.482855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training cases of Brain, NonCE CT : 32000 cases, Validation case : 300 case\n"
     ]
    }
   ],
   "source": [
    "dicom_dir = \"/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train\"\n",
    "df_train_brainct = pd.read_csv(\"/kaggle/input/rsna-ich-detection-metadata/df_train_split.csv\")\n",
    "df_val_brainct = pd.read_csv(\"/kaggle/input/rsna-ich-detection-metadata/df_val_splt.csv\").head(300)\n",
    "\n",
    "for df in [df_train_brainct, df_val_brainct]:\n",
    "    df[\"file_name\"] = [os.path.join(dicom_dir, fname + \".dcm\") for fname in df['SOPInstanceUID']]\n",
    "    \n",
    "print(f\"Total training cases of Brain, NonCE CT : {len(df_train_brainct)} cases, Validation case : {len(df_val_brainct)} case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed40befc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:15.688483Z",
     "iopub.status.busy": "2024-05-21T07:39:15.688211Z",
     "iopub.status.idle": "2024-05-21T07:39:16.068819Z",
     "shell.execute_reply": "2024-05-21T07:39:16.067883Z"
    },
    "papermill": {
     "duration": 0.396387,
     "end_time": "2024-05-21T07:39:16.070951",
     "exception": false,
     "start_time": "2024-05-21T07:39:15.674564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27863</th>\n",
       "      <td>/kaggle/input/rsna-intracranial-hemorrhage-det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>/kaggle/input/nih-deeplesion-subset/minideeple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12077</th>\n",
       "      <td>/kaggle/input/nih-deeplesion-subset/minideeple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25883</th>\n",
       "      <td>/kaggle/input/nih-deeplesion-subset/minideeple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11373</th>\n",
       "      <td>/kaggle/input/vinbigdata-chest-xray-original-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>/kaggle/input/vinbigdata-chest-xray-original-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>/kaggle/input/nih-deeplesion-subset/minideeple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10721</th>\n",
       "      <td>/kaggle/input/vinbigdata-chest-xray-original-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>/kaggle/input/chexdet-image-and-annotations/tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30151</th>\n",
       "      <td>/kaggle/input/rsna-intracranial-hemorrhage-det...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               file_name\n",
       "27863  /kaggle/input/rsna-intracranial-hemorrhage-det...\n",
       "1222   /kaggle/input/nih-deeplesion-subset/minideeple...\n",
       "12077  /kaggle/input/nih-deeplesion-subset/minideeple...\n",
       "25883  /kaggle/input/nih-deeplesion-subset/minideeple...\n",
       "11373  /kaggle/input/vinbigdata-chest-xray-original-p...\n",
       "13095  /kaggle/input/vinbigdata-chest-xray-original-p...\n",
       "2090   /kaggle/input/nih-deeplesion-subset/minideeple...\n",
       "10721  /kaggle/input/vinbigdata-chest-xray-original-p...\n",
       "1321   /kaggle/input/chexdet-image-and-annotations/tr...\n",
       "30151  /kaggle/input/rsna-intracranial-hemorrhage-det..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([df_ct_train, df_train_cxr, df_train_brainct], axis = 0, join='inner')\n",
    "df_val = pd.concat([df_val_cxr, df_ct_val, df_val_brainct], axis = 0, join='inner')\n",
    "\n",
    "df_train.to_csv(\"df_train_ER_SSL.csv\", index = False)\n",
    "df_val.to_csv(\"df_val_ER_SSL.csv\", index = False)\n",
    "\n",
    "df_train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f864d814",
   "metadata": {
    "papermill": {
     "duration": 0.012539,
     "end_time": "2024-05-21T07:39:16.096574",
     "exception": false,
     "start_time": "2024-05-21T07:39:16.084035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building Dataloader in keras-3 style\n",
    "- Merging 2 kinds of dataset : original files with pd dataframe and tfrecord\n",
    "    - using this [tf dataset method](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#sample_from_datasets)\n",
    "    - [reference code](https://www.kaggle.com/code/calebeverett/combining-dataset-examples#Sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e805e808",
   "metadata": {
    "papermill": {
     "duration": 0.012432,
     "end_time": "2024-05-21T07:39:16.121645",
     "exception": false,
     "start_time": "2024-05-21T07:39:16.109213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Original Files with dataframe\n",
    "- using keras.utils.Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65c91525",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:16.148601Z",
     "iopub.status.busy": "2024-05-21T07:39:16.148321Z",
     "iopub.status.idle": "2024-05-21T07:39:16.232871Z",
     "shell.execute_reply": "2024-05-21T07:39:16.232091Z"
    },
    "papermill": {
     "duration": 0.10057,
     "end_time": "2024-05-21T07:39:16.234881",
     "exception": false,
     "start_time": "2024-05-21T07:39:16.134311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageDataLoader(keras.utils.Sequence):\n",
    "    def __init__(self, dataframe, x_col, res, batch_size, y_col = None, shuffle = True):\n",
    "        self.df = dataframe\n",
    "        self.x_col = x_col ; self.y_col = y_col\n",
    "        self.res = res\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "    def dicom_to_tensor(self, dicom_path):\n",
    "        dataset = pydicom.dcmread(dicom_path)\n",
    "        tensor = np.array(dataset.pixel_array)\n",
    "        slope = dataset.RescaleSlope   # dicom header (Rescale slope)\n",
    "        intercept = dataset.RescaleIntercept   # dicom header (Rescale intercept)\n",
    "        center = dataset.WindowCenter   # dicom header (Window center)\n",
    "        width = dataset.WindowWidth   # dicom header (Window width)\n",
    "\n",
    "        if(type(dataset.WindowCenter) == pydicom.multival.MultiValue):\n",
    "                center = float(dataset.WindowCenter[0])\n",
    "                width = float(dataset.WindowWidth[0])       \n",
    "        else:    \n",
    "                center = float(dataset.WindowCenter)\n",
    "                width = float(dataset.WindowWidth)\n",
    "\n",
    "        tensor = slope*tensor + intercept\n",
    "        lbound, ubound = center - 0.5*width, center + 0.5*width\n",
    "        tensor[np.where(tensor < lbound)] = lbound\n",
    "        tensor[np.where(tensor > ubound)] = ubound\n",
    "        tensor = tf.image.resize(tensor[:,:,tf.newaxis], [self.res,self.res],\n",
    "                                antialias = True) #HU unit\n",
    "        if tf.shape(tensor)[-1] == 1 :#gray\n",
    "            tensor = tf.image.grayscale_to_rgb(tensor)\n",
    "            \n",
    "        tensor = (tensor - tf.reduce_min(tensor)) / (tf.reduce_max(tensor) - tf.reduce_min(tensor) + 1e-4) #HU unit to Uint8\n",
    "        tensor = tensor*255.0\n",
    "        try:\n",
    "            del dataset\n",
    "        except:\n",
    "            pass\n",
    "        #print(f\"Dicom tensor shape : {ops.shape(tensor)}\")\n",
    "        return tensor\n",
    "    \n",
    "    def image_to_tensor(self, path):\n",
    "        if path.split(\".\")[-1] == \"dcm\":\n",
    "            return self.dicom_to_tensor(path)\n",
    "        \n",
    "        if \"minideeplesion\" in str(path).split(\"/\"):\n",
    "            image = imread(path).astype(np.float32)-32768\n",
    "            image = image[..., tf.newaxis]\n",
    "            image = tf.image.resize(image, [self.res, self.res],\n",
    "                                   antialias = True)\n",
    "            #print(f\"deepLesion tensor shape : {ops.shape(image)}\")\n",
    "            image = tf.clip_by_value(image, -750.0, 700.0)\n",
    "            image = (image - tf.reduce_min(image))/(tf.reduce_max(image) - tf.reduce_min(image) + 1e-3)\n",
    "            image = image * 255.0\n",
    "            \n",
    "        else:           \n",
    "            image = load_img(path, target_size = [self.res, self.res])\n",
    "            image = img_to_array(image)\n",
    "            #print(f\"other tensor shape : {ops.shape(image)}\")\n",
    "        if tf.shape(image)[-1] == 1 :#gray\n",
    "            image = tf.image.grayscale_to_rgb(image)\n",
    "            #image = np.array(image)\n",
    "            \n",
    "\n",
    "        return image\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.df))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __data_generation(self, img_name):\n",
    "        ## path를 받아 img화 및 token화 하여 실제로 Feeding할 데이터를 반환\n",
    "        X = []\n",
    "        for i, fname in enumerate(img_name):\n",
    "            img = self.image_to_tensor(fname)\n",
    "            img = tf.convert_to_tensor(img)\n",
    "            img = tf.cast(img, tf.uint8)\n",
    "            X.append(img)\n",
    "        \n",
    "        return X\n",
    "        \n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        \n",
    "        img_name = [self.df.iloc[k].loc[self.x_col] for k in indexes]\n",
    "        \n",
    "        X = self.__data_generation(img_name)\n",
    "        #X = np.array(X).reshape([-1, self.res, self.res, 3])\n",
    "        return X\n",
    "    \n",
    "def get_train_gen():\n",
    "    return ImageDataLoader(df_train, x_col = \"file_name\",\n",
    "                         res = res, batch_size = batch_size)\n",
    "\n",
    "def get_val_gen():\n",
    "    return ImageDataLoader(df_val, x_col = \"file_name\",\n",
    "                         res = res, batch_size = batch_size)\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(get_train_gen, (tf.uint8), output_shapes = (batch_size, res, res,3) ).ignore_errors().prefetch(tf.data.AUTOTUNE).repeat()\n",
    "val_ds = tf.data.Dataset.from_generator(get_val_gen, (tf.uint8), output_shapes = (batch_size, res, res,3) ).ignore_errors().prefetch(tf.data.AUTOTUNE).repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c02b51",
   "metadata": {
    "papermill": {
     "duration": 0.012633,
     "end_time": "2024-05-21T07:39:16.260507",
     "exception": false,
     "start_time": "2024-05-21T07:39:16.247874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Spinal X-ray dataset in TFrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c355e908",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:16.287438Z",
     "iopub.status.busy": "2024-05-21T07:39:16.287162Z",
     "iopub.status.idle": "2024-05-21T07:39:16.691680Z",
     "shell.execute_reply": "2024-05-21T07:39:16.690898Z"
    },
    "papermill": {
     "duration": 0.420959,
     "end_time": "2024-05-21T07:39:16.693971",
     "exception": false,
     "start_time": "2024-05-21T07:39:16.273012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#spinal xray dataset\n",
    "\n",
    "label_map = {0: 'Disc space narrowing', 1: 'Foraminal stenosis', 2: 'No finding', 3: 'Osteophytes', 4: 'Other lesions', 5: 'Spondylolysthesis', 6: 'Surgical implant', 7: 'Vertebral collapse'}\n",
    "\n",
    "labels = list(label_map.values())\n",
    "labels.sort()\n",
    "n_labels = len(label_map)\n",
    "\n",
    "\n",
    "def deserialize_example(serialized_string, train = True):\n",
    "    image_feature_description = {\n",
    "            'image': tf.io.FixedLenFeature([], tf.string),\n",
    "            'label': tf.io.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "    parsed_record = tf.io.parse_single_example(serialized_string, image_feature_description)\n",
    "    image = tf.io.parse_tensor(parsed_record[\"image\"], tf.float32)\n",
    "    image = (image - tf.reduce_min(image))/(tf.reduce_max(image)-tf.reduce_min(image)+1e-4)\n",
    "    image = image * 255.0\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    image = ops.reshape(image, [res, res, 3])\n",
    "    label = tf.io.decode_raw(parsed_record['label'], tf.int32)\n",
    "    label = ops.reshape(label, [n_labels,])\n",
    "    return image, label\n",
    "    \n",
    "def load_dataset(filenames):\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, compression_type = \"GZIP\", \n",
    "                                      num_parallel_reads=tf.data.AUTOTUNE) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(deserialize_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "original_train_ds = load_dataset(\"/kaggle/input/tfrecords-vindr-spinexr-tfrecords/train_gzip_384.tfrecord\")\n",
    "original_val_ds = load_dataset(\"/kaggle/input/tfrecords-vindr-spinexr-tfrecords/val_gzip_384.tfrecord\")\n",
    "\n",
    "spine_train_ds = original_train_ds.batch(batch_size, drop_remainder = True).map(lambda x,y:x).ignore_errors().repeat().prefetch(tf.data.AUTOTUNE)\n",
    "spine_val_ds = original_val_ds.batch(batch_size, drop_remainder = True).map(lambda x,y:x).ignore_errors().repeat().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90754a1b",
   "metadata": {
    "papermill": {
     "duration": 0.012547,
     "end_time": "2024-05-21T07:39:16.719726",
     "exception": false,
     "start_time": "2024-05-21T07:39:16.707179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Merging 2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a7064b5",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:16.746299Z",
     "iopub.status.busy": "2024-05-21T07:39:16.746020Z",
     "iopub.status.idle": "2024-05-21T07:39:18.571391Z",
     "shell.execute_reply": "2024-05-21T07:39:18.570541Z"
    },
    "papermill": {
     "duration": 1.841333,
     "end_time": "2024-05-21T07:39:18.573673",
     "exception": false,
     "start_time": "2024-05-21T07:39:16.732340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_train_ds = tf.data.Dataset.sample_from_datasets([train_ds.unbatch(), spine_train_ds.unbatch()], weights = [0.5, 0.5]).batch(batch_size).ignore_errors().repeat().prefetch(tf.data.AUTOTUNE)\n",
    "merged_val_ds = tf.data.Dataset.sample_from_datasets([val_ds.unbatch(), spine_val_ds.unbatch()], weights = [0.5, 0.5]).batch(batch_size).ignore_errors().repeat().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d716a708",
   "metadata": {
    "papermill": {
     "duration": 0.012785,
     "end_time": "2024-05-21T07:39:18.599741",
     "exception": false,
     "start_time": "2024-05-21T07:39:18.586956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> calculating train and validation steps per epoch\n",
    "\n",
    "- Spinal dataset : [여기 참고](https://www.kaggle.com/code/khsmdjjys/self-supervised-learning-with-tfrecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd04c717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:18.626354Z",
     "iopub.status.busy": "2024-05-21T07:39:18.626049Z",
     "iopub.status.idle": "2024-05-21T07:39:18.631510Z",
     "shell.execute_reply": "2024-05-21T07:39:18.630671Z"
    },
    "papermill": {
     "duration": 0.021241,
     "end_time": "2024-05-21T07:39:18.633670",
     "exception": false,
     "start_time": "2024-05-21T07:39:18.612429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Train cases, Val cases : (91614, 3064)\n"
     ]
    }
   ],
   "source": [
    "train_1 = len(df_train) ; val_1 = len(df_val)\n",
    "train_2 = 8389 ; val_2 = 2077\n",
    "\n",
    "train_steps = (train_1 + train_2)//batch_size\n",
    "val_steps = (val_1 + val_2)//batch_size\n",
    "\n",
    "print(f\"Total Train cases, Val cases : {train_1 + train_2, val_1 + val_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374e725",
   "metadata": {
    "papermill": {
     "duration": 0.012417,
     "end_time": "2024-05-21T07:39:18.658752",
     "exception": false,
     "start_time": "2024-05-21T07:39:18.646335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Applying SSL functions\n",
    "- A. Basic function : return 2 global views (g=2)\n",
    "- B. SwAV-like strategy : return 2 global views + additional local views (l = 4)\n",
    "- Use get_map_fn in SSL module:\n",
    "> parameters of get_map_fn:\n",
    "    - res = image resolution, \n",
    "    - input_type = \"without_label\" or \"supervised\"\n",
    "    - output_type = \"ssl\" or \"ssl_with_label\"\n",
    "    - n_view = HOW MANY VIEWS? -> n_view >= 3일 때, 첫번째 이미지와 두 번째 이미지는 비교적 global information을 담고, 나머지 이미지는 local image (가로/세로 1/2)임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ee1a237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:18.685365Z",
     "iopub.status.busy": "2024-05-21T07:39:18.685075Z",
     "iopub.status.idle": "2024-05-21T07:39:28.243973Z",
     "shell.execute_reply": "2024-05-21T07:39:28.243141Z"
    },
    "papermill": {
     "duration": 9.575124,
     "end_time": "2024-05-21T07:39:28.246600",
     "exception": false,
     "start_time": "2024-05-21T07:39:18.671476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "multiview_fn = get_map_fn(res = res, input_type = \"without_label\", output_type = \"ssl\",\n",
    "                         n_view = n_multicrop)\n",
    "two_view_fn = get_map_fn(res = res, input_type = \"without_label\", output_type = \"ssl\",\n",
    "                         n_view = 2)\n",
    "\n",
    "train_ds = merged_train_ds.unbatch().map(two_view_fn, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).ignore_errors().prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = merged_val_ds.unbatch().map(two_view_fn, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).ignore_errors().prefetch(tf.data.AUTOTUNE)\n",
    "train_ds_multiview = merged_train_ds.unbatch().map(multiview_fn, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).ignore_errors().prefetch(tf.data.AUTOTUNE)\n",
    "val_ds_multiview = merged_val_ds.unbatch().map(multiview_fn, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).ignore_errors().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c71c2e85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:28.277898Z",
     "iopub.status.busy": "2024-05-21T07:39:28.277111Z",
     "iopub.status.idle": "2024-05-21T07:39:47.033902Z",
     "shell.execute_reply": "2024-05-21T07:39:47.032877Z"
    },
    "papermill": {
     "duration": 18.774659,
     "end_time": "2024-05-21T07:39:47.036388",
     "exception": false,
     "start_time": "2024-05-21T07:39:28.261729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for imgs in val_ds_multiview.take(1):\n",
    "    images = imgs\n",
    "sample_img = images[0]\n",
    "test_set = tuple([comp[:2] for comp in images])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa74c1e",
   "metadata": {
    "papermill": {
     "duration": 0.012685,
     "end_time": "2024-05-21T07:39:47.062569",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.049884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> Curate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "889fdc0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:47.130442Z",
     "iopub.status.busy": "2024-05-21T07:39:47.130091Z",
     "iopub.status.idle": "2024-05-21T07:39:47.134534Z",
     "shell.execute_reply": "2024-05-21T07:39:47.133603Z"
    },
    "papermill": {
     "duration": 0.020449,
     "end_time": "2024-05-21T07:39:47.136506",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.116057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "view_curation = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e458f4a",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:47.165582Z",
     "iopub.status.busy": "2024-05-21T07:39:47.165293Z",
     "iopub.status.idle": "2024-05-21T07:39:47.174331Z",
     "shell.execute_reply": "2024-05-21T07:39:47.173650Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.02564,
     "end_time": "2024-05-21T07:39:47.176088",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.150448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if view_curation:\n",
    "    print(\"Training dataset Curation, with Basic SSL Fn (2 global views)\")\n",
    "    for originals, augs in train_ds.take(1):\n",
    "        for origin, aug in zip(originals, augs):\n",
    "            fig, axes = plt.subplots(1,2, figsize = (16, 8))\n",
    "            axes = axes.flatten()\n",
    "            axes[0].imshow(ops.cast(origin, \"uint8\"))\n",
    "            axes[1].imshow(ops.cast(aug, \"uint8\"))\n",
    "            axes[0].set_title(\"ORIGINAL\")\n",
    "            axes[1].set_title(\"GLOBAL VIEW AUGMENTATION\")\n",
    "            plt.show()\n",
    "\n",
    "    print(\"Validation dataset Curation, with Basic SSL Fn (2 global views)\")\n",
    "    for originals, augs in val_ds.take(1):\n",
    "        for origin, aug in zip(originals, augs):\n",
    "            fig, axes = plt.subplots(1,2, figsize = (16, 8))\n",
    "            axes = axes.flatten()\n",
    "            axes[0].imshow(ops.cast(origin, \"uint8\"))\n",
    "            axes[1].imshow(ops.cast(aug, \"uint8\"))\n",
    "            axes[0].set_title(\"ORIGINAL\")\n",
    "            axes[1].set_title(\"GLOBAL VIEW AUGMENTATION\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1891e72",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:47.202557Z",
     "iopub.status.busy": "2024-05-21T07:39:47.202292Z",
     "iopub.status.idle": "2024-05-21T07:39:47.211174Z",
     "shell.execute_reply": "2024-05-21T07:39:47.210434Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.02413,
     "end_time": "2024-05-21T07:39:47.212999",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.188869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if view_curation:\n",
    "    for multiset in train_ds_multiview.take(1):\n",
    "        global_views = multiset[:2]\n",
    "        local_views = multiset[2:]\n",
    "    for idx in tqdm(range(batch_size)):\n",
    "        print(f\"=================\\nBatch No.{idx}\\n===================\")\n",
    "        print(\"Global Views\")\n",
    "        fig, axes = plt.subplots(1,2, figsize = (20,10))\n",
    "        axes = axes.flatten()\n",
    "        g1, g2 = global_views[0][idx], global_views[1][idx] \n",
    "        axes[0].imshow(ops.cast(ops.squeeze(g1), \"uint8\"))\n",
    "        axes[1].imshow(ops.cast(ops.squeeze(g2), \"uint8\"))\n",
    "        plt.show()\n",
    "        print(\"=================\\nLocal Views\\n===================\")\n",
    "        fig, axes = plt.subplots(2,2, figsize = (16,16))\n",
    "        axes = axes.flatten()\n",
    "        local_set = [local_views[0][idx], local_views[1][idx], local_views[2][idx], local_views[3][idx]] \n",
    "\n",
    "        for k in range(4):\n",
    "            axes[k].imshow(ops.cast(ops.squeeze(local_set[k]), \"uint8\"))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86926709",
   "metadata": {
    "papermill": {
     "duration": 0.012551,
     "end_time": "2024-05-21T07:39:47.238331",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.225780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SSL experiment : Information-Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4cd0d",
   "metadata": {
    "papermill": {
     "duration": 0.01435,
     "end_time": "2024-05-21T07:39:47.268972",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.254622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> Model Save and Attention map visualize callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97520808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:47.306956Z",
     "iopub.status.busy": "2024-05-21T07:39:47.306465Z",
     "iopub.status.idle": "2024-05-21T07:39:47.331342Z",
     "shell.execute_reply": "2024-05-21T07:39:47.330427Z"
    },
    "papermill": {
     "duration": 0.046673,
     "end_time": "2024-05-21T07:39:47.333275",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.286602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelSaveCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, exp_name, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.exp_name = exp_name\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        save_dir = \"/kaggle/working/\" ; target_dir = '/kaggle/working/model_save'\n",
    "        os.makedirs(target_dir, exist_ok = True)\n",
    "        if (epoch % 1 == 0):\n",
    "            try:\n",
    "                print(\"\\nModel Saving to local notebook...\")\n",
    "                file_name = f\"{self.exp_name}_{self.model.name}_keras_v3_Epoch{epoch}.keras\"\n",
    "                filepath = os.path.join(target_dir, file_name)\n",
    "                saved_dir = self.model.save(filepath, overwrite=True)\n",
    "                if (epoch+1) % 5 == 0:\n",
    "                    print(\"\\nModel Uploading to NAS...\")\n",
    "                    upload_file(file_name, filepath)\n",
    "                    print(\"\\nModel Saved to Local NAS\")\n",
    "            except Exception as e: \n",
    "                print('Model Saving Error:\\n', e)\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        save_dir = \"/kaggle/working/\" ; target_dir = '/kaggle/working/model_save'\n",
    "        os.makedirs(target_dir, exist_ok = True)\n",
    "        if (batch % 5000 == 0) and (batch != 0): \n",
    "            try:\n",
    "                print(\"\\nModel Saving to local notebook...\")\n",
    "                file_name = f\"{self.exp_name}_{self.model.name}_keras_v3_Batch{batch}.keras\"\n",
    "                filepath = os.path.join(target_dir, file_name)\n",
    "                saved_dir = self.model.save(filepath, overwrite=True)\n",
    "                if (batch % 10000 == 0):\n",
    "                    print(\"\\nModel Uploading to NAS...\")\n",
    "                    upload_file(file_name, filepath)\n",
    "                    print(\"\\nModel Saved to Local NAS\")\n",
    "            except Exception as e: \n",
    "                print('Model Saving Error:\\n', e)\n",
    "                \n",
    "                \n",
    "class TrainingViz(keras.callbacks.Callback):\n",
    "    def __init__(self, run):\n",
    "        super().__init__()\n",
    "        self.run = run\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        configs = self.model.get_config() ; method = configs[\"SSL_method\"]\n",
    "        if method in [\"CLIP\" , \"SigLIP\", \"SPARC\"]:\n",
    "            feature_extractor = self.model\n",
    "        else:\n",
    "            feature_extractor = self.model.feature_extractor\n",
    "        viz_weights = ssl_module.att_visualize(feature_extractor, sample_img, res,\n",
    "                                              thresholding = True)\n",
    "        viz_weights = np.array(viz_weights) #batch, heads, res, res, 3\n",
    "        heads = viz_weights.shape[1]\n",
    "        origin = [\"Original Image\"]\n",
    "        col = [f\"Head{idx + 1}\" for idx in range(heads)]\n",
    "        col = origin + col\n",
    "        \n",
    "        visualize_data = []\n",
    "        for idx, weights in enumerate(viz_weights):\n",
    "            origin_img = [wandb.Image(sample_img[idx])]\n",
    "            tmp = [wandb.Image(weights[idx]) for idx in range(heads)]\n",
    "            tmp = origin_img + tmp\n",
    "            visualize_data.append(tmp)\n",
    "            del tmp, origin_img\n",
    "        tbl = wandb.Table(columns = col, data = visualize_data)\n",
    "        wandb.log({f\"Epoch{epoch+1}_{method}_result\": tbl})\n",
    "        del feature_extractor, tbl\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if (batch == (train_steps//2)) or (batch == 0): \n",
    "            try:\n",
    "                configs = self.model.get_config() ; method = configs[\"SSL_method\"]\n",
    "                if method in [\"CLIP\" , \"SigLIP\", \"SPARC\"]:\n",
    "                    feature_extractor = self.model\n",
    "                else:\n",
    "                    feature_extractor = self.model.feature_extractor\n",
    "                viz_weights = ssl_module.att_visualize(feature_extractor, sample_img, res,\n",
    "                                                      thresholding = True)\n",
    "                viz_weights = np.array(viz_weights) #batch, heads, res, res, 3\n",
    "                heads = viz_weights.shape[1]\n",
    "                origin = [\"Original Image\"]\n",
    "                col = [f\"Head{idx + 1}\" for idx in range(heads)]\n",
    "                col = origin + col\n",
    "                visualize_data = []\n",
    "                for idx, weights in enumerate(viz_weights):\n",
    "                    origin_img = [wandb.Image(sample_img[idx])]\n",
    "                    tmp = [wandb.Image(weights[idx]) for idx in range(heads)]\n",
    "                    tmp = origin_img + tmp\n",
    "                    visualize_data.append(tmp)\n",
    "                    del tmp, origin_img\n",
    "                tbl = wandb.Table(columns = col, data = visualize_data)\n",
    "                if batch == 0:\n",
    "                    wandb.log({f\"ZeroBatch_{method}_result\": tbl})\n",
    "                else:\n",
    "                    wandb.log({f\"MidEpoch_{method}_result\": tbl})\n",
    "                del feature_extractor, tbl\n",
    "                tf.keras.backend.clear_session()\n",
    "            except Exception as e:\n",
    "                print(\"Error code in callback : \", e)\n",
    "           \n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f23745",
   "metadata": {
    "papermill": {
     "duration": 0.013171,
     "end_time": "2024-05-21T07:39:47.359337",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.346166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> Training/logging helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d9a376e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:47.386121Z",
     "iopub.status.busy": "2024-05-21T07:39:47.385826Z",
     "iopub.status.idle": "2024-05-21T07:39:47.397722Z",
     "shell.execute_reply": "2024-05-21T07:39:47.396858Z"
    },
    "papermill": {
     "duration": 0.027506,
     "end_time": "2024-05-21T07:39:47.399592",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.372086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_exp(model, train_ds = train_ds, val_ds = val_ds, epochs = 10, note= None):\n",
    "    try:\n",
    "        wandb.finish()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if True :\n",
    "        wandb_config()\n",
    "        configs = model.get_config()\n",
    "        method = configs[\"SSL_method\"]\n",
    "        if method in ['CLIP', \"SigLIP\", \"SPARC\"]:\n",
    "            _ = model((example_images[:2], example_reports[:2]))\n",
    "            feature_extractor_flops = get_flops(model.image_encoder, [example_images[:1]])\n",
    "        else:\n",
    "            _ = model(test_set)\n",
    "            feature_extractor_flops = get_flops(model.feature_extractor, [sample_img[:1]])\n",
    "        env_config = {\"batch_size\" : batch_size, \"original resolution\" : res, \"local view resolution\" : small_res,\n",
    "                     \"Training steps\" : train_steps,\n",
    "                     \"Val steps\" : val_steps,\n",
    "                     \"train cases\" : (train_1 + train_2),\n",
    "                     \"val cases\" : (val_1 + val_2),\n",
    "                     \"embed_dims\" : embed_dims,\n",
    "                     \"Image resolution\" : res,\n",
    "                     \"(Image) Encoder Flops(G)\" : feature_extractor_flops,\n",
    "                     \"dtype\" : keras.mixed_precision.dtype_policy(),\n",
    "                      \"Optimizer configs\" : model.optimizer.get_config(),\n",
    "                      \"Multicrop N\" : n_multicrop,\n",
    "                     }\n",
    "        configs.update(env_config)\n",
    "        \n",
    "        wd = \"/kaggle/working/\"\n",
    "        file_name = os.path.join(wd, f\"{method}_GrandCXR_mini.keras\")\n",
    "        print(configs, \"\\n\\n\")\n",
    "        model.summary()\n",
    "        run = wandb.init(project=\"FusionFocus\", \n",
    "                         entity=\"gongbungkim\", config = configs, notes = note)\n",
    "\n",
    "        pass_error = keras.callbacks.TerminateOnNaN()\n",
    "        wb_callback = WandbMetricsLogger(log_freq = 100)\n",
    "        \n",
    "        callbacks = [pass_error, wb_callback, ModelSaveCallback(f\"FF_SSL_{method}\"), \n",
    "                     TrainingViz(run)]\n",
    "        if val_ds is not None:\n",
    "            hist = model.fit(train_ds, \n",
    "                             steps_per_epoch = train_steps, \n",
    "                             epochs = epochs, \n",
    "                             validation_data = val_ds, \n",
    "                             validation_steps = val_steps, \n",
    "                             verbose = 1,\n",
    "                             callbacks = callbacks)\n",
    "        else:\n",
    "            hist = model.fit(train_ds, \n",
    "                         steps_per_epoch = train_steps, \n",
    "                         epochs = epochs, \n",
    "                         verbose = 1,\n",
    "                         callbacks = callbacks)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f47a84",
   "metadata": {
    "papermill": {
     "duration": 0.012479,
     "end_time": "2024-05-21T07:39:47.424959",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.412480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> Feature extractor setting\n",
    "- General-Context Vision Transformer,\n",
    "- Convolution-based models:\n",
    "    - EfficientNetV2B0, Small\n",
    "    - ConvNeXtTiny, Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7085589d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:47.452777Z",
     "iopub.status.busy": "2024-05-21T07:39:47.452281Z",
     "iopub.status.idle": "2024-05-21T07:39:47.457486Z",
     "shell.execute_reply": "2024-05-21T07:39:47.456664Z"
    },
    "papermill": {
     "duration": 0.021653,
     "end_time": "2024-05-21T07:39:47.459444",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.437791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc_xxtiny_configs = get_gcvit_configs(res, 64, \"GC_ViT_xxtiny\")\n",
    "gc_xxtiny_configs[\"level_depth\"] = [1,1,2,2]\n",
    "\n",
    "gc_tiny_configs = get_gcvit_configs(res, 64, \"GC_ViT_tiny\")\n",
    "gc_tiny_configs[\"level_depth\"] = [1,1,2,4]\n",
    "\n",
    "gc_small_configs = get_gcvit_configs(res, 64, \"GC_ViT_small\")\n",
    "gc_small_configs[\"level_depth\"] = [1,2,4,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6395b3",
   "metadata": {
    "papermill": {
     "duration": 0.012549,
     "end_time": "2024-05-21T07:39:47.484683",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.472134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Setting Final Feature Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed4021ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:39:47.511526Z",
     "iopub.status.busy": "2024-05-21T07:39:47.511256Z",
     "iopub.status.idle": "2024-05-21T07:40:26.339862Z",
     "shell.execute_reply": "2024-05-21T07:40:26.338991Z"
    },
    "papermill": {
     "duration": 38.844681,
     "end_time": "2024-05-21T07:40:26.342177",
     "exception": false,
     "start_time": "2024-05-21T07:39:47.497496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b1_notop.h5\n",
      "\u001b[1m28456008/28456008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n",
      "\u001b[1m82420632/82420632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_tiny_notop.h5\n",
      "\u001b[1m111650432/111650432\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/convnext/convnext_small_notop.h5\n",
      "\u001b[1m198551472/198551472\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n",
      "Downloading data from https://github.com/james77777778/kimm/releases/download/0.1.0/mobilevitv2w125_mobilevitv2_125.cvnets_in1k.keras\n",
      "\u001b[1m30477832/30477832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "gcvit_xxtiny = get_full_model(gc_xxtiny_configs, res = res, pe_type = None, att_depth = 1, att_heads = 16, embed_dims = embed_dims)\n",
    "gcvit_tiny = get_full_model(gc_tiny_configs, res = res, pe_type = None, att_depth = 1, att_heads = 16, embed_dims = embed_dims)\n",
    "gcvit_small = get_full_model(gc_small_configs, res = res, pe_type = None, att_depth = 1, att_heads = 16, embed_dims = embed_dims)\n",
    "###############\n",
    "eff_tiny = get_full_model(\"effnet\", res = res, pe_type = 'learnable', att_depth = 1, att_heads = 16, embed_dims = embed_dims)\n",
    "eff_small = get_full_model(\"effnet_small\", res = res, pe_type = 'learnable', att_depth = 1, att_heads = 16, embed_dims = embed_dims)\n",
    "\n",
    "conv_tiny = get_full_model(\"convnext\", res = res, pe_type = 'learnable', att_depth = 1, att_heads = 16, embed_dims = embed_dims)\n",
    "conv_small = get_full_model(\"convnext_small\", res = res, pe_type = 'learnable', att_depth = 1, att_heads = 16, embed_dims = embed_dims)\n",
    "\n",
    "mlpmixer = get_full_model(\"mlpmixer_16_4_512\",res = res, att_depth = 1, att_heads = 16, embed_dims = embed_dims)\n",
    "convmixer = get_full_model(\"convmixer_16_4_512\",res = res, att_depth = 1, att_heads = 16, embed_dims = embed_dims)\n",
    "\n",
    "vit = get_full_model(\"vit\", res = res, embed_dims = 1024, att_depth = 16, pe_type = \"learnable\")\n",
    "mobilevit = kimm.models.MobileViTV2W125(input_shape = [res,res,3], include_top = False)\n",
    "mobilevit = get_full_model(mobilevit, res = res, embed_dims = 1024, pe_type = None, att_depth = 1, att_heads = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99674dd1",
   "metadata": {
    "papermill": {
     "duration": 0.030463,
     "end_time": "2024-05-21T07:40:26.404397",
     "exception": false,
     "start_time": "2024-05-21T07:40:26.373934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "> learning rate setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eec07d7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:40:26.466097Z",
     "iopub.status.busy": "2024-05-21T07:40:26.465752Z",
     "iopub.status.idle": "2024-05-21T07:40:26.470845Z",
     "shell.execute_reply": "2024-05-21T07:40:26.470042Z"
    },
    "papermill": {
     "duration": 0.037909,
     "end_time": "2024-05-21T07:40:26.472595",
     "exception": false,
     "start_time": "2024-05-21T07:40:26.434686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cosine_decay = keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate = 1e-6,\n",
    "    decay_steps = int(0.5*train_steps),\n",
    "    alpha=1e-5,\n",
    "    name='CosineDecay',\n",
    "    warmup_target=1e-3,\n",
    "    warmup_steps=train_steps - int(0.3*train_steps)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "972dd0d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:40:26.534682Z",
     "iopub.status.busy": "2024-05-21T07:40:26.534381Z",
     "iopub.status.idle": "2024-05-21T07:40:26.540177Z",
     "shell.execute_reply": "2024-05-21T07:40:26.539387Z"
    },
    "papermill": {
     "duration": 0.039097,
     "end_time": "2024-05-21T07:40:26.541949",
     "exception": false,
     "start_time": "2024-05-21T07:40:26.502852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ssl_train(module, feature_extractor, embed_dims = embed_dims, multiview = True, gradient_accumulation = None,\n",
    "             note = \"\"):\n",
    "    ssl_trainer = module(feature_extractor, embed_dims = embed_dims, multiview = multiview)\n",
    "    ssl_trainer.compile(optimizer = keras.optimizers.AdamW(learning_rate = cosine_decay,\n",
    "                                                         clipvalue = 1.0,\n",
    "                                                         #amsgrad = True,\n",
    "                                                           gradient_accumulation_steps=gradient_accumulation,\n",
    "                                                         ),\n",
    "                        #run_eagerly = True\n",
    "                      )\n",
    "    run_exp(ssl_trainer, train_ds_multiview, None, epochs = 100,\n",
    "       note = \"Without validation d/t lack of resources\" + note)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e26fa92",
   "metadata": {
    "papermill": {
     "duration": 0.030924,
     "end_time": "2024-05-21T07:40:26.603240",
     "exception": false,
     "start_time": "2024-05-21T07:40:26.572316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Barlow Twins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b31e260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:40:26.663551Z",
     "iopub.status.busy": "2024-05-21T07:40:26.663268Z",
     "iopub.status.idle": "2024-05-21T07:40:26.667194Z",
     "shell.execute_reply": "2024-05-21T07:40:26.666459Z"
    },
    "papermill": {
     "duration": 0.03614,
     "end_time": "2024-05-21T07:40:26.669092",
     "exception": false,
     "start_time": "2024-05-21T07:40:26.632952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#barlow_trainer = BarlowModel(convmixer, \n",
    "#                             embed_dims = embed_dims, multiview = True)\n",
    "#barlow_trainer.compile(optimizer = keras.optimizers.AdamW(learning_rate = cosine_decay,\n",
    "#                                                         clipvalue = 1.0,\n",
    "#                                                         #amsgrad = True\n",
    "#                                                         )\n",
    "#                      )\n",
    "#run_exp(barlow_trainer, train_ds_multiview, None, epochs = 100,\n",
    "#       note = \"Without validation d/t lack of resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1c423",
   "metadata": {
    "papermill": {
     "duration": 0.030364,
     "end_time": "2024-05-21T07:40:26.729067",
     "exception": false,
     "start_time": "2024-05-21T07:40:26.698703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VICReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e54edabd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:40:26.790928Z",
     "iopub.status.busy": "2024-05-21T07:40:26.790334Z",
     "iopub.status.idle": "2024-05-21T07:40:26.794511Z",
     "shell.execute_reply": "2024-05-21T07:40:26.793676Z"
    },
    "papermill": {
     "duration": 0.03697,
     "end_time": "2024-05-21T07:40:26.796344",
     "exception": false,
     "start_time": "2024-05-21T07:40:26.759374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#vic_trainer = VICRegModel(eff_tiny, \n",
    "#                             embed_dims = embed_dims, multiview = True)\n",
    "#vic_trainer.compile(optimizer = keras.optimizers.AdamW(learning_rate = cosine_decay,\n",
    "#                                                         clipvalue = 1.0,\n",
    "#                                                         #amsgrad = True\n",
    "#                                                         )\n",
    "#                      )\n",
    "#run_exp(vic_trainer, train_ds_multiview, None, epochs = 100,\n",
    "#       note = \"Without validation d/t lack of resources\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b57cc3",
   "metadata": {
    "papermill": {
     "duration": 0.029799,
     "end_time": "2024-05-21T07:40:26.856170",
     "exception": false,
     "start_time": "2024-05-21T07:40:26.826371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SimSiam\n",
    "- instant collapse...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a881d8a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:40:26.917478Z",
     "iopub.status.busy": "2024-05-21T07:40:26.917207Z",
     "iopub.status.idle": "2024-05-21T07:40:26.920802Z",
     "shell.execute_reply": "2024-05-21T07:40:26.920038Z"
    },
    "papermill": {
     "duration": 0.036367,
     "end_time": "2024-05-21T07:40:26.922575",
     "exception": false,
     "start_time": "2024-05-21T07:40:26.886208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ssl_train(ssl_module.SimSiam, eff_tiny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e608d5ac",
   "metadata": {
    "papermill": {
     "duration": 0.029459,
     "end_time": "2024-05-21T07:40:26.981741",
     "exception": false,
     "start_time": "2024-05-21T07:40:26.952282",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b122fff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T07:40:27.042950Z",
     "iopub.status.busy": "2024-05-21T07:40:27.042599Z",
     "iopub.status.idle": "2024-05-21T07:40:27.046405Z",
     "shell.execute_reply": "2024-05-21T07:40:27.045603Z"
    },
    "papermill": {
     "duration": 0.036695,
     "end_time": "2024-05-21T07:40:27.048266",
     "exception": false,
     "start_time": "2024-05-21T07:40:27.011571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ssl_train(ssl_module.SimCLR, eff_small,\n",
    "#         gradient_accumulation = 8, note = \"+ Attentional pooling with register\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f448d",
   "metadata": {
    "papermill": {
     "duration": 0.029537,
     "end_time": "2024-05-21T07:40:27.108454",
     "exception": false,
     "start_time": "2024-05-21T07:40:27.078917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4970b45a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T05:20:23.615957Z",
     "iopub.status.busy": "2024-05-21T05:20:23.615599Z"
    },
    "papermill": {
     "duration": 0.041915,
     "end_time": "2024-05-21T07:40:27.179924",
     "exception": false,
     "start_time": "2024-05-21T07:40:27.138009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 1188070,
     "sourceId": 13451,
     "sourceType": "competition"
    },
    {
     "datasetId": 38326,
     "sourceId": 58333,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1164135,
     "sourceId": 1950595,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2683088,
     "sourceId": 4729375,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2727590,
     "sourceId": 4800870,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4616374,
     "sourceId": 7923692,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5051531,
     "sourceId": 8471595,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 169421886,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 178771602,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 121.230469,
   "end_time": "2024-05-21T07:40:30.375034",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-21T07:38:29.144565",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0de0593b6f794be0acadc0e6dcc67b59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_75a53e3a306e498d89f081581e085ec8",
       "placeholder": "​",
       "style": "IPY_MODEL_d774101063fd4b7fafaba0c1c8dca6f3",
       "value": ""
      }
     },
     "66efb77ba4ae4d0a8e6a467c6daa26cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0de0593b6f794be0acadc0e6dcc67b59",
        "IPY_MODEL_9d451ecca7d348a9881bfb8f003600e7",
        "IPY_MODEL_b9a15576f18b469fbc28820f925df696"
       ],
       "layout": "IPY_MODEL_a41e0e65fba04843b59bcf6434a77192"
      }
     },
     "75a53e3a306e498d89f081581e085ec8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f1cdd534be344e6bbd27f703fac267a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d451ecca7d348a9881bfb8f003600e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c1f93b0329d94611846f971a82f5bb7b",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b8c2227c851848e393fbc57eafcb35c7",
       "value": 1.0
      }
     },
     "a41e0e65fba04843b59bcf6434a77192": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8c2227c851848e393fbc57eafcb35c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b9a15576f18b469fbc28820f925df696": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8f1cdd534be344e6bbd27f703fac267a",
       "placeholder": "​",
       "style": "IPY_MODEL_e61a63a347db48c187555de0fa20769c",
       "value": " 672/? [00:18&lt;00:00, 31.65it/s]"
      }
     },
     "c1f93b0329d94611846f971a82f5bb7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "d774101063fd4b7fafaba0c1c8dca6f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e61a63a347db48c187555de0fa20769c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
