{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8471595,"sourceType":"datasetVersion","datasetId":5051531},{"sourceId":8556597,"sourceType":"datasetVersion","datasetId":5112865},{"sourceId":8845065,"sourceType":"datasetVersion","datasetId":5323611},{"sourceId":169421886,"sourceType":"kernelVersion"},{"sourceId":187230573,"sourceType":"kernelVersion"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os, sys\nimport random\nimport pydicom\n\nfrom sklearn.manifold import TSNE\nimport re\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nseed = 2024\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# ML tools \nsys.path.append(\"/kaggle/input/kimm-keras-image-model-repository\"\n               )\n\nimport tensorflow as tf\nimport keras# ; keras.config.set_dtype_policy(\"mixed_float16\")\nimport kimm\nimport keras_cv\nimport keras_nlp\n\nimport cv2\nfrom skimage.io import imread\nkeras.utils.set_random_seed(seed)\nimport tensorflow_io as tfio\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow_datasets as tfds\nimport tensorflow_probability as tfp\nimport tensorflow_decision_forests as tfdf\n\nprint(f\"Tensorflow version : {tf.__version__}\")\ntry:\n    print(f\"Keras version : {keras.__version__}\")\nexcept:\n    pass\n\nfrom keras import Input, Model, ops\nfrom keras.models import load_model\n\nfrom keras.layers import Conv2D, DepthwiseConv2D, Dense, Activation, BatchNormalization, LayerNormalization, MultiHeadAttention, Embedding, Subtract, Add, Multiply, GlobalAveragePooling2D, GlobalAveragePooling1D, LayerNormalization\nfrom keras.utils import load_img, img_to_array\nfrom keras.applications import *\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tqdm.notebook import tqdm\nimport wandb\n#from wandb.keras import WandbCallback, WandbModelCheckpoint, WandbMetricsLogger\ndef wandb_config():\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    try:\n        secret_value_0 = user_secrets.get_secret(\"__gcloud_sdk_auth__\")\n        secret_value_1 = user_secrets.get_secret(\"huggingface_key\")\n        secret_value_2 = user_secrets.get_secret(\"wandb_key\")\n        !wandb login $secret_value_2\n    except:\n        secret_value_0 = user_secrets.get_secret(\"huggingface_key\")\n        secret_value_1 = user_secrets.get_secret(\"wandb_key\")\n        !wandb login $secret_value_1\n    \ndef auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        tpu = False\n        strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return tpu, strategy\n\ntpu, strategy = auto_select_accelerator()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-07-08T10:02:42.815488Z","iopub.execute_input":"2024-07-08T10:02:42.815791Z","iopub.status.idle":"2024-07-08T10:03:07.788864Z","shell.execute_reply.started":"2024-07-08T10:02:42.815765Z","shell.execute_reply":"2024-07-08T10:03:07.787899Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-08 10:02:47.588744: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-08 10:02:47.588850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-08 10:02:47.772029: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Tensorflow version : 2.15.0\nKeras version : 3.3.3\nRunning on 1 replicas\n","output_type":"stream"}]},{"cell_type":"code","source":"import ssl_module\nfrom ssl_module import get_masking_fn, get_map_fn, get_gcvit_configs, get_flops, att_visualize, get_full_model, AttentionPooling, BarlowModel, VICRegModel, Moco, SimSiam, CLIP, SigLIP\nimport nas_ftp_module\nfrom nas_ftp_module import upload_file, download_file\nssl_module.available_models()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-08T10:03:07.790765Z","iopub.execute_input":"2024-07-08T10:03:07.791211Z","iopub.status.idle":"2024-07-08T10:03:07.948534Z","shell.execute_reply.started":"2024-07-08T10:03:07.791173Z","shell.execute_reply":"2024-07-08T10:03:07.946148Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirements loaded, keras : v3.3.3, Tensorflow : v2.15.0\nRandAug Component in this SSL module :  ['random_contrast', 'random_brightness', 'random_shear', 'random_shear_1', 'random_translation', 'random_translation_1', 'KerasCVGridMasking']\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"{'models_from_kimm': ['ConvMixer1024D20',\n  'ConvMixer1536D20',\n  'ConvMixer736D32',\n  'ConvNeXtAtto',\n  'ConvNeXtBase',\n  'ConvNeXtFemto',\n  'ConvNeXtLarge',\n  'ConvNeXtNano',\n  'ConvNeXtPico',\n  'ConvNeXtSmall',\n  'ConvNeXtTiny',\n  'ConvNeXtXLarge',\n  'DenseNet121',\n  'DenseNet161',\n  'DenseNet169',\n  'DenseNet201',\n  'EfficientNetB0',\n  'EfficientNetB1',\n  'EfficientNetB2',\n  'EfficientNetB3',\n  'EfficientNetB4',\n  'EfficientNetB5',\n  'EfficientNetB6',\n  'EfficientNetB7',\n  'EfficientNetLiteB0',\n  'EfficientNetLiteB1',\n  'EfficientNetLiteB2',\n  'EfficientNetLiteB3',\n  'EfficientNetLiteB4',\n  'EfficientNetV2B0',\n  'EfficientNetV2B1',\n  'EfficientNetV2B2',\n  'EfficientNetV2B3',\n  'EfficientNetV2L',\n  'EfficientNetV2M',\n  'EfficientNetV2S',\n  'EfficientNetV2XL',\n  'GhostNet050',\n  'GhostNet100',\n  'GhostNet100V2',\n  'GhostNet130',\n  'GhostNet130V2',\n  'GhostNet160V2',\n  'HGNetBase',\n  'HGNetSmall',\n  'HGNetTiny',\n  'HGNetV2B0',\n  'HGNetV2B1',\n  'HGNetV2B2',\n  'HGNetV2B3',\n  'HGNetV2B4',\n  'HGNetV2B5',\n  'HGNetV2B6',\n  'InceptionNeXtBase',\n  'InceptionNeXtSmall',\n  'InceptionNeXtTiny',\n  'InceptionV3',\n  'LCNet035',\n  'LCNet050',\n  'LCNet075',\n  'LCNet100',\n  'LCNet150',\n  'MobileNetV2W050',\n  'MobileNetV2W100',\n  'MobileNetV2W110',\n  'MobileNetV2W120',\n  'MobileNetV2W140',\n  'MobileNetV3W050Small',\n  'MobileNetV3W075Small',\n  'MobileNetV3W100Large',\n  'MobileNetV3W100LargeMinimal',\n  'MobileNetV3W100Small',\n  'MobileNetV3W100SmallMinimal',\n  'MobileOneS0',\n  'MobileOneS1',\n  'MobileOneS2',\n  'MobileOneS3',\n  'MobileViTS',\n  'MobileViTV2W050',\n  'MobileViTV2W075',\n  'MobileViTV2W100',\n  'MobileViTV2W125',\n  'MobileViTV2W150',\n  'MobileViTV2W175',\n  'MobileViTV2W200',\n  'MobileViTXS',\n  'MobileViTXXS',\n  'RegNetX002',\n  'RegNetX004',\n  'RegNetX006',\n  'RegNetX008',\n  'RegNetX016',\n  'RegNetX032',\n  'RegNetX040',\n  'RegNetX064',\n  'RegNetX080',\n  'RegNetX120',\n  'RegNetX160',\n  'RegNetX320',\n  'RegNetY002',\n  'RegNetY004',\n  'RegNetY006',\n  'RegNetY008',\n  'RegNetY016',\n  'RegNetY032',\n  'RegNetY040',\n  'RegNetY064',\n  'RegNetY080',\n  'RegNetY120',\n  'RegNetY160',\n  'RegNetY320',\n  'RepVGGA0',\n  'RepVGGA1',\n  'RepVGGA2',\n  'RepVGGB0',\n  'RepVGGB1',\n  'RepVGGB2',\n  'RepVGGB3',\n  'ResNet101',\n  'ResNet152',\n  'ResNet18',\n  'ResNet34',\n  'ResNet50',\n  'TinyNetA',\n  'TinyNetB',\n  'TinyNetC',\n  'TinyNetD',\n  'TinyNetE',\n  'VGG11',\n  'VGG13',\n  'VGG16',\n  'VGG19',\n  'VisionTransformerBase16',\n  'VisionTransformerBase32',\n  'VisionTransformerLarge16',\n  'VisionTransformerLarge32',\n  'VisionTransformerSmall16',\n  'VisionTransformerSmall32',\n  'VisionTransformerTiny16',\n  'VisionTransformerTiny32',\n  'Xception'],\n 'models_from_keras': ['effnet',\n  'effnet_small',\n  'effnet_base',\n  'convnext',\n  'convnext_small',\n  'convnext_base',\n  'mlpmixer_patch_depth_dims',\n  'convmixer_patch_depth_dims']}"},"metadata":{}}]},{"cell_type":"markdown","source":"# Setting hyperparameters","metadata":{}},{"cell_type":"code","source":"batch_size = 16\nbatch_size = strategy.num_replicas_in_sync * batch_size\nprint('batch size', batch_size)\n\nres = int(1.5*256)\nsmall_res = 64\n\nembed_dims = 1024\nn_multicrop = 2\n\ngrayscale = True # False if using pretrained model, True if from scratch\ndepth = 4\nheads = 8\natt_dims = heads * 32\npatch_size = 24\n\nif grayscale:\n    pretrained_encoder = None\nelse:\n    #pretrained_encoder = keras.applications.EfficientNetV2B0(input_shape = [res,res,3], include_top = False)\n    pretrained_encoder = keras.applications.ConvNeXtTiny(input_shape = [res,res,3], include_top = False)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:03:07.952574Z","iopub.execute_input":"2024-07-08T10:03:07.952972Z","iopub.status.idle":"2024-07-08T10:03:07.962658Z","shell.execute_reply.started":"2024-07-08T10:03:07.952937Z","shell.execute_reply":"2024-07-08T10:03:07.961528Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"batch size 16\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- radimagenet tfrecord key : image, label\n- nih cxr tfrecord key : image_raw, label","metadata":{}},{"cell_type":"markdown","source":"# RadImageNet decoding","metadata":{}},{"cell_type":"code","source":"def _parse_tfrecord(res = res):\n    def parse_tfrecord(tfrecord):\n        features = {'image': tf.io.FixedLenFeature([], tf.string),\n                    'label': tf.io.FixedLenFeature([], tf.int64),\n                    }\n        x = tf.io.parse_single_example(tfrecord, features)\n        image_train = tf.image.decode_jpeg(x['image'], channels=1)\n        image_train = _transform_images(res = res)(image_train)\n        label = tf.cast(x[\"label\"], tf.int32)\n        return (image_train, label)\n    \n    return parse_tfrecord\n\n\ndef _transform_images(res = res):\n    def transform_images(x_train):\n        x_train = tf.image.resize_with_pad(x_train, res, res, antialias = True)\n        x_train = tf.cast(x_train, tf.uint8)\n        return x_train\n    return transform_images\n\ndef load_tfrecord_dataset(tfrecord_name, res = res, batch_size = batch_size, shuffle=True, buffer_size=10240):\n    \"\"\"load dataset from tfrecord\"\"\"\n    raw_dataset = tf.data.TFRecordDataset(tfrecord_name, compression_type = \"GZIP\")\n    raw_dataset = raw_dataset.repeat()\n    if shuffle:\n        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n    dataset = raw_dataset.map(\n        _parse_tfrecord(),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return dataset\n\ntrain_radimagenet_ds = load_tfrecord_dataset(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/RagImageNet_Train_GZIP.tfrecord\")\nval_ds = load_tfrecord_dataset(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/RagImageNet_Test_GZIP.tfrecord\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-08T10:03:07.965650Z","iopub.execute_input":"2024-07-08T10:03:07.965977Z","iopub.status.idle":"2024-07-08T10:03:09.984769Z","shell.execute_reply.started":"2024-07-08T10:03:07.965935Z","shell.execute_reply":"2024-07-08T10:03:09.983789Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# NIH CXR decoding","metadata":{}},{"cell_type":"code","source":"def _parse_tfrecord(res = res):\n    def parse_tfrecord(tfrecord):\n        features = {'image_raw': tf.io.FixedLenFeature([], tf.string),\n                    'label': tf.io.FixedLenFeature([], tf.int64),\n                    }\n        x = tf.io.parse_single_example(tfrecord, features)\n        image_train = tf.image.decode_jpeg(x['image_raw'], channels=1)\n        image_train = _transform_images(res = res)(image_train)\n        label = tf.cast(x[\"label\"], tf.int32)\n        return (image_train, label)\n    \n    return parse_tfrecord\n\n\ndef _transform_images(res = res):\n    def transform_images(x_train):\n        x_train = tf.image.resize_with_pad(x_train, res, res, antialias = True)\n        x_train = tf.cast(x_train, tf.uint8)\n        return x_train\n    return transform_images\n\ndef load_tfrecord_dataset(tfrecord_name, res = res, batch_size = batch_size, shuffle=True, buffer_size=10240):\n    \"\"\"load dataset from tfrecord\"\"\"\n    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n    raw_dataset = raw_dataset.repeat()\n    if shuffle:\n        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n    dataset = raw_dataset.map(\n        _parse_tfrecord(),\n        num_parallel_calls=tf.data.AUTOTUNE\n    )\n    if batch_size:\n        dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return dataset\n\nnih_cxr_ds = load_tfrecord_dataset(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/nih_cxr_images.tfrecords\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-08T10:03:09.986015Z","iopub.execute_input":"2024-07-08T10:03:09.986707Z","iopub.status.idle":"2024-07-08T10:03:10.244854Z","shell.execute_reply.started":"2024-07-08T10:03:09.986672Z","shell.execute_reply":"2024-07-08T10:03:10.244057Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Merging 2 datasets","metadata":{}},{"cell_type":"code","source":"train_ds = tf.data.Dataset.sample_from_datasets([train_radimagenet_ds.unbatch(), nih_cxr_ds.unbatch()], weights = [0.75, 0.25]).batch(batch_size).repeat().prefetch(tf.data.AUTOTUNE)\nval_ds_ = tf.data.Dataset.sample_from_datasets([train_radimagenet_ds.unbatch(), nih_cxr_ds.unbatch()], weights = [0.75, 0.25]).batch(32).prefetch(tf.data.AUTOTUNE)\n# train data curation\nfor images, labels in val_ds_.take(1):\n    sample_img = images\n    labels = labels\ndel val_ds_","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-08T10:03:10.245957Z","iopub.execute_input":"2024-07-08T10:03:10.246239Z","iopub.status.idle":"2024-07-08T10:03:52.320298Z","shell.execute_reply.started":"2024-07-08T10:03:10.246215Z","shell.execute_reply":"2024-07-08T10:03:52.319479Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Convert supervised dataset into SSL dataset","metadata":{}},{"cell_type":"code","source":"multiview_fn = get_map_fn(res = res, input_type = \"supervised\", output_type = \"ssl\",\n                         n_view = n_multicrop, grayscale = grayscale)\n\ntrain_ds_multiview = train_ds.unbatch().map(multiview_fn, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).prefetch(tf.data.AUTOTUNE)\nval_ds_multiview = val_ds.unbatch().map(multiview_fn, num_parallel_calls=tf.data.AUTOTUNE).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\nmask_map_fn_ = get_masking_fn(grayscale = grayscale, masking_rate = 0.6, patch_size = patch_size)\ndef masking_function(image, label):\n    return mask_map_fn_(image)\ntrain_ds_masked = train_ds.map(masking_function, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE).repeat()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:03:52.321566Z","iopub.execute_input":"2024-07-08T10:03:52.321857Z","iopub.status.idle":"2024-07-08T10:03:55.316672Z","shell.execute_reply.started":"2024-07-08T10:03:52.321832Z","shell.execute_reply":"2024-07-08T10:03:55.315895Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for test_set in val_ds_multiview.take(1):\n    test_set = test_set","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:03:55.317724Z","iopub.execute_input":"2024-07-08T10:03:55.318011Z","iopub.status.idle":"2024-07-08T10:04:02.436760Z","shell.execute_reply.started":"2024-07-08T10:03:55.317986Z","shell.execute_reply":"2024-07-08T10:04:02.435893Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"----------\n# Experiment - helper functions","metadata":{}},{"cell_type":"code","source":"df_train_rad = pd.read_csv(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/RadImgNet_train.csv\")\ndf_train_nih = pd.read_csv(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/nih_trainval_split.csv\"\n                          )\ndf_val_rad = pd.read_csv(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/RadImgNet_test.csv\")\ndf_val_nih = pd.read_csv(\"/kaggle/input/radimagenet-and-nih-cxr-dataset-tfrecord/nih_test_split.csv\")\n\n\ntrain_cases = len(df_train_rad) + len(df_train_nih) + len(df_val_nih)\nval_cases = len(df_val_rad)\n\ntrain_steps = train_cases//batch_size\nval_steps = val_cases//batch_size\nprint(f\"Total train cases : {train_cases}, validation cases : {val_cases}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:04:02.437909Z","iopub.execute_input":"2024-07-08T10:04:02.438198Z","iopub.status.idle":"2024-07-08T10:04:05.112906Z","shell.execute_reply.started":"2024-07-08T10:04:02.438174Z","shell.execute_reply":"2024-07-08T10:04:05.111691Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Total train cases : 1303237, validation cases : 163796\n","output_type":"stream"}]},{"cell_type":"code","source":"class ModelSaveCallback(keras.callbacks.Callback):\n    def __init__(self, exp_name, **kwargs):\n        super().__init__(**kwargs)\n        self.exp_name = exp_name\n    def on_epoch_end(self, epoch, logs=None):\n        save_dir = \"/kaggle/working/\" ; target_dir = '/kaggle/working/model_save'\n        os.makedirs(target_dir, exist_ok = True)\n        if (epoch % 1 == 0):\n            try:\n                print(\"\\nModel Saving to local notebook...\")\n                file_name = f\"{self.exp_name}_{self.model.name}_keras_v3_Epoch{epoch}.keras\"\n                filepath = os.path.join(target_dir, file_name)\n                saved_dir = self.model.save(filepath, overwrite=True)\n                if (epoch+1) % 5 == 0:\n                    print(\"\\nModel Uploading to NAS...\")\n                    upload_file(file_name, filepath)\n                    print(\"\\nModel Saved to Local NAS\")\n            except Exception as e: \n                print('Model Saving Error:\\n', e)\n    def on_train_batch_end(self, batch, logs=None):\n        save_dir = \"/kaggle/working/\" ; target_dir = '/kaggle/working/model_save'\n        os.makedirs(target_dir, exist_ok = True)\n        if (batch % 50000 == 0) and (batch != 0): \n            try:\n                print(\"\\nModel Saving to local notebook...\")\n                file_name = f\"{self.exp_name}_{self.model.name}_keras_v3_Batch{batch}.keras\"\n                filepath = os.path.join(target_dir, file_name)\n                saved_dir = self.model.save(filepath, overwrite=True)\n                if (batch % 10000 == 0):\n                    print(\"\\nModel Uploading to NAS...\")\n                    upload_file(file_name, filepath)\n                    print(\"\\nModel Saved to Local NAS\")\n            except Exception as e: \n                print('Model Saving Error:\\n', e)\n                \n                \nclass TrainingViz(keras.callbacks.Callback):\n    def __init__(self, run):\n        super().__init__()\n        self.run = run\n    def on_epoch_end(self, epoch, logs=None):\n        try:\n            configs = self.model.get_config() ; method = configs[\"SSL_method\"]\n            if method in [\"CLIP\" , \"SigLIP\", \"SPARC\"]:\n                feature_extractor = self.model\n            else:\n                try:\n                    feature_extractor = self.model.feature_extractor\n                except:\n                    feature_extractor = self.model.get_full_model(res = res)\n            viz_weights = ssl_module.att_visualize(feature_extractor, sample_img, res,\n                                                  thresholding = True)\n            viz_weights = np.array(viz_weights) #batch, heads, res, res, 3\n            heads = viz_weights.shape[1]\n            origin = [\"Original Image\"]\n            col = [f\"Head{idx + 1}\" for idx in range(heads)]\n            col = origin + col\n\n            visualize_data = []\n            for idx, weights in enumerate(viz_weights):\n                origin_img = [wandb.Image(sample_img[idx])]\n                tmp = [wandb.Image(weights[idx]) for idx in range(heads)]\n                tmp = origin_img + tmp\n                visualize_data.append(tmp)\n                del tmp, origin_img\n            tbl = wandb.Table(columns = col, data = visualize_data)\n            wandb.log({f\"Epoch{epoch+1}_{method}_result\": tbl})\n            del feature_extractor, tbl\n            tf.keras.backend.clear_session()\n        except Exception as e: \n                print('Model Saving Error:\\n', e)\n        \n    def on_train_batch_end(self, batch, logs=None):\n        if (batch % (10000) == 0) : \n            try:\n                configs = self.model.get_config() ; method = configs[\"SSL_method\"]\n                if method in [\"CLIP\" , \"SigLIP\", \"SPARC\"]:\n                    feature_extractor = self.model\n                else:\n                    try:\n                        feature_extractor = self.model.feature_extractor\n                    except:\n                        feature_extractor = self.model.get_full_model(res = res)\n                viz_weights = ssl_module.att_visualize(feature_extractor, sample_img, res,\n                                                      thresholding = True)\n                viz_weights = np.array(viz_weights) #batch, heads, res, res, 3\n                heads = viz_weights.shape[1]\n                origin = [\"Original Image\"]\n                col = [f\"Head{idx + 1}\" for idx in range(heads)]\n                col = origin + col\n                visualize_data = []\n                for idx, weights in enumerate(viz_weights):\n                    origin_img = [wandb.Image(sample_img[idx])]\n                    tmp = [wandb.Image(weights[idx]) for idx in range(heads)]\n                    tmp = origin_img + tmp\n                    visualize_data.append(tmp)\n                    del tmp, origin_img\n                tbl = wandb.Table(columns = col, data = visualize_data)\n                if batch == 0:\n                    wandb.log({f\"ZeroBatch_{method}_result\": tbl})\n                else:\n                    wandb.log({f\"MidEpoch_{method}_result\": tbl})\n                del feature_extractor, tbl\n                tf.keras.backend.clear_session()\n            except Exception as e:\n                print(\"Error code in callback : \", e)\n           \n        else:\n            pass","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:04:05.117600Z","iopub.execute_input":"2024-07-08T10:04:05.117873Z","iopub.status.idle":"2024-07-08T10:04:05.143302Z","shell.execute_reply.started":"2024-07-08T10:04:05.117849Z","shell.execute_reply":"2024-07-08T10:04:05.142480Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"> Real world evaluation and Segmentation callback","metadata":{}},{"cell_type":"code","source":"real_world_dir = \"/kaggle/input/real-world-medical-image-dataset-for-evaluation\" ; filenames_ = os.listdir(real_world_dir)\nfilenames_.sort()\nlabels_ = [name.split('.')[0] for name in filenames_]\nreal_world_files = [os.path.join(real_world_dir, paths) for paths in filenames_]\ndef get_img_tensor(path, res = res) :\n    file = tf.io.read_file(path)\n    c =1 if grayscale else 3\n    image = tf.io.decode_image(file, channels=c)\n    image = tf.image.resize_with_pad(image, res, res, antialias = True)\n    image = ops.cast(image, \"uint8\")\n    return image\nreal_world_images = tf.stack([get_img_tensor(f) for f in real_world_files],\n                             axis = 0)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:12:02.416449Z","iopub.execute_input":"2024-07-08T10:12:02.417337Z","iopub.status.idle":"2024-07-08T10:12:02.723837Z","shell.execute_reply.started":"2024-07-08T10:12:02.417301Z","shell.execute_reply":"2024-07-08T10:12:02.722862Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class RealWorldViz(keras.callbacks.Callback):\n    def __init__(self, run):\n        super().__init__()\n        self.run = run\n    \n    def on_train_batch_end(self, batch, logs=None):\n        if (batch % (10000) == 0) : \n            try:\n                configs = self.model.get_config() ; method = configs[\"SSL_method\"]\n                if method in [\"CLIP\" , \"SigLIP\", \"SPARC\"]:\n                    feature_extractor = self.model\n                else:\n                    try:\n                        feature_extractor = self.model.feature_extractor\n                    except:\n                        feature_extractor = self.model.get_full_model(res = res)\n                viz_weights = ssl_module.att_visualize(feature_extractor, real_world_images, res,\n                                                      thresholding = True)\n                viz_weights = np.array(viz_weights) #batch, heads, res, res, 3\n                heads = viz_weights.shape[1]\n                origin = [\"Original Image\"]\n                col = [f\"Head{idx + 1}\" for idx in range(heads)]\n                col = origin + [\"Original Label\"] + col\n                visualize_data = []\n                for idx, weights in enumerate(viz_weights):\n                    origin_img = [wandb.Image(sample_img[idx])]\n                    lab = list(labels_[idx])\n                    tmp = [wandb.Image(weights[idx]) for idx in range(heads)]\n                    tmp = origin_img + lab + tmp\n                    visualize_data.append(tmp)\n                    del tmp, origin_img\n                tbl = wandb.Table(columns = col, data = visualize_data)\n                if batch == 0:\n                    wandb.log({f\"RW_ZeroBatch_{method}_result\": tbl})\n                else:\n                    wandb.log({f\"RW_MidEpoch_{method}_result\": tbl})\n                del feature_extractor, tbl\n                tf.keras.backend.clear_session()\n            except Exception as e:\n                print(\"Error code in callback : \", e)\n        else:\n            pass\n        \n        \nclass SegViz(keras.callbacks.Callback):\n    def __init__(self, run, images, labels = None):\n        super().__init__()\n        self.run = run\n        self.images = images\n        self.labels = labels\n    def on_train_batch_end(self, batch, logs=None):\n        configs = self.model.get_config() ; method = configs[\"SSL_method\"]\n        if (batch % (10000) == 0) and  (method in [\"UnsupSeg\", \"MixedUnsupSeg\"]): \n            try:\n                heatmap, superimposed_images = self.model.get_segments(self.images)\n                origin = [\"Original Image\"]\n                col = origin + [\"Original Label\"] + [\"Segmentation Result\"]\n                visualize_data = []\n                for idx, sup_img in enumerate(superimposed_images):\n                    origin_img = [wandb.Image(self.images[idx])]\n                    if self.labels is None:\n                        lab = [\"Label not provided.\"]\n                    else:\n                        lab = list(self.labels[idx]) \n                    tmp = [wandb.Image(sup_img)]\n                    tmp = origin_img + lab + tmp\n                    visualize_data.append(tmp)\n                    del tmp, origin_img\n                tbl = wandb.Table(columns = col, data = visualize_data)\n                if batch == 0:\n                    wandb.log({f\"Seg_ZeroBatch_{method}_result\": tbl})\n                else:\n                    wandb.log({f\"Seg_MidEpoch_{method}_result\": tbl})\n                \n                tf.keras.backend.clear_session()\n            except Exception as e:\n                print(\"Error code in Segmentation callback : \", e)\n        else:\n            pass","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:11:40.697183Z","iopub.execute_input":"2024-07-08T10:11:40.698111Z","iopub.status.idle":"2024-07-08T10:11:40.719458Z","shell.execute_reply.started":"2024-07-08T10:11:40.698078Z","shell.execute_reply":"2024-07-08T10:11:40.718372Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def run_exp(model, train_ds = train_ds, val_ds = val_ds, epochs = 10, note= None, exp_name = None):\n    try:\n        wandb.finish()\n    except:\n        pass\n    \n    if True :\n        wandb_config()\n        configs = model.get_config()\n        method = configs[\"SSL_method\"]\n        try:\n            feature_extractor = model.feature_extractor\n        except:\n            feature_extractor = model.get_full_model(res = res)\n        \n        if method in ['CLIP', \"SigLIP\", \"SPARC\"]:\n            _ = model((example_images[:2], example_reports[:2]))\n        elif method in [\"SimMIM\", \"MixedMIM\",\"DistilMIM\", \"MixedUnsupSeg\"]:\n            pass\n        else:\n            _ = model(test_set)\n        feature_extractor_flops = get_flops(feature_extractor, [tf.random.normal([1,res,res,grayscale])])\n        del feature_extractor\n        \n        env_config = {\"batch_size\" : batch_size, \"Patch size\": patch_size,\n                      \"original resolution\" : res, \"local view resolution\" : small_res,\n                     \"Training steps\" : train_steps,\n                     \"Val steps\" : val_steps,\n                     \"train cases\" : train_cases,\n                     \"val cases\" : val_cases,\n                     \"embed_dims\" : embed_dims,\n                     \"Image resolution\" : res,\n                     \"(Image) Encoder Flops(G)\" : feature_extractor_flops,\n                     \"dtype\" : keras.mixed_precision.dtype_policy(),\n                      \"Optimizer configs\" : model.optimizer.get_config(),\n                      \"Multicrop N\" : n_multicrop,\n                     }\n        configs.update(env_config)\n        \n        wd = \"/kaggle/working/\"\n        file_name = os.path.join(wd, f\"{method}_radimgnet_mini.keras\")\n        print(configs, \"\\n\\n\")\n        model.summary()\n        run = wandb.init(project=\"RadImageNet\", \n                         entity=\"gongbungkim\", config = configs, notes = note,\n                        name = exp_name)\n\n        pass_error = keras.callbacks.TerminateOnNaN()\n        wb_callback = wandb.keras.WandbMetricsLogger(log_freq = 100)\n        \n        callbacks = [pass_error, wb_callback, ModelSaveCallback(f\"RI_SSL_{method}\"), \n                     TrainingViz(run),\n                    RealWorldViz(run),\n                    SegViz(run, images = sample_img),\n                    SegViz(run, images = real_world_images, labels = labels_)]\n        if val_ds is not None:\n            hist = model.fit(train_ds, \n                             steps_per_epoch = train_steps, \n                             epochs = epochs, \n                             validation_data = val_ds, \n                             validation_steps = val_steps, \n                             verbose = 1,\n                             callbacks = callbacks)\n        else:\n            hist = model.fit(train_ds, \n                         steps_per_epoch = train_steps, \n                         epochs = epochs, \n                         verbose = 1,\n                         callbacks = callbacks)\n    return hist","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:05:56.144333Z","iopub.execute_input":"2024-07-08T10:05:56.144742Z","iopub.status.idle":"2024-07-08T10:05:56.161569Z","shell.execute_reply.started":"2024-07-08T10:05:56.144709Z","shell.execute_reply":"2024-07-08T10:05:56.160556Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"cosine_decay = keras.optimizers.schedules.CosineDecay(\n    initial_learning_rate = 1e-6,\n    decay_steps = int(0.5*train_steps),\n    alpha=1e-5,\n    name='CosineDecay',\n    warmup_target=2e-4,\n    warmup_steps=train_steps - int(0.3*train_steps)\n)\n\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate = 2e-4,\n    decay_steps=20000,\n    decay_rate=0.75,\n    staircase=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:04:06.239284Z","iopub.execute_input":"2024-07-08T10:04:06.239555Z","iopub.status.idle":"2024-07-08T10:04:06.250809Z","shell.execute_reply.started":"2024-07-08T10:04:06.239533Z","shell.execute_reply":"2024-07-08T10:04:06.249880Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def ssl_train(module, feature_extractor, learning_rate = lr_schedule,\n              embed_dims = embed_dims, multiview = True, gradient_accumulation = None, use_ema = False,\n             note = \"\", name = \"\",\n             apply_barlow = False, apply_simclr = False):\n    try:\n        ssl_trainer = module(feature_extractor, embed_dims = embed_dims, multiview = multiview,\n                            apply_barlow = apply_barlow, apply_simclr = apply_simclr)\n    except Exception as e:\n        print(\"Error : \",e)\n        ssl_trainer = module(feature_extractor, embed_dims = embed_dims, multiview = multiview)\n    ssl_trainer.compile(optimizer = keras.optimizers.Adam(learning_rate = learning_rate,\n                                                         clipnorm = 0.5,\n                                                         #amsgrad = True,\n                                                           gradient_accumulation_steps=gradient_accumulation,\n                                                         use_ema = use_ema),\n                        jit_compile = False\n                      )\n    \n    run_exp(ssl_trainer, train_ds_multiview, None, epochs = 100,\n       note = \"Without validation d/t lack of resources \" + note, exp_name = name)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:04:06.251894Z","iopub.execute_input":"2024-07-08T10:04:06.252151Z","iopub.status.idle":"2024-07-08T10:04:06.260907Z","shell.execute_reply.started":"2024-07-08T10:04:06.252129Z","shell.execute_reply":"2024-07-08T10:04:06.260164Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"ibot = 0\nother = 0\nmim = 1","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:04:06.261961Z","iopub.execute_input":"2024-07-08T10:04:06.262720Z","iopub.status.idle":"2024-07-08T10:04:06.273867Z","shell.execute_reply.started":"2024-07-08T10:04:06.262695Z","shell.execute_reply":"2024-07-08T10:04:06.273001Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"if mim:\n    model_ = 'gMLP'\n    if pretrained_encoder is None:\n        note = \"From Scratch\"\n        assert grayscale is True, \"If building from scratch, make sure [grayscale = True]\"\n    else:\n        note = f\"With pretrained {pretrained_encoder.name}\"\n        assert grayscale is False, \"If using pretrained network, make sure [grayscale = False]\"\n    vanilla_model = ssl_module.get_metaformer(model_, res = res, embed_dims = 512, \n                                              att_depth = depth, att_heads = heads,att_dims = att_dims,\n                                              grayscale = grayscale, patch_size = patch_size, \n                                              register_tokens = 8,\n                                             pretrained_encoder = pretrained_encoder,\n                                             return_patches = True)\n    vanilla_model.summary()\n    #ssl_trainer = ssl_module.MixedMIM(vanilla_model, grayscale = grayscale, patch_size = patch_size)\n    ssl_trainer = ssl_module.MixedUnsupSeg(vanilla_model, q = 20, mu = 1.0)\n    \n    ssl_trainer.compile(optimizer = keras.optimizers.AdamW(learning_rate = 1e-4, \n                                                           clipnorm = 0.5,\n                                                           gradient_accumulation_steps=32,\n                                                          # use_ema = True\n                                                          ),\n                        jit_compile = False\n                      )\n    configs = ssl_trainer.get_config()\n    method = configs[\"SSL_method\"]\n    \n    ssl_trainer.summary()\n    \n    \n    run_exp(ssl_trainer, train_ds_masked, None, \n           note = note + \", Tri-tokenwise learning\", exp_name = f\"{method}_{model_}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:12:15.180106Z","iopub.execute_input":"2024-07-08T10:12:15.180966Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"Metaformer_res384_type_gMLP\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Metaformer_res384_type_gMLP\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ Input_images_grays… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m384\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ RescalingImage      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m384\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ Input_images_gra… │\n│ (\u001b[38;5;33mRescaling\u001b[0m)         │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ImagePatchingWithL… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │    \u001b[38;5;34m795,136\u001b[0m │ RescalingImage[\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mImagePatchEmbeddi…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ ImagePatchingWit… │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n│ (\u001b[38;5;33mOnesLike\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ ones_like[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mOnesLike\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ ones_like[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mOnesLike\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ ones_like[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mOnesLike\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ ones_like[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mOnesLike\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ ones_like[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mOnesLike\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ ones_like[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mOnesLike\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ ones_like[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mOnesLike\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ ones_like[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mOnesLike\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ ones_like_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ ones_like_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ ones_like_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ ones_like_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ ones_like_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ ones_like_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ ones_like_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ ones_like_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m265\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ ImagePatchingWit… │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ ones_like[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│                     │                   │            │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ MetaEncoder_gMLP_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m265\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │  \u001b[38;5;34m1,122,650\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mMetaEncoder\u001b[0m)       │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ MetaEncoder_gMLP_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m265\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │  \u001b[38;5;34m1,122,650\u001b[0m │ MetaEncoder_gMLP… │\n│ (\u001b[38;5;33mMetaEncoder\u001b[0m)       │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ MetaEncoder_gMLP_3  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m265\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │  \u001b[38;5;34m1,122,650\u001b[0m │ MetaEncoder_gMLP… │\n│ (\u001b[38;5;33mMetaEncoder\u001b[0m)       │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ MetaEncoder_gMLP_4  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m265\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │  \u001b[38;5;34m1,122,650\u001b[0m │ MetaEncoder_gMLP… │\n│ (\u001b[38;5;33mMetaEncoder\u001b[0m)       │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ MetaEncoder_gMLP… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ MetaEncoder_gMLP… │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m257\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ AttentionPooling    │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m257\u001b[0m,      │  \u001b[38;5;34m4,194,304\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m,   │            │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ \u001b[38;5;34m257\u001b[0m, \u001b[38;5;34m257\u001b[0m)]        │            │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m512\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_4          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ AttentionPooling… │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_5          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ get_item_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Representation_vec… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ get_item_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mIdentity\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Attention_weight    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ get_item_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mIdentity\u001b[0m)          │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ Input_images_grays… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ RescalingImage      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ Input_images_gra… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ImagePatchingWithL… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">795,136</span> │ RescalingImage[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ImagePatchEmbeddi…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ImagePatchingWit… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OnesLike</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ones_like[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OnesLike</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ones_like[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OnesLike</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ones_like[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OnesLike</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ones_like[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OnesLike</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ones_like[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OnesLike</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ones_like[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OnesLike</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ones_like[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OnesLike</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ ones_like_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ones_like[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OnesLike</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ones_like_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ ones_like_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ ones_like_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ ones_like_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ ones_like_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ ones_like_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ ones_like_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ ones_like_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">265</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ ImagePatchingWit… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ ones_like[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│                     │                   │            │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ MetaEncoder_gMLP_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">265</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,122,650</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MetaEncoder</span>)       │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ MetaEncoder_gMLP_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">265</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,122,650</span> │ MetaEncoder_gMLP… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MetaEncoder</span>)       │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ MetaEncoder_gMLP_3  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">265</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,122,650</span> │ MetaEncoder_gMLP… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MetaEncoder</span>)       │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ MetaEncoder_gMLP_4  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">265</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,122,650</span> │ MetaEncoder_gMLP… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MetaEncoder</span>)       │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ MetaEncoder_gMLP… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ MetaEncoder_gMLP… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ AttentionPooling    │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,304</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>,   │            │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span>)]        │            │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ AttentionPooling… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Representation_vec… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Identity</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Attention_weight    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Identity</span>)          │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,480,040\u001b[0m (36.16 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,480,040</span> (36.16 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,480,040\u001b[0m (36.16 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,480,040</span> (36.16 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"mixed_unsup_seg\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mixed_unsup_seg\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ Metaformer_res384_type_gMLP     │ ?                      │     \u001b[38;5;34m9,480,040\u001b[0m │\n│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ Metaformer_res384_type_gMLP     │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,480,040</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,480,040\u001b[0m (36.16 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,480,040</span> (36.16 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,480,040\u001b[0m (36.16 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,480,040</span> (36.16 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n{'feature_extractor_name': 'Metaformer_res384_type_gMLP', 'SSL_method': 'MixedUnsupSeg', 'Q(n_cluster)': 20, 'Mu(continuity loss weight)': 1.0, 'batch_size': 16, 'Patch size': 24, 'original resolution': 384, 'local view resolution': 64, 'Training steps': 81452, 'Val steps': 10237, 'train cases': 1303237, 'val cases': 163796, 'embed_dims': 1024, 'Image resolution': 384, '(Image) Encoder Flops(G)': 4.057112546, 'dtype': <FloatDTypePolicy \"float32\">, 'Optimizer configs': {'name': 'adamw', 'learning_rate': 9.999999747378752e-05, 'weight_decay': 0.004, 'clipnorm': 0.5, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': 32, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'Multicrop N': 2} \n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"mixed_unsup_seg\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mixed_unsup_seg\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ Metaformer_res384_type_gMLP     │ ?                      │     \u001b[38;5;34m9,480,040\u001b[0m │\n│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ Metaformer_res384_type_gMLP     │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,480,040</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,480,040\u001b[0m (36.16 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,480,040</span> (36.16 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,480,040\u001b[0m (36.16 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,480,040</span> (36.16 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.4 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240708_101220-trocslh8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/gongbungkim/RadImageNet/runs/trocslh8' target=\"_blank\">MixedUnsupSeg_gMLP</a></strong> to <a href='https://wandb.ai/gongbungkim/RadImageNet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/gongbungkim/RadImageNet' target=\"_blank\">https://wandb.ai/gongbungkim/RadImageNet</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/gongbungkim/RadImageNet/runs/trocslh8' target=\"_blank\">https://wandb.ai/gongbungkim/RadImageNet/runs/trocslh8</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720433607.544239     102 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720433636.802697     102 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"Error code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m10000/81452\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:30:09\u001b[0m 277ms/step - Tokenwise_Barlow_loss: 0.2817 - Tokenwise_VIC_loss: 95.0326 - UnsupSegLoss: 6473.9126 - loss: 160.0534Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m20000/81452\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:46:45\u001b[0m 280ms/step - Tokenwise_Barlow_loss: 0.2373 - Tokenwise_VIC_loss: 93.1498 - UnsupSegLoss: 3610.8975 - loss: 129.4960Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m30000/81452\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:01:00\u001b[0m 281ms/step - Tokenwise_Barlow_loss: 0.2124 - Tokenwise_VIC_loss: 92.2957 - UnsupSegLoss: 2496.3699 - loss: 117.4719Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m40000/81452\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:14:47\u001b[0m 282ms/step - Tokenwise_Barlow_loss: 0.1942 - Tokenwise_VIC_loss: 91.7339 - UnsupSegLoss: 1904.2306 - loss: 110.9704Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m50000/81452\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:28:05\u001b[0m 283ms/step - Tokenwise_Barlow_loss: 0.1797 - Tokenwise_VIC_loss: 91.2995 - UnsupSegLoss: 1542.0167 - loss: 106.8993\nModel Saving to local notebook...\n\nModel Uploading to NAS...\n\nModel Saved to Local NAS\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m60000/81452\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:41:25\u001b[0m 284ms/step - Tokenwise_Barlow_loss: 0.1679 - Tokenwise_VIC_loss: 90.9467 - UnsupSegLoss: 1297.2739 - loss: 104.0873Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m70000/81452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m54:09\u001b[0m 284ms/step - Tokenwise_Barlow_loss: 0.1581 - Tokenwise_VIC_loss: 90.6490 - UnsupSegLoss: 1120.0758 - loss: 102.0078Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m80000/81452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m6:52\u001b[0m 284ms/step - Tokenwise_Barlow_loss: 0.1500 - Tokenwise_VIC_loss: 90.3885 - UnsupSegLoss: 985.5346 - loss: 100.3938Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m81452/81452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - Tokenwise_Barlow_loss: 0.1488 - Tokenwise_VIC_loss: 90.3531 - UnsupSegLoss: 968.6736 - loss: 100.1887\nModel Saving to local notebook...\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\n\u001b[1m81452/81452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23330s\u001b[0m 285ms/step - Tokenwise_Barlow_loss: 0.1488 - Tokenwise_VIC_loss: 90.3531 - UnsupSegLoss: 968.6622 - loss: 100.1885\nEpoch 2/10\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m10000/81452\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:29:24\u001b[0m 277ms/step - Tokenwise_Barlow_loss: 0.0865 - Tokenwise_VIC_loss: 88.3479 - UnsupSegLoss: 36.9164 - loss: 88.8035Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m20000/81452\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:46:33\u001b[0m 280ms/step - Tokenwise_Barlow_loss: 0.0847 - Tokenwise_VIC_loss: 88.2639 - UnsupSegLoss: 34.8480 - loss: 88.6972Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m30000/81452\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m4:01:04\u001b[0m 281ms/step - Tokenwise_Barlow_loss: 0.0831 - Tokenwise_VIC_loss: 88.1870 - UnsupSegLoss: 34.6640 - loss: 88.6167Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m40000/81452\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m3:14:26\u001b[0m 281ms/step - Tokenwise_Barlow_loss: 0.0814 - Tokenwise_VIC_loss: 88.1176 - UnsupSegLoss: 32.7895 - loss: 88.5269Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m50000/81452\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2:27:37\u001b[0m 282ms/step - Tokenwise_Barlow_loss: 0.0804 - Tokenwise_VIC_loss: 88.0604 - UnsupSegLoss: 31.1522 - loss: 88.4524\nModel Saving to local notebook...\n\nModel Uploading to NAS...\n\nModel Saved to Local NAS\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m60000/81452\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1:41:03\u001b[0m 283ms/step - Tokenwise_Barlow_loss: 0.0793 - Tokenwise_VIC_loss: 88.0037 - UnsupSegLoss: 29.9153 - loss: 88.3822Using Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nUsing Raw model with Att pooling \n Possible error: \n 'Functional' object has no attribute 'get_full_model'\nError code in callback :  This table expects 10 columns: ['Original Image', 'Original Label', 'Head1', 'Head2', 'Head3', 'Head4', 'Head5', 'Head6', 'Head7', 'Head8'], found 23\nError code in Segmentation callback :  local variable 'feature_extractor' referenced before assignment\nError code in Segmentation callback :  This table expects 3 columns: ['Original Image', 'Original Label', 'Segmentation Result'], found 16\n\u001b[1m67851/81452\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m1:04:08\u001b[0m 283ms/step - Tokenwise_Barlow_loss: 0.0785 - Tokenwise_VIC_loss: 87.9622 - UnsupSegLoss: 28.9690 - loss: 88.3303","output_type":"stream"}]},{"cell_type":"code","source":"if ibot:\n    ssl_trainer = ssl_module.iBOT(att_depth = depth, att_dims = att_dims, att_heads = heads,\n                                  embed_dims = 2048, patch_size = patch_size,\n\n                                  multiview = True, apply_simclr = False,\n                                  grayscale = True\n                                 )\n    ssl_trainer.compile(optimizer = keras.optimizers.AdamW(learning_rate = lr_schedule,\n                                                         clipnorm = 1.0, use_ema = True),\n                       jit_compile = False)\n    run_exp(ssl_trainer, train_ds_multiview, None, epochs = 100,\n           note = \"+ NEW aug, New Patching\", exp_name = \"iBOT_VanillaViT\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-08T10:04:12.954561Z","iopub.status.idle":"2024-07-08T10:04:12.954917Z","shell.execute_reply.started":"2024-07-08T10:04:12.954748Z","shell.execute_reply":"2024-07-08T10:04:12.954764Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if other:\n    model_ = 'gMLP'\n    if pretrained_encoder is None:\n        note = \"From Scratch\"\n        assert grayscale is True, \"If building from scratch, make sure [grayscale = True]\"\n    else:\n        note = f\"With pretrained {pretrained_encoder.name}\"\n        assert grayscale is False, \"If using pretrained network, make sure [grayscale = False]\"\n    vanilla_model = ssl_module.get_metaformer(model_, res = res, embed_dims = embed_dims, \n                                              att_depth = depth, att_heads = heads,att_dims = att_dims,\n                                              grayscale = grayscale, patch_size = patch_size, \n                                              register_tokens = 4,\n                                             pretrained_encoder = pretrained_encoder)\n    ssl_train(ssl_module.DINO, vanilla_model, \n             note = note + \" / 2-view\",\n             name = f\"DINO_{model_}_reg\",\n             learning_rate = lr_schedule,\n             multiview = False,\n             gradient_accumulation = 32)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:04:12.956616Z","iopub.status.idle":"2024-07-08T10:04:12.956926Z","shell.execute_reply.started":"2024-07-08T10:04:12.956773Z","shell.execute_reply":"2024-07-08T10:04:12.956785Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}