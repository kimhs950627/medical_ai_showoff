{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3e9d65",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-15T15:23:38.156090Z",
     "iopub.status.busy": "2024-07-15T15:23:38.155718Z",
     "iopub.status.idle": "2024-07-15T15:23:59.146494Z",
     "shell.execute_reply": "2024-07-15T15:23:59.145493Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 20.999076,
     "end_time": "2024-07-15T15:23:59.148635",
     "exception": false,
     "start_time": "2024-07-15T15:23:38.149559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 15:23:40.627967: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-15 15:23:40.628076: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-15 15:23:40.755975: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirements loaded, keras : v3.4.1, Tensorflow : v2.15.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "seed = 2024\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ML tools \n",
    "\n",
    "import tensorflow as tf\n",
    "import keras #; keras.config.set_dtype_policy(\"mixed_float16\")\n",
    "import keras_nlp\n",
    "import keras_cv\n",
    "from keras import ops\n",
    "\n",
    "keras.utils.set_random_seed(seed)\n",
    "\n",
    "import cv2\n",
    "import tensorflow_io as tfio\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from keras import Input, Model, layers\n",
    "from keras.models import load_model\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Conv2D, DepthwiseConv2D, Dense, Activation, BatchNormalization, LayerNormalization, MultiHeadAttention, Embedding, Subtract, Add, Multiply, GlobalAveragePooling2D, GlobalAveragePooling1D, LayerNormalization\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications import *\n",
    "import os, sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tqdm.notebook import tqdm\n",
    "print(f\"Requirements loaded, keras : v{keras.__version__}, Tensorflow : v{tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf1af7b",
   "metadata": {
    "papermill": {
     "duration": 0.004076,
     "end_time": "2024-07-15T15:23:59.157287",
     "exception": false,
     "start_time": "2024-07-15T15:23:59.153211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e382cdc6",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-15T15:23:59.167128Z",
     "iopub.status.busy": "2024-07-15T15:23:59.166512Z",
     "iopub.status.idle": "2024-07-15T15:23:59.172527Z",
     "shell.execute_reply": "2024-07-15T15:23:59.171662Z"
    },
    "papermill": {
     "duration": 0.012995,
     "end_time": "2024-07-15T15:23:59.174447",
     "exception": false,
     "start_time": "2024-07-15T15:23:59.161452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters about images\n",
    "res = 384\n",
    "batch_size = 16\n",
    "# hyperparameters about text\n",
    "seq_len = 128\n",
    "# hyperparameters about cross attentive decoder\n",
    "att_depth = 4\n",
    "att_heads = 8\n",
    "att_dims = att_heads * 32\n",
    "use_bias = False\n",
    "\n",
    "train_cases = 70108\n",
    "val_cases = 9972\n",
    "train_steps = train_cases//batch_size\n",
    "val_steps = val_cases//batch_size\n",
    "\n",
    "train_dataset_dir = '/kaggle/input/roco-v2-tfrecord-dataset/Tot70108cases_RoCoV2_radiology_train_GZIP.tfrecord'\n",
    "val_dataset_dir = '/kaggle/input/roco-v2-tfrecord-dataset/Tot9972cases_RoCoV2_radiology_test_GZIP.tfrecord'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb959c2",
   "metadata": {
    "papermill": {
     "duration": 0.004113,
     "end_time": "2024-07-15T15:23:59.183082",
     "exception": false,
     "start_time": "2024-07-15T15:23:59.178969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parsing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc255085",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-15T15:23:59.193278Z",
     "iopub.status.busy": "2024-07-15T15:23:59.192884Z",
     "iopub.status.idle": "2024-07-15T15:24:12.390574Z",
     "shell.execute_reply": "2024-07-15T15:24:12.389641Z"
    },
    "papermill": {
     "duration": 13.205691,
     "end_time": "2024-07-15T15:24:12.393035",
     "exception": false,
     "start_time": "2024-07-15T15:23:59.187344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _parse_tfrecord(c, res = res):\n",
    "    def parse_tfrecord(tfrecord):\n",
    "        features = {'image': tf.io.FixedLenFeature([], tf.string),\n",
    "                    'report': tf.io.FixedLenFeature([], tf.string),\n",
    "                    }\n",
    "        x = tf.io.parse_single_example(tfrecord, features)\n",
    "        image_train = tf.image.decode_jpeg(x['image'], channels=c)\n",
    "        image_train = _transform_images(res = res)(image_train)\n",
    "        report = tf.cast(x[\"report\"], tf.string)\n",
    "        return image_train, report\n",
    "    \n",
    "    return parse_tfrecord\n",
    "\n",
    "\n",
    "def _transform_images(res = res):\n",
    "    def transform_images(x_train):\n",
    "        x_train = tf.image.resize_with_pad(x_train, res, res, antialias = True)\n",
    "        x_train = tf.cast(x_train, tf.uint8)\n",
    "        return x_train\n",
    "    return transform_images\n",
    "\n",
    "def load_tfrecord_dataset(tfrecord_name, res = res, batch_size = batch_size, shuffle=True, buffer_size=10240, grayscale = False):\n",
    "    \"\"\"load dataset from tfrecord\"\"\"\n",
    "    c = 1 if grayscale else 3\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name, compression_type = \"GZIP\")\n",
    "    raw_dataset = raw_dataset.repeat()\n",
    "    if shuffle:\n",
    "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = raw_dataset.map(\n",
    "        _parse_tfrecord(c = c, res = res),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_ds = load_tfrecord_dataset(train_dataset_dir)\n",
    "val_ds = load_tfrecord_dataset(val_dataset_dir) #image, report 2 outputs\n",
    "\n",
    "for a, b in val_ds.take(1):\n",
    "    val_images = a\n",
    "    val_texts = b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97813652",
   "metadata": {
    "papermill": {
     "duration": 0.004276,
     "end_time": "2024-07-15T15:24:12.401836",
     "exception": false,
     "start_time": "2024-07-15T15:24:12.397560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing Natural language decoder (pretrained on plain texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f1d567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T15:24:12.411835Z",
     "iopub.status.busy": "2024-07-15T15:24:12.411471Z",
     "iopub.status.idle": "2024-07-15T15:24:37.710121Z",
     "shell.execute_reply": "2024-07-15T15:24:37.709229Z"
    },
    "papermill": {
     "duration": 25.305974,
     "end_time": "2024-07-15T15:24:37.712059",
     "exception": false,
     "start_time": "2024-07-15T15:24:12.406085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching 'model.safetensors' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.safetensors.index.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'config.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'config.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.weights.h5' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.safetensors' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.safetensors.index.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'preprocessor.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'assets/tokenizer/vocabulary.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'assets/tokenizer/merges.txt' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt2_backbone\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gpt2_backbone\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ token_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_embedding     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">38,597,376</span> │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ position_embedding  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">786,432</span> │ token_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionEmbedding</span>) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_add      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ token_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ position_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_dropout  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embeddings_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ padding_mask        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_0 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ embeddings_dropo… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_4 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_5 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_6 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_7 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_8 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_9 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_norm          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ token_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_embedding     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │ \u001b[38;5;34m38,597,376\u001b[0m │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mReversibleEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ position_embedding  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │    \u001b[38;5;34m786,432\u001b[0m │ token_embedding[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mPositionEmbedding\u001b[0m) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_add      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ token_embedding[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │                   │            │ position_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_dropout  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ embeddings_add[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ padding_mask        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_0 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ embeddings_dropo… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_4 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_5 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_6 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_7 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_8 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_9 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_norm          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │      \u001b[38;5;34m1,536\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">126,221,568</span> (481.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m126,221,568\u001b[0m (481.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,800,192</span> (6.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,800,192\u001b[0m (6.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,421,376</span> (474.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m124,421,376\u001b[0m (474.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt_freeset = \"gpt2_base_en\"\n",
    "text_only_decoder = keras_nlp.models.Backbone.from_preset(\n",
    "    gpt_freeset,\n",
    "    trainable=False,\n",
    ")\n",
    "preprocessor = keras_nlp.models.GPT2Preprocessor.from_preset(\n",
    "    gpt_freeset,\n",
    "    sequence_length=seq_len,\n",
    "    add_start_token = False\n",
    ")\n",
    "preprocessor.trainable = False\n",
    "text_only_decoder.enable_lora(8)\n",
    "text_only_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b9bc7ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T15:24:37.726728Z",
     "iopub.status.busy": "2024-07-15T15:24:37.726388Z",
     "iopub.status.idle": "2024-07-15T15:24:39.529202Z",
     "shell.execute_reply": "2024-07-15T15:24:39.528047Z"
    },
    "papermill": {
     "duration": 1.812759,
     "end_time": "2024-07-15T15:24:39.531540",
     "exception": false,
     "start_time": "2024-07-15T15:24:37.718781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#according to summarized GPT2 model structure:\n",
    "text_embed_dims = 768\n",
    "n_vocab = preprocessor.tokenizer.vocabulary_size()\n",
    "pad_token = preprocessor.tokenizer.pad_token_id\n",
    "start_packer = keras_nlp.layers.StartEndPacker(\n",
    "    sequence_length=seq_len,\n",
    "    start_value=None,\n",
    ")\n",
    "prompt_words_ = preprocessor.tokenizer([\"This image shows\"]) ; start_word_idx = len(prompt_words_[0]) \n",
    "prompt = start_packer(prompt_words_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c7bf5",
   "metadata": {
    "papermill": {
     "duration": 0.006429,
     "end_time": "2024-07-15T15:24:39.544839",
     "exception": false,
     "start_time": "2024-07-15T15:24:39.538410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modelling\n",
    "- building a single model that functions as a testbed;\n",
    "    - image encoder, text encoder(GPT2), cross-attentive attention layer로 구성\n",
    "    - 모델은 image와 raw text를 input으로 받고\n",
    "        - image -> encoder -> [CLS_token, encoded_patches, attention_weight] 3개의 output return\n",
    "        - raw text -> GPT2 -> encoded_text & get mask\n",
    "    - cross_attended_text = TransformerDecoder(query = raw_text, key = encoded_patches, value = encoded_patches, mask = mask) -> Dense -> Perplexity, accuracy 측정\n",
    "    - 위 과정과 cls_token 및 pooled encoded_text의 batchwise cross-correlation 구해서 contrastive accuracy 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaf968a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T15:24:39.560129Z",
     "iopub.status.busy": "2024-07-15T15:24:39.559785Z",
     "iopub.status.idle": "2024-07-15T15:24:39.581844Z",
     "shell.execute_reply": "2024-07-15T15:24:39.580953Z"
    },
    "papermill": {
     "duration": 0.032224,
     "end_time": "2024-07-15T15:24:39.583712",
     "exception": false,
     "start_time": "2024-07-15T15:24:39.551488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MedicalCaptioner(keras.Model): \n",
    "    def __init__(self, image_encoder, \n",
    "                 preprocessor, text_encoder,\n",
    "                 att_heads = att_heads, att_dims = att_dims, att_depth = att_depth,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.image_encoder = image_encoder\n",
    "        self.text_encoder = text_encoder ; \n",
    "        self.text_preprocessor = preprocessor ; self.text_preprocessor.trainable = False\n",
    "        \n",
    "        self.mlp_text = keras.layers.Dense(units = n_vocab, activation = \"softmax\", name = \"VocabClassifier\")\n",
    "        self.att_heads = att_heads\n",
    "        self.att_dims = att_dims\n",
    "        self.att_depth = att_depth\n",
    "        self.cross_attention_layers = [keras_nlp.layers.TransformerDecoder(att_dims, att_heads, name = f\"CrossMHADecoder{i+1}\",\n",
    "                                                                          dropout = 0.2, activation = \"gelu\") for i in range(att_depth)]\n",
    "        self.compute_perplexity = keras_nlp.metrics.Perplexity(mask_token_id=pad_token)\n",
    "        self.compute_accuracy = keras.metrics.SparseCategoricalAccuracy()\n",
    "        self.compute_softmax_loss = keras.losses.SparseCategoricalCrossentropy(ignore_class = pad_token, reduction = None)\n",
    "    def get_config(self):\n",
    "        return {\"Image encoder name\": self.image_encoder.name,\n",
    "               \"Text encoder name\" : self.text_encoder.name,\n",
    "               \"cross attention heads\" : att_heads, \"intermediate dims\" : self.att_dims, \"cross attention depth\" : self.att_depth\n",
    "               }\n",
    "    def call(self, image, text):\n",
    "        if len(self.image_encoder.outputs) == 2 :\n",
    "            image_token, encoded_patches = self.image_encoder(image)\n",
    "        elif len(self.image_encoder.outputs) == 3 :\n",
    "            image_token, encoded_patches, image_attention_weights = self.image_encoder(image)\n",
    "        elif len(self.image_encoder.outputs) == 1:\n",
    "            encoded_patches = self.image_encoder(image)\n",
    "        \n",
    "        if len(ops.shape(encoded_patches)) == 4:\n",
    "            _, w, h, dims = ops.shape(encoded_patches)\n",
    "            encoded_patches = ops.reshape(encoded_patches, [-1, w*h, dims])\n",
    "\n",
    "        preprocessed_text = self.text_preprocessor(text) ; text_mask = preprocessed_text[\"padding_mask\"]\n",
    "        original_token = preprocessed_text[\"token_ids\"]\n",
    "        encoded_text = self.text_encoder(preprocessed_text)\n",
    "        \n",
    "        # Cross-Attention\n",
    "        for idx, decoder in enumerate(self.cross_attention_layers):\n",
    "            encoded_text = decoder(decoder_sequence = encoded_text,\n",
    "                                  encoder_sequence = encoded_patches,\n",
    "                                  decoder_padding_mask = text_mask)\n",
    "        vocab_p = self.mlp_text(encoded_text)\n",
    "        \n",
    "        return vocab_p, original_token, text_mask\n",
    "    \n",
    "    def get_next_proba_fn(self, image, prompt):\n",
    "        \n",
    "        def next(prompt, cache, index):\n",
    "            prompt = self.text_preprocessor.tokenizer.detokenize(prompt)\n",
    "            vocab_proba = self(image, prompt)[0]\n",
    "            logits = vocab_proba[:, index - 1, :]\n",
    "            # Ignore hidden states for now; only needed for contrastive search.\n",
    "            hidden_states = None\n",
    "            return logits, hidden_states, cache\n",
    "        return next\n",
    "    def infer(self, image):\n",
    "        if len(ops.shape(image)) == 3:\n",
    "            image = image[tf.newaxis, ...]\n",
    "        next_fn = self.get_next_proba_fn(image = image, prompt = prompt)\n",
    "        \n",
    "        greedy_sampler = keras_nlp.samplers.GreedySampler()\n",
    "        nuc_sampler = keras_nlp.samplers.TopPSampler(p=0.5, k = 10)\n",
    "        \n",
    "        greedy_tokens = greedy_sampler(next=next_fn,\n",
    "                                prompt=prompt,\n",
    "                                index=start_word_idx)\n",
    "        \n",
    "        nuc_tokens = nuc_sampler(next=next_fn,\n",
    "                                prompt=prompt,\n",
    "                                index=start_word_idx)\n",
    "        \n",
    "        greedy_words, nuc_words = self.text_preprocessor.tokenizer.detokenize(greedy_tokens), self.text_preprocessor.tokenizer.detokenize(nuc_tokens)\n",
    "        greedy_words, nuc_words = greedy_words.numpy(), nuc_words.numpy()\n",
    "        greedy_words = [w.decode() for w in greedy_words]\n",
    "        nuc_words = [w.decode() for w in nuc_words]\n",
    "        return {\"greedy_sampling\" : greedy_words,\n",
    "               \"nucleus_sampling\" : nuc_words}\n",
    "    \n",
    "    def train_step(self, dataset): \n",
    "        image, text = dataset\n",
    "        with tf.GradientTape() as tape: \n",
    "            vocab_p, original_tokens, text_mask = self(image, text)\n",
    "            \n",
    "            loss = self.compute_softmax_loss(y_true = original_tokens, y_pred = vocab_p)\n",
    "            perplexity = self.compute_perplexity(y_true = original_tokens, y_pred = vocab_p)\n",
    "            accuracy = self.compute_accuracy(y_true = original_tokens, y_pred = vocab_p, sample_weight = text_mask)\n",
    "            loss = ops.mean(loss)\n",
    "            \n",
    "        grads = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        \n",
    "        return {\"VocabSoftmaxLoss\" : loss,\n",
    "               \"Perplexity\" : perplexity,\n",
    "               \"TokenAccuracy\" : accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01caf5bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T15:24:39.597405Z",
     "iopub.status.busy": "2024-07-15T15:24:39.597119Z",
     "iopub.status.idle": "2024-07-15T16:23:51.482553Z",
     "shell.execute_reply": "2024-07-15T16:23:51.481491Z"
    },
    "papermill": {
     "duration": 3552.260512,
     "end_time": "2024-07-15T16:23:51.850569",
     "exception": false,
     "start_time": "2024-07-15T15:24:39.590057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b1_notop.h5\n",
      "\u001b[1m28456008/28456008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "\u001b[1m4381/4381\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3512s\u001b[0m 774ms/step - Perplexity: 374.5047 - TokenAccuracy: 0.7131 - VocabSoftmaxLoss: 0.2340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7e385464c550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effnet = keras.applications.EfficientNetV2B1(include_top = False,\n",
    "                                            input_shape = [res,res,3])\n",
    "model = MedicalCaptioner(effnet, preprocessor, text_only_decoder)\n",
    "model.compile(optimizer = keras.optimizers.AdamW(learning_rate = 1e-4),\n",
    "             jit_compile = False)\n",
    "model.fit(train_ds, epochs = 1, steps_per_epoch = train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6377781c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T16:23:52.581266Z",
     "iopub.status.busy": "2024-07-15T16:23:52.580863Z",
     "iopub.status.idle": "2024-07-15T16:27:28.598317Z",
     "shell.execute_reply": "2024-07-15T16:27:28.597458Z"
    },
    "papermill": {
     "duration": 216.744667,
     "end_time": "2024-07-15T16:27:28.959352",
     "exception": false,
     "start_time": "2024-07-15T16:23:52.214685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721060634.489449      25 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'greedy_sampling': ['This image shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows'],\n",
       "  'nucleus_sampling': ['This image shows showed obtained collected extracted deployedantedractedvedcututsuts cuts changessessississssssessesslexcessiesents nodes veins veins nodes node processasmasmimus moris moris morIS mortARS mortPET mort pet fet cat termin PET deline PET reverberan oscillan compensas regenerch compenschi compens Chi compens Chi reverber mu reverberu delineU appreciO delineo appreciino appreciico reverberano delineero regeneroro degenerchio delinechio excavso delineso disliesino disosesato transicatesinotransatesatinrot transizes carcinlet transizesatinlet transizesuminlets noniatesatinies interifies']},\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'Initial CT angiography chest demonstrating multifocal lung infiltrates.'>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer(val_images[0]), val_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc5c54e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T16:27:29.693483Z",
     "iopub.status.busy": "2024-07-15T16:27:29.692834Z",
     "iopub.status.idle": "2024-07-15T16:30:51.917375Z",
     "shell.execute_reply": "2024-07-15T16:30:51.916214Z"
    },
    "papermill": {
     "duration": 202.96471,
     "end_time": "2024-07-15T16:30:52.287217",
     "exception": false,
     "start_time": "2024-07-15T16:27:29.322507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'greedy_sampling': ['This image shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows shows'],\n",
       "  'nucleus_sampling': ['This image shows shown demonstrated enhanced enhanced increased reduced decreased Increased Increased Increased Enhanced Enhanced enhancedifiedizedizedulatedculatedculated compressed compact compressed compression compression density intensityintensityfrequency transient minimalimalialographicitudinalinesud abdominalinesod anteriorinisrod upperinesrod leftlines rod leftions nod twoionsung Twousions union Tra imagingionsunion Path imagingions differentiation Cancerotherapy lesions consolidation Disease therapeutic lesions consolidation Medicine interrogationusions differentiation).\"strationulations differentiation).\"strationrations differentiation #hesesograms differentiation <hesesogram expansion ≥ denotesograph consolidation (< denote photographmentation < depict picturetreatment ≥ depict view treatment ≥ denote picturetreatment (> evaluate picture treated (> assess Video measured> Select movie treated']},\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'Coronal CT abdomen showing small intestine (yellow arrow) predominantly on the right side and the colon (white arrow) predominantly on the left side'>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer(val_images[4]), val_texts[4]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5073985,
     "sourceId": 8501861,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 4694,
     "sourceId": 6074,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4041.357733,
   "end_time": "2024-07-15T16:30:56.721737",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-15T15:23:35.364004",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
