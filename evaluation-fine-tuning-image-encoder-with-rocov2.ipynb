{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e35f8b0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-14T16:34:43.999295Z",
     "iopub.status.busy": "2024-07-14T16:34:43.998813Z",
     "iopub.status.idle": "2024-07-14T16:35:09.684724Z",
     "shell.execute_reply": "2024-07-14T16:35:09.683301Z"
    },
    "papermill": {
     "duration": 25.695775,
     "end_time": "2024-07-14T16:35:09.687721",
     "exception": false,
     "start_time": "2024-07-14T16:34:43.991946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 16:34:47.189676: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-14 16:34:47.189801: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-14 16:34:47.356311: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirements loaded, keras : v3.4.1, Tensorflow : v2.15.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "seed = 2024\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ML tools \n",
    "\n",
    "import tensorflow as tf\n",
    "import keras #; keras.config.set_dtype_policy(\"mixed_float16\")\n",
    "import keras_nlp\n",
    "import keras_cv\n",
    "from keras import ops\n",
    "\n",
    "keras.utils.set_random_seed(seed)\n",
    "\n",
    "import cv2\n",
    "import tensorflow_io as tfio\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from keras import Input, Model, layers\n",
    "from keras.models import load_model\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Conv2D, DepthwiseConv2D, Dense, Activation, BatchNormalization, LayerNormalization, MultiHeadAttention, Embedding, Subtract, Add, Multiply, GlobalAveragePooling2D, GlobalAveragePooling1D, LayerNormalization\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications import *\n",
    "import os, sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tqdm.notebook import tqdm\n",
    "print(f\"Requirements loaded, keras : v{keras.__version__}, Tensorflow : v{tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb915b",
   "metadata": {
    "papermill": {
     "duration": 0.004784,
     "end_time": "2024-07-14T16:35:09.697460",
     "exception": false,
     "start_time": "2024-07-14T16:35:09.692676",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setting hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebaf8945",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-14T16:35:09.709383Z",
     "iopub.status.busy": "2024-07-14T16:35:09.708630Z",
     "iopub.status.idle": "2024-07-14T16:35:09.715912Z",
     "shell.execute_reply": "2024-07-14T16:35:09.714730Z"
    },
    "papermill": {
     "duration": 0.015961,
     "end_time": "2024-07-14T16:35:09.718398",
     "exception": false,
     "start_time": "2024-07-14T16:35:09.702437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters about images\n",
    "res = 384\n",
    "batch_size = 16\n",
    "# hyperparameters about text\n",
    "seq_len = 128\n",
    "# hyperparameters about cross attentive decoder\n",
    "att_depth = 4\n",
    "att_heads = 8\n",
    "att_dims = att_heads * 32\n",
    "use_bias = False\n",
    "\n",
    "train_cases = 70108\n",
    "val_cases = 9972\n",
    "train_steps = train_cases//batch_size\n",
    "val_steps = val_cases//batch_size\n",
    "\n",
    "train_dataset_dir = '/kaggle/input/roco-v2-tfrecord-dataset/Tot70108cases_RoCoV2_radiology_train_GZIP.tfrecord'\n",
    "val_dataset_dir = '/kaggle/input/roco-v2-tfrecord-dataset/Tot9972cases_RoCoV2_radiology_test_GZIP.tfrecord'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d95b3",
   "metadata": {
    "papermill": {
     "duration": 0.004563,
     "end_time": "2024-07-14T16:35:09.727784",
     "exception": false,
     "start_time": "2024-07-14T16:35:09.723221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parsing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a65bb12",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-14T16:35:09.739459Z",
     "iopub.status.busy": "2024-07-14T16:35:09.738128Z",
     "iopub.status.idle": "2024-07-14T16:35:10.266717Z",
     "shell.execute_reply": "2024-07-14T16:35:10.265424Z"
    },
    "papermill": {
     "duration": 0.537145,
     "end_time": "2024-07-14T16:35:10.269491",
     "exception": false,
     "start_time": "2024-07-14T16:35:09.732346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _parse_tfrecord(res = res):\n",
    "    def parse_tfrecord(tfrecord):\n",
    "        features = {'image': tf.io.FixedLenFeature([], tf.string),\n",
    "                    'report': tf.io.FixedLenFeature([], tf.string),\n",
    "                    }\n",
    "        x = tf.io.parse_single_example(tfrecord, features)\n",
    "        image_train = tf.image.decode_jpeg(x['image'], channels=3)\n",
    "        image_train = _transform_images(res = res)(image_train)\n",
    "        report = tf.cast(x[\"report\"], tf.string)\n",
    "        return image_train, report\n",
    "    \n",
    "    return parse_tfrecord\n",
    "\n",
    "\n",
    "def _transform_images(res = res):\n",
    "    def transform_images(x_train):\n",
    "        x_train = tf.image.resize_with_pad(x_train, res, res, antialias = True)\n",
    "        x_train = tf.cast(x_train, tf.uint8)\n",
    "        return x_train\n",
    "    return transform_images\n",
    "\n",
    "def load_tfrecord_dataset(tfrecord_name, res = res, batch_size = batch_size, shuffle=True, buffer_size=10240):\n",
    "    \"\"\"load dataset from tfrecord\"\"\"\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name, compression_type = \"GZIP\")\n",
    "    raw_dataset = raw_dataset.repeat()\n",
    "    if shuffle:\n",
    "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
    "    dataset = raw_dataset.map(\n",
    "        _parse_tfrecord(),\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_ds_ = load_tfrecord_dataset(train_dataset_dir)\n",
    "val_ds_ = load_tfrecord_dataset(val_dataset_dir) #image, report 2 outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01412a90",
   "metadata": {
    "papermill": {
     "duration": 0.004458,
     "end_time": "2024-07-14T16:35:10.278619",
     "exception": false,
     "start_time": "2024-07-14T16:35:10.274161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing Natural language decoder (pretrained on plain texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05c03628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T16:35:10.289796Z",
     "iopub.status.busy": "2024-07-14T16:35:10.289367Z",
     "iopub.status.idle": "2024-07-14T16:35:38.628400Z",
     "shell.execute_reply": "2024-07-14T16:35:38.627196Z"
    },
    "papermill": {
     "duration": 28.347509,
     "end_time": "2024-07-14T16:35:38.630697",
     "exception": false,
     "start_time": "2024-07-14T16:35:10.283188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching 'model.safetensors' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.safetensors.index.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'config.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'config.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.weights.h5' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.safetensors' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'model.safetensors.index.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'metadata.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'preprocessor.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'tokenizer.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'assets/tokenizer/vocabulary.json' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n",
      "Attaching 'assets/tokenizer/merges.txt' from model 'keras/gpt2/keras/gpt2_base_en/2' to your Kaggle notebook...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt2_backbone\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gpt2_backbone\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ token_ids           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_embedding     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">38,597,376</span> │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ position_embedding  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">786,432</span> │ token_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionEmbedding</span>) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_add      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ token_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │                   │            │ position_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_dropout  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embeddings_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ padding_mask        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_0 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ embeddings_dropo… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_2 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_3 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_4 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_5 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_6 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_7 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_8 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_9 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">7,236,352</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_norm          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │ transformer_laye… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ token_ids           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_embedding     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │ \u001b[38;5;34m38,597,376\u001b[0m │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mReversibleEmbeddi…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ position_embedding  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │    \u001b[38;5;34m786,432\u001b[0m │ token_embedding[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mPositionEmbedding\u001b[0m) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_add      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ token_embedding[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAdd\u001b[0m)               │                   │            │ position_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embeddings_dropout  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ embeddings_add[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ padding_mask        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_0 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ embeddings_dropo… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_2 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_3 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_4 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_5 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_6 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_7 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_8 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_9 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_layer_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │  \u001b[38;5;34m7,236,352\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_norm          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m) │      \u001b[38;5;34m1,536\u001b[0m │ transformer_laye… │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">126,221,568</span> (481.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m126,221,568\u001b[0m (481.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,800,192</span> (6.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,800,192\u001b[0m (6.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,421,376</span> (474.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m124,421,376\u001b[0m (474.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt_freeset = \"gpt2_base_en\"\n",
    "text_only_decoder = keras_nlp.models.Backbone.from_preset(\n",
    "    gpt_freeset,\n",
    "    trainable=False,\n",
    ")\n",
    "preprocessor = keras_nlp.models.GPT2Preprocessor.from_preset(\n",
    "    gpt_freeset,\n",
    "    sequence_length=seq_len,\n",
    ")\n",
    "preprocessor.trainable = False\n",
    "text_only_decoder.enable_lora(8)\n",
    "text_only_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5560d6a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T16:35:38.647625Z",
     "iopub.status.busy": "2024-07-14T16:35:38.646592Z",
     "iopub.status.idle": "2024-07-14T16:35:38.652031Z",
     "shell.execute_reply": "2024-07-14T16:35:38.650951Z"
    },
    "papermill": {
     "duration": 0.016403,
     "end_time": "2024-07-14T16:35:38.654346",
     "exception": false,
     "start_time": "2024-07-14T16:35:38.637943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#according to summarized GPT2 model structure:\n",
    "text_embed_dims = 768\n",
    "n_vocab = preprocessor.tokenizer.vocabulary_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f64eee",
   "metadata": {
    "papermill": {
     "duration": 0.007032,
     "end_time": "2024-07-14T16:35:38.668806",
     "exception": false,
     "start_time": "2024-07-14T16:35:38.661774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modelling\n",
    "- building a single model that functions as a testbed;\n",
    "    - image encoder, text encoder(GPT2), cross-attentive attention layer로 구성\n",
    "    - 모델은 image와 raw text를 input으로 받고\n",
    "        - image -> encoder -> [CLS_token, encoded_patches, attention_weight] 3개의 output return\n",
    "        - raw text -> GPT2 -> encoded_text & get mask\n",
    "    - cross_attended_text = TransformerDecoder(query = raw_text, key = encoded_patches, value = encoded_patches, mask = mask) -> Dense -> Perplexity, accuracy 측정\n",
    "    - 위 과정과 cls_token 및 pooled encoded_text의 batchwise cross-correlation 구해서 contrastive accuracy 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7242b3e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T16:35:38.685268Z",
     "iopub.status.busy": "2024-07-14T16:35:38.684871Z",
     "iopub.status.idle": "2024-07-14T16:35:38.715113Z",
     "shell.execute_reply": "2024-07-14T16:35:38.714063Z"
    },
    "papermill": {
     "duration": 0.041949,
     "end_time": "2024-07-14T16:35:38.717987",
     "exception": false,
     "start_time": "2024-07-14T16:35:38.676038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MedicalCaptioner(keras.Model): #original CLIP + CLIP surgery\n",
    "    def __init__(self, image_encoder, \n",
    "                 preprocessor, text_encoder,\n",
    "                 att_heads = att_heads, att_dims = att_dims, att_depth = att_depth,\n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.image_encoder = image_encoder\n",
    "        self.text_encoder = text_encoder\n",
    "        self.embed_dims = embed_dims\n",
    "        self.mlp_text = keras.layers.Dense(units = n_vocab)\n",
    "        self.att_heads = att_heads\n",
    "        self.att_dims = att_dims\n",
    "        self.att_depth = att_depth\n",
    "        self.cross_attention_layers = [keras_nlp.layers.TransformerDecoder(att_dims, att_heads, name = f\"CrossMHADecoder{i+1}\",\n",
    "                                                                          dropout = 0.2, activation = \"gelu\") for i in att_depth]\n",
    "        \n",
    "    def get_config(self):\n",
    "        return {\"Image encoder name\": self.image_encoder.name,\n",
    "               \"Text encoder name\" : self.text_encoder.name,\n",
    "               \"cross attention heads\" : att_heads, \"intermediate dims\" : self.att_dims, \"cross attention depth\" : self.att_depth\n",
    "               }\n",
    "        \n",
    "    def train_step(self, dataset): ###<- 여기서부터!!\n",
    "        image, text = dataset\n",
    "        with tf.GradientTape() as tape: \n",
    "            image_feature, text_feature = self.image_encoder(image, training = True), self.text_encoder(text, training = True)\n",
    "            batch_size, w, h, dims = ops.shape(image_feature) ; batch_size = ops.shape(image_feature)[0]\n",
    "            \n",
    "            image_feature = ops.reshape(image_feature, [batch_size, w*h, dims])\n",
    "            image_feature = self.pe_fn(image_feature)\n",
    "            text_vector = keras.layers.GlobalAveragePooling1D()(text_feature)\n",
    "            if len(ops.shape(image_feature)) == 3:\n",
    "                image_vector = keras.layers.GlobalAveragePooling1D()(image_feature)\n",
    "            elif len(ops.shape(image_feature)) == 4:\n",
    "                image_vector = keras.layers.GlobalAveragePooling2D()(image_feature)\n",
    "\n",
    "            image_vector, text_vector = self.mlp_image(image_vector, training = True), self.mlp_text(text_vector, training = True)\n",
    "            image_vector, text_vector = self.image_pooler([image_vector, image_feature], training = True)[0], self.text_pooler([text_vector, text_feature], training = True)[0]\n",
    "            loss = self.get_clip_loss(image_vector, text_vector)\n",
    "        \n",
    "        encoder_weights = self.image_encoder.trainable_weights + self.text_encoder.trainable_weights\n",
    "        mlp_weights = self.mlp_image.trainable_weights + self.mlp_text.trainable_weights\n",
    "        pool_weights = self.image_pooler.trainable_weights + self.text_pooler.trainable_weights\n",
    "        trainable_weights = encoder_weights + mlp_weights + pool_weights + self.pe_fn.trainable_weights\n",
    "        \n",
    "        grads = tape.gradient(loss, trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, trainable_weights))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {self.loss_tracker.name : self.loss_tracker.result()}\n",
    "    \n",
    "    def test_step(self, dataset):\n",
    "        image, text = dataset\n",
    "        image_feature, text_feature = self.image_encoder(image, training = False), self.text_encoder(text, training = False)\n",
    "        batch_size, w, h, dims = ops.shape(image_feature) ; batch_size = ops.shape(image_feature)[0]\n",
    "            \n",
    "        image_feature = ops.reshape(image_feature, [batch_size, w*h, dims])\n",
    "        image_feature = self.pe_fn(image_feature)\n",
    "        \n",
    "        text_vector = keras.layers.GlobalAveragePooling1D()(text_feature)\n",
    "        if len(ops.shape(image_feature)) == 3:\n",
    "            image_vector = keras.layers.GlobalAveragePooling1D()(image_feature)\n",
    "        elif len(ops.shape(image_feature)) == 4:\n",
    "            image_vector = keras.layers.GlobalAveragePooling2D()(image_feature)\n",
    "\n",
    "        image_vector, text_vector = self.mlp_image(image_vector, training = False), self.mlp_text(text_vector, training = False)\n",
    "        image_vector, text_vector = self.image_pooler([image_vector, image_feature], training = False)[0], self.text_pooler([text_vector, text_feature], training = False)[0]\n",
    "        loss = self.get_clip_loss(image_vector, text_vector)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {self.loss_tracker.name : self.loss_tracker.result()}\n",
    "    def call(self, dataset):\n",
    "        return self.test_step(dataset)\n",
    "    def get_full_model(self):\n",
    "        inputs = self.image_encoder.inputs\n",
    "        feature = self.image_encoder.output\n",
    "        if len(ops.shape(feature)) == 4:\n",
    "            batch_size, w, h, dims = ops.shape(feature)\n",
    "            batch_size = ops.shape(feature)[0]\n",
    "            feature = ops.reshape(feature, [-1, w*h, dims])\n",
    "        feature = self.pe_fn(feature)\n",
    "        image_vector = keras.layers.GlobalAveragePooling1D()(feature)\n",
    "        z_image = self.mlp_image(image_vector)\n",
    "        outputs = self.image_pooler([z_image, feature])\n",
    "        return keras.Model(inputs, outputs,\n",
    "                          name = f\"FullModel_{self.image_encoder.name}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8643234,
     "datasetId": 5073985,
     "sourceId": 8501861,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 7429267,
     "modelInstanceId": 4694,
     "sourceId": 6074,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 61.15491,
   "end_time": "2024-07-14T16:35:42.090109",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-14T16:34:40.935199",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
