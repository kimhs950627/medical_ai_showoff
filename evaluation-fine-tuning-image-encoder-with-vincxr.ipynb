{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":24800,"datasetId":1042002,"databundleVersionId":1831594}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport pydicom\n\nfrom sklearn.manifold import TSNE\nimport re\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nseed = 2024\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# ML tools \n\nimport tensorflow as tf\nimport keras\nfrom keras import ops #keras 3부터는 tf연산이 ops 하위 attribute로 옮겨감\nimport keras_cv\nimport keras_nlp\n\nimport cv2\nkeras.utils.set_random_seed(seed)\nimport tensorflow_io as tfio\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow_datasets as tfds\nimport tensorflow_probability as tfp\nimport tensorflow_decision_forests as tfdf\n\nprint(f\"Tensorflow version : {tf.__version__}\")\ntry:\n    print(f\"Keras version : {keras.__version__}\")\nexcept:\n    pass\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.models import load_model\n\nfrom tensorflow.keras.layers import Conv2D, DepthwiseConv2D, Dense, Activation, BatchNormalization, LayerNormalization, MultiHeadAttention, Embedding, Subtract, Add, Multiply, GlobalAveragePooling2D, GlobalAveragePooling1D, LayerNormalization\nfrom tensorflow.keras.utils import load_img, img_to_array\nfrom tensorflow.keras.applications import *\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tqdm.notebook import tqdm\n\nimport wandb\ndef wandb_config():\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    try:\n        secret_value_0 = user_secrets.get_secret(\"__gcloud_sdk_auth__\")\n        secret_value_1 = user_secrets.get_secret(\"huggingface_key\")\n        secret_value_2 = user_secrets.get_secret(\"wandb_key\")\n        !wandb login $secret_value_2\n    except:\n        secret_value_0 = user_secrets.get_secret(\"huggingface_key\")\n        secret_value_1 = user_secrets.get_secret(\"wandb_key\")\n        !wandb login $secret_value_1\n    \n\nres = int(1.5*256)\nbatch_size = 16\nembed_dims = 768\n\ndef auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        tpu = False\n        strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return tpu, strategy\n\ntpu, strategy = auto_select_accelerator()\nbatch_size = strategy.num_replicas_in_sync * batch_size\nprint('batch size', batch_size)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-27T08:31:11.867668Z","iopub.execute_input":"2024-07-27T08:31:11.868105Z","iopub.status.idle":"2024-07-27T08:31:12.838427Z","shell.execute_reply.started":"2024-07-27T08:31:11.868072Z","shell.execute_reply":"2024-07-27T08:31:12.837374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"channels = 3\nall_labels = ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration', 'Lung Opacity', 'Nodule/Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis', 'No finding']\n\nconfigs = {'batch size' : batch_size,\n          \"image size\" : res,\n          'image channel' : channels,\n          f\"labels({len(all_labels)})\" : all_labels}\n\nlabelencoder = sklearn.preprocessing.MultiLabelBinarizer().fit([all_labels])","metadata":{"execution":{"iopub.status.busy":"2024-07-27T07:48:41.414361Z","iopub.execute_input":"2024-07-27T07:48:41.414836Z","iopub.status.idle":"2024-07-27T07:48:41.423474Z","shell.execute_reply.started":"2024-07-27T07:48:41.414798Z","shell.execute_reply":"2024-07-27T07:48:41.421728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parsing dataset and curation\n- Metadataset link : https://www.kaggle.com/datasets/financekim/vincxr-metadataset","metadata":{}},{"cell_type":"code","source":"mother_dir = \"/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train\"\ndf_train = pd.read_csv(\"/kaggle/input/vinbigdata-chest-xray-abnormalities-detection/train.csv\")\ndf_train[\"image_id\"] = [os.path.join(mother_dir, ids+\".dicom\") for ids in df_train[\"image_id\"]]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-27T07:48:41.425307Z","iopub.execute_input":"2024-07-27T07:48:41.425971Z","iopub.status.idle":"2024-07-27T07:48:41.822178Z","shell.execute_reply.started":"2024-07-27T07:48:41.425939Z","shell.execute_reply":"2024-07-27T07:48:41.820976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_labels(image_path):\n    labels = np.unique(df_train.loc[df_train[\"image_id\"] == image_path, \"class_name\"])\n    labels = labelencoder.transform([labels])\n    return labels[0]\nimg_paths = np.unique(df_train[\"image_id\"].values)\ndf_train_new = pd.DataFrame({\"image_id\" : img_paths,\n                            \"class_id\" : [get_labels(path) for path in tqdm(img_paths)]})","metadata":{"execution":{"iopub.status.busy":"2024-07-27T07:48:41.825567Z","iopub.execute_input":"2024-07-27T07:48:41.826045Z","iopub.status.idle":"2024-07-27T07:52:33.776971Z","shell.execute_reply.started":"2024-07-27T07:48:41.826004Z","shell.execute_reply":"2024-07-27T07:52:33.775859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train, df_val = train_test_split(df_train_new, test_size = 20*batch_size,\n                                   random_state = seed)\ntrain_cases, test_cases = len(df_train), len(df_val)\ntrain_steps, test_steps = train_cases//batch_size, test_cases//batch_size\n\n#setting global image decoding functions\ndef get_image_tensor(filepath, res = res) :\n    #filepath = str(filepath)\n    image_bytes = tf.io.read_file(filepath)\n    if tf.strings.split(filepath, sep = '.')[-1] == \"dicom\" or tf.strings.split(filepath, sep = '.')[-1] == \"dcm\":\n        image = tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint16)\n        image = tf.image.convert_image_dtype(image, tf.float32)\n        image = image[0]\n    else:\n        image = tf.io.decode_png(image_bytes)\n        image = tf.cast(image, tf.float32)\n    image = tf.image.resize_with_pad(image, res, res)\n    image = (image - tf.reduce_min(image)) / (tf.reduce_max(image) - tf.reduce_min(image))\n    image = image * 255.0\n    if channels == 3:\n        try:\n            image = tf.image.grayscale_to_rgb(image)\n        except:\n            pass\n    return image\n\ndef load_data(image_paths, labels):\n    image_paths = tf.convert_to_tensor(image_paths, dtype=tf.string)\n    labels = tf.convert_to_tensor(labels, tf.int32)\n    \n    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n    \n    def _parse_function(image_path, label):\n        image = get_image_tensor(image_path)\n        image = ops.cast(image, 'uint8')\n        return image, label\n    \n    dataset = dataset.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE).ignore_errors()\n    return dataset\n\ntrain_ds = load_data(df_train[\"image_id\"].values, np.stack(df_train[\"class_id\"].values))\nval_ds = load_data(df_val[\"image_id\"].values, np.stack(df_val[\"class_id\"].values))\ntrain_ds = train_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE).repeat().cache()\nval_ds = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE).repeat().cache()\n\nfor img, lab in val_ds.take(1):\n    sample_images = img\n    sample_labels = lab\n    print(ops.shape(sample_images))\n    print(lab)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-27T07:52:33.778310Z","iopub.execute_input":"2024-07-27T07:52:33.778654Z","iopub.status.idle":"2024-07-27T07:52:47.155468Z","shell.execute_reply.started":"2024-07-27T07:52:33.778626Z","shell.execute_reply":"2024-07-27T07:52:47.154253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling and Report callback","metadata":{}},{"cell_type":"code","source":"def get_classifier_model(base_model):\n    base_name = base_model.name\n    inputs = Input([res,res,channels], name = \"VinCXR_Images\")\n    outputs = base_model(inputs)\n    if len(base_model.outputs) == 3:\n        cls_token, encoded_patches, weights = outputs\n        \n    elif len(base_model.outputs) == 2:\n        cls_token, encoded_patches = outputs\n        \n    else:\n        encoded_patches = outputs\n        if len(ops.shape(encoded_patches)) == 4:\n            cls_token = keras.layers.GlobalAveragePooling2D(name = \"CLS_bottleneck\")(encoded_patches)\n        elif len(ops.shape(encoded_patches)) == 3:\n            cls_token = keras.layers.GlobalAveragePooling1D(name = \"CLS_bottleneck\")(encoded_patches)\n    if ops.shape(encoded_patches) == 3:\n        n_patches = ops.shape(encoded_patches)[1] ; dims = ops.shape(encoded_patches)[2]\n        w_ = ops.sqrt(ops.cast(n_patches, \"float32\")\n                     )\n        encoded_patches = ops.reshape(encoded_patches, [-1, w_, w_, dims])\n    encoded_patches = keras.layers.Identity(name = 'Patches')(encoded_patches)\n    \n    classifier_layer = Dense(units = len(all_labels), activation = \"sigmoid\", name = \"DiseaseClassifier\")(cls_token)\n    model = Model(inputs, [classifier_layer, encoded_patches],\n                 name = f\"{base_name}_based_NaiveClassifier\")\n    metric_set = [[keras.metrics.AUC(curve = 'ROC', name = \"AUROC\", multi_label = True), \n                  keras.metrics.AUC(curve = 'PR', name = \"AUPRC\", multi_label = True), \n                  keras.metrics.Precision(name = \"Precision\"), \n                  keras.metrics.Recall(name = \"Recall\"), \n                  keras.metrics.F1Score(average = 'weighted', name = \"F1score\")], None]\n    \n    model.compile(optimizer = keras.optimizers.AdamW(learning_rate = 1e-4),\n                 loss = [\"binary_crossentropy\", None],\n                 metrics = metric_set,\n                 jit_compile = False)\n    return model\n\nclass ClassificationReportCallback(keras.callbacks.Callback):\n    def __init__(self, test_dataset):\n        super().__init__()\n        self.test_dataset = test_dataset\n\n    def on_epoch_end(self, epoch, logs=None):\n        y_true = []\n        y_pred = []\n\n        for idx, batch in tqdm(enumerate(self.test_dataset), total = test_steps +1):\n            X_batch, y_batch = batch\n            y_batch_pred = (self.model.predict(X_batch, verbose = 0)[0] > 0.5).astype(int)\n            y_true.extend(y_batch.numpy())\n            y_pred.extend(y_batch_pred)\n            if idx > test_steps:\n                break\n\n        y_true = np.array(y_true)\n        y_pred = np.array(y_pred)\n        \n        report = classification_report(y_true, y_pred, output_dict=True, target_names=[f'class_{name}' for name in all_labels])\n        report_df = pd.DataFrame(report).transpose()\n        colnames = all_labels + [\"MicroAVG\", \"MacroAVG\", \"WeightedAVG\", \"SamplesAVG\"]\n        report_df[\"ItemNames\"] = colnames\n        # wandb에 업로드\n        wandb.log({'classification_report': wandb.Table(dataframe=report_df)})\n    def on_epoch_begin(self, epoch, logs=None):\n        self.on_epoch_end(epoch, logs)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T07:52:54.466172Z","iopub.execute_input":"2024-07-27T07:52:54.466614Z","iopub.status.idle":"2024-07-27T07:52:54.487985Z","shell.execute_reply.started":"2024-07-27T07:52:54.466577Z","shell.execute_reply":"2024-07-27T07:52:54.486710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_full_cam(model, image):\n    model.trainable = True\n    model_ = keras.Model(model.inputs,\n                        [model.get_layer(\"Patches\").output,\n                        model.get_layer(\"DiseaseClassifier\").output]\n                        )\n    if len(ops.shape(image)) == 3:\n        image = image[tf.newaxis, ...]\n    \n    with tf.GradientTape(persistent = True) as tape:\n        encoded_patches, cls_proba = model_(image)\n        cls_proba_set = ops.split(cls_proba, indices_or_sections = len(all_labels), axis = -1)\n    cam = []\n    for p in cls_proba_set:\n        cls_grads = tape.gradient(p, \n                                  encoded_patches)\n        cls_grads = ops.mean(cls_grads, axis = [1,2])\n        cls_grads = cls_grads[:, tf.newaxis, :] #batch, 1, dims\n\n        cam_ = ops.einsum('bwhd, bcd -> bwhc', encoded_patches, cls_grads)\n        cam_ = keras.layers.Activation(\"relu\")(cam_)\n        cam_ = (cam_ - ops.min(cam_, axis = [1, 2], keepdims = True)) / (ops.max(cam_, axis = [1,2], keepdims = True) - ops.min(cam_, axis = [1,2], keepdims = True)\n                                                                        )\n        cam_ = ops.squeeze(cam_, axis = -1)\n        # Rescale heatmap to a range 0-255\n        cam_ = np.uint8(255 * cam_)\n\n        # Use jet colormap to colorize heatmap\n        jet = mpl.colormaps[\"jet\"]\n\n        # Use RGB values of the colormap\n        jet_colors = jet(np.arange(256))[:, :3]\n        cam_ = jet_colors[cam_]\n\n        # Create an image with RGB colorized heatmap\n        cam_ = tf.image.resize(cam_, (image.shape[2], image.shape[1]),\n                              method = 'gaussian')\n        \n        cam.append(cam_)\n        tf.keras.backend.clear_session()\n        \n    cam = ops.stack(cam, axis = 1)\n    cam = ops.clip(cam, 0, 1)\n    cam *= 255.0\n    cam = ops.cast(cam, \"uint8\")\n    try:\n        image = tf.image.grayscale_to_rgb(image)\n    except:\n        pass\n    \n    superimposed = 0.6*ops.cast(image[:, tf.newaxis, :, :, :], \"float32\") + 0.4*ops.cast(cam, \"float32\")\n    superimposed = ops.cast(superimposed, \"uint8\")\n    return cam, superimposed","metadata":{"execution":{"iopub.status.busy":"2024-07-27T09:11:30.609273Z","iopub.execute_input":"2024-07-27T09:11:30.609714Z","iopub.status.idle":"2024-07-27T09:11:31.271556Z","shell.execute_reply.started":"2024-07-27T09:11:30.609682Z","shell.execute_reply":"2024-07-27T09:11:31.270274Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"# Experiment","metadata":{}},{"cell_type":"code","source":"def run_exp(base_model, notes = None, exp_name = None, epochs = 100,\n           ):\n    try:\n        wandb.finish()\n    except:\n        pass\n    print(configs)\n    model = get_classifier_model(base_model)\n    if exp_name is None:\n        encname = base_model.name\n        exp_name = f\"{encname}_CXRClassification\"\n    pass_error = keras.callbacks.TerminateOnNaN()\n    \n    \n    wandb_config()\n    run = wandb.init(project=\"Eval_RadImageNet_VinCXRClassif\", \n                         entity=\"gongbungkim\", config = configs, notes = notes,\n                        name = exp_name)\n    wb_callback = wandb.keras.WandbMetricsLogger(log_freq = 100)\n    vizcallback = ClassificationReportCallback(val_ds)\n    callbacks = [pass_error, wb_callback, vizcallback]\n    hist = model.fit(train_ds, steps_per_epoch = train_steps, epochs = epochs, verbose = 1, callbacks = callbacks)\n    return hist, model","metadata":{"execution":{"iopub.status.busy":"2024-07-27T07:55:12.542325Z","iopub.execute_input":"2024-07-27T07:55:12.542764Z","iopub.status.idle":"2024-07-27T07:55:12.552428Z","shell.execute_reply.started":"2024-07-27T07:55:12.542723Z","shell.execute_reply":"2024-07-27T07:55:12.551190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run_exp(keras.applications.EfficientNetV2M(input_shape = [res,res,channels], include_top = False)\n       )","metadata":{"execution":{"iopub.status.busy":"2024-07-27T07:55:27.525978Z","iopub.execute_input":"2024-07-27T07:55:27.526530Z","iopub.status.idle":"2024-07-27T08:04:40.563162Z","shell.execute_reply.started":"2024-07-27T07:55:27.526490Z","shell.execute_reply":"2024-07-27T08:04:40.559391Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}